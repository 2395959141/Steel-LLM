{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test qwen2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-12 14:41:38,675] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible\n",
      "/home/calfa100/gqs/Steel-LLM/pretrain_modify_from_TinyLlama/model\n",
      "zhanshijin: surrport flash_attn_2\n",
      "zhanshijin: if flash attn surrport window:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mlp_class: SteelSENet\n",
      "FFN: SteelSoftMoeV3\n",
      "zhanshijin: now use _attn_implementation is sdpa, you can choose from dict_keys(['eager', 'flash_attention_2', 'sdpa'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zhanshijin: success import cuda __rms_norm\n",
      "模型在显存中的占用大小： 9238446080 字节\n",
      "参数名称: model.embed_tokens.weight，数据类型: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# 增加norm和rope的一致性\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy  as np\n",
    "from deepspeed.profiling.flops_profiler import get_model_profile  # type: ignore\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "sys.path.append(os.path.join(current_dir, \"steel_modify_from_qwen_1_5\"))\n",
    "from transformers import AutoConfig\n",
    "from steel_modify_from_qwen_1_5.modeling_steel import Qwen2ForCausalLM\n",
    "config = AutoConfig.from_pretrained(\"./steel_modify_from_qwen_1_5\",trust_remote_code=True)\n",
    "config.use_cuda_rmsnorm = True\n",
    "config.mlp_type = \"raw\"\n",
    "config.FFN_type = \"softmoe_v1\"\n",
    "# ['eager', 'flash_attention_2', 'sdpa']\n",
    "# config._attn_implementation = \"flash_attention_2\"\n",
    "model = Qwen2ForCausalLM(config)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "memory_allocated = torch.cuda.memory_allocated(device)\n",
    "print(\"模型在显存中的占用大小：\", memory_allocated, \"字节\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"参数名称: {name}，数据类型: {param.dtype}\")\n",
    "    break\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2ForCausalLM(\n",
      "  (model): Qwen2Model(\n",
      "    (embed_tokens): Embedding(151936, 2048)\n",
      "    (layers): ModuleList(\n",
      "      (0-23): 24 x Qwen2DecoderLayer(\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): SteelSoftMoEV3(\n",
      "          (experts): ModuleList(\n",
      "            (0-7): 8 x SteelSENet(\n",
      "              (gate_up_proj): Linear(in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(in_features=2048, out_features=688, bias=False)\n",
      "              (gate_down_proj): Linear(in_features=688, out_features=2048, bias=False)\n",
      "              (down_proj): Linear(in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn1): SiLU()\n",
      "              (act_fn2): SiLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm()\n",
      "        (post_attention_layernorm): Qwen2RMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-12 03:36:42,547] [INFO] [profiler.py:1218:get_model_profile] Flops profiler warming-up...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-12 03:36:43,142] [INFO] [profiler.py:80:start_profile] Flops profiler started\n",
      "\n",
      "-------------------------- DeepSpeed Flops Profiler --------------------------\n",
      "Profile Summary at step 1:\n",
      "Notations:\n",
      "data parallel size (dp_size), model parallel size(mp_size),\n",
      "number of parameters (params), number of multiply-accumulate operations(MACs),\n",
      "number of floating-point operations (flops), floating-point operations per second (FLOPS),\n",
      "fwd latency (forward propagation latency), bwd latency (backward propagation latency),\n",
      "step (weights update latency), iter latency (sum of fwd, bwd and step latency)\n",
      "\n",
      "params per GPU:                                                         1.84 B  \n",
      "params of model = params per GPU * mp_size:                             0       \n",
      "fwd MACs per GPU:                                                       189.99 GMACs\n",
      "fwd flops per GPU:                                                      380.59 G\n",
      "fwd flops of model = fwd flops per GPU * mp_size:                       380.59 G\n",
      "fwd latency:                                                            165.19 ms\n",
      "fwd FLOPS per GPU = fwd flops per GPU / fwd latency:                    2.3 TFLOPS\n",
      "\n",
      "----------------------------- Aggregated Profile per GPU -----------------------------\n",
      "Top 1 modules in terms of params, MACs or fwd latency at different model depths:\n",
      "depth 0:\n",
      "    params      - {'Qwen2ForCausalLM': '1.84 B'}\n",
      "    MACs        - {'Qwen2ForCausalLM': '189.99 GMACs'}\n",
      "    fwd latency - {'Qwen2ForCausalLM': '165.19 ms'}\n",
      "depth 1:\n",
      "    params      - {'Qwen2Model': '1.53 B'}\n",
      "    MACs        - {'Qwen2Model': '110.33 GMACs'}\n",
      "    fwd latency - {'Qwen2Model': '163.68 ms'}\n",
      "depth 2:\n",
      "    params      - {'ModuleList': '1.21 B'}\n",
      "    MACs        - {'ModuleList': '110.33 GMACs'}\n",
      "    fwd latency - {'ModuleList': '161.98 ms'}\n",
      "depth 3:\n",
      "    params      - {'Qwen2DecoderLayer': '1.21 B'}\n",
      "    MACs        - {'Qwen2DecoderLayer': '110.33 GMACs'}\n",
      "    fwd latency - {'Qwen2DecoderLayer': '161.98 ms'}\n",
      "depth 4:\n",
      "    params      - {'SteelSoftMoEV3': '811.99 M'}\n",
      "    MACs        - {'Qwen2SdpaAttention': '109.52 GMACs'}\n",
      "    fwd latency - {'SteelSoftMoEV3': '108.5 ms'}\n",
      "depth 5:\n",
      "    params      - {'ModuleList': '811.6 M'}\n",
      "    MACs        - {'Linear': '103.08 GMACs'}\n",
      "    fwd latency - {'ModuleList': '74.45 ms'}\n",
      "depth 6:\n",
      "    params      - {'SteelMLP': '811.6 M'}\n",
      "    MACs        - {'SteelMLP': '811.6 MMACs'}\n",
      "    fwd latency - {'SteelMLP': '74.45 ms'}\n",
      "\n",
      "------------------------------ Detailed Profile per GPU ------------------------------\n",
      "Each module profile is listed after its name in the following order: \n",
      "params, percentage of total params, MACs, percentage of total MACs, fwd latency, percentage of total fwd latency, fwd FLOPS\n",
      "\n",
      "Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). They are not counted as submodules, thus not to be printed out. However they make up the difference between a parent's MACs (or latency) and the sum of its submodules'.\n",
      "2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n",
      "3. The fwd latency listed in the top module's profile is directly captured at the module forward function in PyTorch, thus it's less than the fwd latency shown above which is captured in DeepSpeed.\n",
      "\n",
      "Qwen2ForCausalLM(\n",
      "  1.84 B = 100% Params, 189.99 GMACs = 100% MACs, 165.19 ms = 100% latency, 2.3 TFLOPS\n",
      "  (model): Qwen2Model(\n",
      "    1.53 B = 83.06% Params, 110.33 GMACs = 58.07% MACs, 163.68 ms = 99.09% latency, 1.35 TFLOPS\n",
      "    (embed_tokens): Embedding(311.16 M = 16.94% Params, 0 MACs = 0% MACs, 598.67 us = 0.36% latency, 0 FLOPS, 151936, 2048)\n",
      "    (layers): ModuleList(\n",
      "      (0): Qwen2DecoderLayer(\n",
      "        50.62 M = 2.76% Params, 4.6 GMACs = 2.42% MACs, 7.81 ms = 4.73% latency, 1.18 TFLOPS\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          16.78 M = 0.91% Params, 4.56 GMACs = 2.4% MACs, 2.1 ms = 1.27% latency, 4.34 TFLOPS\n",
      "          (q_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 427.01 us = 0.26% latency, 5.03 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 311.14 us = 0.19% latency, 6.9 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 78.92 us = 0.05% latency, 27.21 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear(4.19 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 116.83 us = 0.07% latency, 18.38 TFLOPS, in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding(0 = 0% Params, 0 MACs = 0% MACs, 63.42 us = 0.04% latency, 0 FLOPS)\n",
      "        )\n",
      "        (mlp): SteelSoftMoEV3(\n",
      "          33.83 M = 1.84% Params, 33.82 MMACs = 0.02% MACs, 5 ms = 3.03% latency, 18.55 GFLOPS\n",
      "          (experts): ModuleList(\n",
      "            (0): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 468.97 us = 0.28% latency, 18.03 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 122.07 us = 0.07% latency, 23.09 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 83.21 us = 0.05% latency, 33.87 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 65.57 us = 0.04% latency, 42.98 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 60.08 us = 0.04% latency, 11.45 MFLOPS)\n",
      "            )\n",
      "            (1): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 385.28 us = 0.23% latency, 21.94 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 83.45 us = 0.05% latency, 33.77 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.87 us = 0.05% latency, 35.28 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.75 us = 0.04% latency, 45.64 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.25 us = 0.02% latency, 16.68 MFLOPS)\n",
      "            )\n",
      "            (2): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 391.24 us = 0.24% latency, 21.61 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.78 us = 0.05% latency, 34.46 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.59 us = 0.05% latency, 34.97 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.7 us = 0.04% latency, 44.94 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 45.54 us = 0.03% latency, 15.11 MFLOPS)\n",
      "            )\n",
      "            (3): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 376.7 us = 0.23% latency, 22.44 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.87 us = 0.05% latency, 35.28 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.06 us = 0.05% latency, 34.76 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.56 us = 0.04% latency, 46.53 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.1 us = 0.02% latency, 17.6 MFLOPS)\n",
      "            )\n",
      "            (4): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 373.36 us = 0.23% latency, 22.65 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.87 us = 0.05% latency, 35.28 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.25 us = 0.05% latency, 36.48 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.27 us = 0.04% latency, 45.99 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.1 us = 0.02% latency, 17.6 MFLOPS)\n",
      "            )\n",
      "            (5): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 392.2 us = 0.24% latency, 21.56 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.59 us = 0.05% latency, 34.97 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.59 us = 0.05% latency, 34.97 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.7 us = 0.04% latency, 44.94 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.05 us = 0.02% latency, 17.18 MFLOPS)\n",
      "            )\n",
      "            (6): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 385.52 us = 0.23% latency, 21.93 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.82 us = 0.05% latency, 34.87 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.92 us = 0.05% latency, 35.71 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 63.42 us = 0.04% latency, 44.44 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.29 us = 0.02% latency, 17.08 MFLOPS)\n",
      "            )\n",
      "            (7): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 372.41 us = 0.23% latency, 22.7 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.15 us = 0.05% latency, 35.6 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.72 us = 0.05% latency, 36.26 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.04 us = 0.04% latency, 46.17 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 38.86 us = 0.02% latency, 17.7 MFLOPS)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 165.94 us = 0.1% latency, 0 FLOPS)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 94.41 us = 0.06% latency, 0 FLOPS)\n",
      "      )\n",
      "      (1): Qwen2DecoderLayer(\n",
      "        50.62 M = 2.76% Params, 4.6 GMACs = 2.42% MACs, 6.9 ms = 4.18% latency, 1.34 TFLOPS\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          16.78 M = 0.91% Params, 4.56 GMACs = 2.4% MACs, 1.75 ms = 1.06% latency, 5.22 TFLOPS\n",
      "          (q_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 321.87 us = 0.19% latency, 6.67 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 78.92 us = 0.05% latency, 27.21 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 300.17 us = 0.18% latency, 7.15 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear(4.19 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 78.2 us = 0.05% latency, 27.46 TFLOPS, in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding(0 = 0% Params, 0 MACs = 0% MACs, 44.35 us = 0.03% latency, 0 FLOPS)\n",
      "        )\n",
      "        (mlp): SteelSoftMoEV3(\n",
      "          33.83 M = 1.84% Params, 33.82 MMACs = 0.02% MACs, 4.5 ms = 2.73% latency, 20.61 GFLOPS\n",
      "          (experts): ModuleList(\n",
      "            (0): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 418.9 us = 0.25% latency, 20.18 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 96.8 us = 0.06% latency, 29.11 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.49 us = 0.05% latency, 34.16 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 63.42 us = 0.04% latency, 44.44 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 43.39 us = 0.03% latency, 15.86 MFLOPS)\n",
      "            )\n",
      "            (1): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 392.91 us = 0.24% latency, 21.52 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 83.45 us = 0.05% latency, 33.77 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.82 us = 0.05% latency, 34.87 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 63.66 us = 0.04% latency, 44.27 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.48 us = 0.03% latency, 16.58 MFLOPS)\n",
      "            )\n",
      "            (2): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 385.05 us = 0.23% latency, 21.96 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.97 us = 0.05% latency, 33.96 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.44 us = 0.05% latency, 35.93 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.75 us = 0.04% latency, 45.64 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.01 us = 0.02% latency, 16.78 MFLOPS)\n",
      "            )\n",
      "            (3): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 390.77 us = 0.24% latency, 21.64 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.11 us = 0.05% latency, 35.18 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.3 us = 0.05% latency, 34.66 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.23 us = 0.04% latency, 45.29 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 45.54 us = 0.03% latency, 15.11 MFLOPS)\n",
      "            )\n",
      "            (4): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 383.85 us = 0.23% latency, 22.03 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.82 us = 0.05% latency, 34.87 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.44 us = 0.05% latency, 35.93 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.94 us = 0.04% latency, 44.77 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.29 us = 0.02% latency, 17.08 MFLOPS)\n",
      "            )\n",
      "            (5): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 382.42 us = 0.23% latency, 22.11 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.25 us = 0.05% latency, 34.26 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.92 us = 0.05% latency, 35.71 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.32 us = 0.04% latency, 46.72 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.01 us = 0.02% latency, 16.78 MFLOPS)\n",
      "            )\n",
      "            (6): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 379.09 us = 0.23% latency, 22.3 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.82 us = 0.05% latency, 34.87 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.96 us = 0.05% latency, 36.15 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.75 us = 0.04% latency, 45.64 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.05 us = 0.02% latency, 17.18 MFLOPS)\n",
      "            )\n",
      "            (7): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 380.75 us = 0.23% latency, 22.21 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.54 us = 0.05% latency, 34.56 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.96 us = 0.05% latency, 36.15 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.27 us = 0.04% latency, 45.99 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.58 us = 0.02% latency, 17.38 MFLOPS)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 103.71 us = 0.06% latency, 0 FLOPS)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 105.62 us = 0.06% latency, 0 FLOPS)\n",
      "      )\n",
      "      (2): Qwen2DecoderLayer(\n",
      "        50.62 M = 2.76% Params, 4.6 GMACs = 2.42% MACs, 6.51 ms = 3.94% latency, 1.42 TFLOPS\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          16.78 M = 0.91% Params, 4.56 GMACs = 2.4% MACs, 1.52 ms = 0.92% latency, 6.01 TFLOPS\n",
      "          (q_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 318.05 us = 0.19% latency, 6.75 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 77.72 us = 0.05% latency, 27.63 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 298.5 us = 0.18% latency, 7.19 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear(4.19 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 76.53 us = 0.05% latency, 28.06 TFLOPS, in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding(0 = 0% Params, 0 MACs = 0% MACs, 47.68 us = 0.03% latency, 0 FLOPS)\n",
      "        )\n",
      "        (mlp): SteelSoftMoEV3(\n",
      "          33.83 M = 1.84% Params, 33.82 MMACs = 0.02% MACs, 4.63 ms = 2.8% latency, 20.04 GFLOPS\n",
      "          (experts): ModuleList(\n",
      "            (0): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 416.76 us = 0.25% latency, 20.29 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 93.94 us = 0.06% latency, 30 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 83.21 us = 0.05% latency, 33.87 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.47 us = 0.04% latency, 45.11 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 45.3 us = 0.03% latency, 15.19 MFLOPS)\n",
      "            )\n",
      "            (1): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 393.39 us = 0.24% latency, 21.49 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.06 us = 0.05% latency, 34.76 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.2 us = 0.05% latency, 36.04 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 72.48 us = 0.04% latency, 38.88 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.01 us = 0.02% latency, 16.78 MFLOPS)\n",
      "            )\n",
      "            (2): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 381.95 us = 0.23% latency, 22.14 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.97 us = 0.05% latency, 33.96 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.96 us = 0.05% latency, 36.15 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.56 us = 0.04% latency, 46.53 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.34 us = 0.02% latency, 17.49 MFLOPS)\n",
      "            )\n",
      "            (3): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 378.37 us = 0.23% latency, 22.35 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.63 us = 0.05% latency, 35.39 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.44 us = 0.05% latency, 35.93 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.04 us = 0.04% latency, 46.17 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.29 us = 0.02% latency, 17.08 MFLOPS)\n",
      "            )\n",
      "            (4): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 384.57 us = 0.23% latency, 21.99 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.73 us = 0.05% latency, 34.06 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.15 us = 0.05% latency, 35.6 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.51 us = 0.04% latency, 45.81 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.77 us = 0.02% latency, 16.88 MFLOPS)\n",
      "            )\n",
      "            (5): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 380.04 us = 0.23% latency, 22.25 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.35 us = 0.05% latency, 35.07 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.92 us = 0.05% latency, 35.71 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.04 us = 0.04% latency, 46.17 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.48 us = 0.03% latency, 16.58 MFLOPS)\n",
      "            )\n",
      "            (6): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 387.43 us = 0.23% latency, 21.82 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 85.12 us = 0.05% latency, 33.11 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.63 us = 0.05% latency, 35.39 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.99 us = 0.04% latency, 45.46 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.25 us = 0.02% latency, 16.68 MFLOPS)\n",
      "            )\n",
      "            (7): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 378.61 us = 0.23% latency, 22.33 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.59 us = 0.05% latency, 34.97 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.68 us = 0.05% latency, 35.82 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.04 us = 0.04% latency, 46.17 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.58 us = 0.02% latency, 17.38 MFLOPS)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 100.85 us = 0.06% latency, 0 FLOPS)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 91.55 us = 0.06% latency, 0 FLOPS)\n",
      "      )\n",
      "      (3): Qwen2DecoderLayer(\n",
      "        50.62 M = 2.76% Params, 4.6 GMACs = 2.42% MACs, 6.75 ms = 4.09% latency, 1.37 TFLOPS\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          16.78 M = 0.91% Params, 4.56 GMACs = 2.4% MACs, 1.74 ms = 1.05% latency, 5.24 TFLOPS\n",
      "          (q_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 316.14 us = 0.19% latency, 6.79 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 305.65 us = 0.19% latency, 7.03 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 85.83 us = 0.05% latency, 25.02 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear(4.19 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 76.06 us = 0.05% latency, 28.24 TFLOPS, in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding(0 = 0% Params, 0 MACs = 0% MACs, 46.49 us = 0.03% latency, 0 FLOPS)\n",
      "        )\n",
      "        (mlp): SteelSoftMoEV3(\n",
      "          33.83 M = 1.84% Params, 33.82 MMACs = 0.02% MACs, 4.4 ms = 2.67% latency, 21.08 GFLOPS\n",
      "          (experts): ModuleList(\n",
      "            (0): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 417.47 us = 0.25% latency, 20.25 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 94.18 us = 0.06% latency, 29.92 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 83.21 us = 0.05% latency, 33.87 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.94 us = 0.04% latency, 44.77 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 44.58 us = 0.03% latency, 15.43 MFLOPS)\n",
      "            )\n",
      "            (1): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 384.09 us = 0.23% latency, 22.01 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.02 us = 0.05% latency, 34.36 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.44 us = 0.05% latency, 35.93 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.23 us = 0.04% latency, 45.29 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.53 us = 0.02% latency, 16.97 MFLOPS)\n",
      "            )\n",
      "            (2): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 384.57 us = 0.23% latency, 21.99 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.3 us = 0.05% latency, 34.66 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.92 us = 0.05% latency, 35.71 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.99 us = 0.04% latency, 45.46 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.01 us = 0.02% latency, 16.78 MFLOPS)\n",
      "            )\n",
      "            (3): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 383.38 us = 0.23% latency, 22.05 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.06 us = 0.05% latency, 34.76 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.96 us = 0.05% latency, 36.15 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.75 us = 0.04% latency, 45.64 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.01 us = 0.02% latency, 16.78 MFLOPS)\n",
      "            )\n",
      "            (4): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 402.93 us = 0.24% latency, 20.98 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.35 us = 0.05% latency, 35.07 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.59 us = 0.05% latency, 34.97 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 73.67 us = 0.04% latency, 38.25 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 45.54 us = 0.03% latency, 15.11 MFLOPS)\n",
      "            )\n",
      "            (5): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 383.38 us = 0.23% latency, 22.05 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.97 us = 0.05% latency, 33.96 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.72 us = 0.05% latency, 36.26 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.04 us = 0.04% latency, 46.17 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.01 us = 0.02% latency, 16.78 MFLOPS)\n",
      "            )\n",
      "            (6): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 386.95 us = 0.23% latency, 21.85 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.35 us = 0.05% latency, 35.07 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.44 us = 0.05% latency, 35.93 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 64.61 us = 0.04% latency, 43.62 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.82 us = 0.02% latency, 17.28 MFLOPS)\n",
      "            )\n",
      "            (7): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 383.62 us = 0.23% latency, 22.04 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.59 us = 0.05% latency, 34.97 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.63 us = 0.05% latency, 35.39 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.99 us = 0.04% latency, 45.46 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.29 us = 0.02% latency, 17.08 MFLOPS)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 96.56 us = 0.06% latency, 0 FLOPS)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 92.51 us = 0.06% latency, 0 FLOPS)\n",
      "      )\n",
      "      (4): Qwen2DecoderLayer(\n",
      "        50.62 M = 2.76% Params, 4.6 GMACs = 2.42% MACs, 6.77 ms = 4.1% latency, 1.36 TFLOPS\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          16.78 M = 0.91% Params, 4.56 GMACs = 2.4% MACs, 1.73 ms = 1.04% latency, 5.29 TFLOPS\n",
      "          (q_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 317.81 us = 0.19% latency, 6.76 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 77.72 us = 0.05% latency, 27.63 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 301.12 us = 0.18% latency, 7.13 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear(4.19 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 75.58 us = 0.05% latency, 28.41 TFLOPS, in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding(0 = 0% Params, 0 MACs = 0% MACs, 40.77 us = 0.02% latency, 0 FLOPS)\n",
      "        )\n",
      "        (mlp): SteelSoftMoEV3(\n",
      "          33.83 M = 1.84% Params, 33.82 MMACs = 0.02% MACs, 4.43 ms = 2.68% latency, 20.93 GFLOPS\n",
      "          (experts): ModuleList(\n",
      "            (0): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 417.47 us = 0.25% latency, 20.25 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 94.65 us = 0.06% latency, 29.77 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.25 us = 0.05% latency, 34.26 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 63.18 us = 0.04% latency, 44.6 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 44.82 us = 0.03% latency, 15.35 MFLOPS)\n",
      "            )\n",
      "            (1): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 388.62 us = 0.24% latency, 21.76 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.3 us = 0.05% latency, 34.66 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.59 us = 0.05% latency, 34.97 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.47 us = 0.04% latency, 45.11 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.48 us = 0.03% latency, 16.58 MFLOPS)\n",
      "            )\n",
      "            (2): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 390.29 us = 0.24% latency, 21.66 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.11 us = 0.05% latency, 35.18 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 87.98 us = 0.05% latency, 32.03 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.75 us = 0.04% latency, 45.64 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.29 us = 0.02% latency, 17.08 MFLOPS)\n",
      "            )\n",
      "            (3): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 392.68 us = 0.24% latency, 21.53 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.59 us = 0.05% latency, 34.97 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.54 us = 0.05% latency, 34.56 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.04 us = 0.04% latency, 46.17 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 46.25 us = 0.03% latency, 14.87 MFLOPS)\n",
      "            )\n",
      "            (4): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 383.62 us = 0.23% latency, 22.04 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.11 us = 0.05% latency, 35.18 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.44 us = 0.05% latency, 35.93 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.99 us = 0.04% latency, 45.46 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.05 us = 0.02% latency, 17.18 MFLOPS)\n",
      "            )\n",
      "            (5): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 375.27 us = 0.23% latency, 22.53 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.87 us = 0.05% latency, 35.28 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.2 us = 0.05% latency, 36.04 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 59.84 us = 0.04% latency, 47.09 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.34 us = 0.02% latency, 17.49 MFLOPS)\n",
      "            )\n",
      "            (6): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 379.09 us = 0.23% latency, 22.3 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.15 us = 0.05% latency, 35.6 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.2 us = 0.05% latency, 36.04 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.04 us = 0.04% latency, 46.17 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.05 us = 0.02% latency, 17.18 MFLOPS)\n",
      "            )\n",
      "            (7): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 396.73 us = 0.24% latency, 21.31 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.15 us = 0.05% latency, 35.6 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.87 us = 0.05% latency, 35.28 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 64.61 us = 0.04% latency, 43.62 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.05 us = 0.02% latency, 17.18 MFLOPS)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 97.04 us = 0.06% latency, 0 FLOPS)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 93.46 us = 0.06% latency, 0 FLOPS)\n",
      "      )\n",
      "      (5): Qwen2DecoderLayer(\n",
      "        50.62 M = 2.76% Params, 4.6 GMACs = 2.42% MACs, 6.48 ms = 3.93% latency, 1.42 TFLOPS\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          16.78 M = 0.91% Params, 4.56 GMACs = 2.4% MACs, 1.51 ms = 0.91% latency, 6.06 TFLOPS\n",
      "          (q_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 317.34 us = 0.19% latency, 6.77 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 78.68 us = 0.05% latency, 27.29 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 299.45 us = 0.18% latency, 7.17 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear(4.19 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 76.53 us = 0.05% latency, 28.06 TFLOPS, in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding(0 = 0% Params, 0 MACs = 0% MACs, 40.05 us = 0.02% latency, 0 FLOPS)\n",
      "        )\n",
      "        (mlp): SteelSoftMoEV3(\n",
      "          33.83 M = 1.84% Params, 33.82 MMACs = 0.02% MACs, 4.61 ms = 2.79% latency, 20.12 GFLOPS\n",
      "          (experts): ModuleList(\n",
      "            (0): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 415.09 us = 0.25% latency, 20.37 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 94.65 us = 0.06% latency, 29.77 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.54 us = 0.05% latency, 34.56 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.47 us = 0.04% latency, 45.11 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 46.25 us = 0.03% latency, 14.87 MFLOPS)\n",
      "            )\n",
      "            (1): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 395.54 us = 0.24% latency, 21.38 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.73 us = 0.05% latency, 34.06 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 87.98 us = 0.05% latency, 32.03 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.94 us = 0.04% latency, 44.77 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.82 us = 0.02% latency, 17.28 MFLOPS)\n",
      "            )\n",
      "            (2): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 382.42 us = 0.23% latency, 22.11 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.3 us = 0.05% latency, 34.66 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.92 us = 0.05% latency, 35.71 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.75 us = 0.04% latency, 45.64 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.53 us = 0.02% latency, 16.97 MFLOPS)\n",
      "            )\n",
      "            (3): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 377.18 us = 0.23% latency, 22.42 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.87 us = 0.05% latency, 35.28 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.68 us = 0.05% latency, 35.82 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.56 us = 0.04% latency, 46.53 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.29 us = 0.02% latency, 17.08 MFLOPS)\n",
      "            )\n",
      "            (4): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 378.13 us = 0.23% latency, 22.36 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.87 us = 0.05% latency, 35.28 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.2 us = 0.05% latency, 36.04 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.04 us = 0.04% latency, 46.17 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.58 us = 0.02% latency, 17.38 MFLOPS)\n",
      "            )\n",
      "            (5): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 374.56 us = 0.23% latency, 22.57 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.39 us = 0.05% latency, 35.49 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.44 us = 0.05% latency, 35.93 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.08 us = 0.04% latency, 46.9 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.05 us = 0.02% latency, 17.18 MFLOPS)\n",
      "            )\n",
      "            (6): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 379.8 us = 0.23% latency, 22.26 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.11 us = 0.05% latency, 35.18 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.72 us = 0.05% latency, 36.26 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.75 us = 0.04% latency, 45.64 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.29 us = 0.02% latency, 17.08 MFLOPS)\n",
      "            )\n",
      "            (7): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 377.18 us = 0.23% latency, 22.42 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.15 us = 0.05% latency, 35.6 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.49 us = 0.05% latency, 36.37 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.8 us = 0.04% latency, 46.35 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.77 us = 0.02% latency, 16.88 MFLOPS)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 100.85 us = 0.06% latency, 0 FLOPS)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 92.98 us = 0.06% latency, 0 FLOPS)\n",
      "      )\n",
      "      (6): Qwen2DecoderLayer(\n",
      "        50.62 M = 2.76% Params, 4.6 GMACs = 2.42% MACs, 6.88 ms = 4.16% latency, 1.34 TFLOPS\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          16.78 M = 0.91% Params, 4.56 GMACs = 2.4% MACs, 1.75 ms = 1.06% latency, 5.23 TFLOPS\n",
      "          (q_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 323.06 us = 0.2% latency, 6.65 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 312.81 us = 0.19% latency, 6.87 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 81.06 us = 0.05% latency, 26.49 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear(4.19 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 75.58 us = 0.05% latency, 28.41 TFLOPS, in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding(0 = 0% Params, 0 MACs = 0% MACs, 41.01 us = 0.02% latency, 0 FLOPS)\n",
      "        )\n",
      "        (mlp): SteelSoftMoEV3(\n",
      "          33.83 M = 1.84% Params, 33.82 MMACs = 0.02% MACs, 4.51 ms = 2.73% latency, 20.56 GFLOPS\n",
      "          (experts): ModuleList(\n",
      "            (0): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 413.89 us = 0.25% latency, 20.43 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 93.22 us = 0.06% latency, 30.23 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.78 us = 0.05% latency, 34.46 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 63.18 us = 0.04% latency, 44.6 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 44.35 us = 0.03% latency, 15.51 MFLOPS)\n",
      "            )\n",
      "            (1): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 382.66 us = 0.23% latency, 22.09 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.54 us = 0.05% latency, 34.56 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.68 us = 0.05% latency, 35.82 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.51 us = 0.04% latency, 45.81 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.05 us = 0.02% latency, 17.18 MFLOPS)\n",
      "            )\n",
      "            (2): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 381.95 us = 0.23% latency, 22.14 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.3 us = 0.05% latency, 34.66 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.92 us = 0.05% latency, 35.71 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.75 us = 0.04% latency, 45.64 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.29 us = 0.02% latency, 17.08 MFLOPS)\n",
      "            )\n",
      "            (3): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 381.47 us = 0.23% latency, 22.16 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.54 us = 0.05% latency, 34.56 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.2 us = 0.05% latency, 36.04 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.04 us = 0.04% latency, 46.17 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.29 us = 0.02% latency, 17.08 MFLOPS)\n",
      "            )\n",
      "            (4): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 430.35 us = 0.26% latency, 19.65 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.59 us = 0.05% latency, 34.97 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 83.68 us = 0.05% latency, 33.67 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.47 us = 0.04% latency, 45.11 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.72 us = 0.03% latency, 16.49 MFLOPS)\n",
      "            )\n",
      "            (5): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 381.95 us = 0.23% latency, 22.14 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.82 us = 0.05% latency, 34.87 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.92 us = 0.05% latency, 35.71 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.27 us = 0.04% latency, 45.99 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.77 us = 0.02% latency, 16.88 MFLOPS)\n",
      "            )\n",
      "            (6): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 395.77 us = 0.24% latency, 21.36 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.35 us = 0.05% latency, 35.07 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.59 us = 0.05% latency, 34.97 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 64.13 us = 0.04% latency, 43.94 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 46.49 us = 0.03% latency, 14.8 MFLOPS)\n",
      "            )\n",
      "            (7): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 380.99 us = 0.23% latency, 22.19 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.82 us = 0.05% latency, 34.87 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.92 us = 0.05% latency, 35.71 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.04 us = 0.04% latency, 46.17 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.01 us = 0.02% latency, 16.78 MFLOPS)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 95.84 us = 0.06% latency, 0 FLOPS)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 92.27 us = 0.06% latency, 0 FLOPS)\n",
      "      )\n",
      "      (7): Qwen2DecoderLayer(\n",
      "        50.62 M = 2.76% Params, 4.6 GMACs = 2.42% MACs, 6.81 ms = 4.12% latency, 1.35 TFLOPS\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          16.78 M = 0.91% Params, 4.56 GMACs = 2.4% MACs, 1.73 ms = 1.05% latency, 5.27 TFLOPS\n",
      "          (q_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 318.05 us = 0.19% latency, 6.75 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 78.68 us = 0.05% latency, 27.29 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 304.46 us = 0.18% latency, 7.05 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear(4.19 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 77.01 us = 0.05% latency, 27.89 TFLOPS, in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding(0 = 0% Params, 0 MACs = 0% MACs, 41.96 us = 0.03% latency, 0 FLOPS)\n",
      "        )\n",
      "        (mlp): SteelSoftMoEV3(\n",
      "          33.83 M = 1.84% Params, 33.82 MMACs = 0.02% MACs, 4.4 ms = 2.66% latency, 21.1 GFLOPS\n",
      "          (experts): ModuleList(\n",
      "            (0): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 417.23 us = 0.25% latency, 20.26 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 95.13 us = 0.06% latency, 29.62 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.02 us = 0.05% latency, 34.36 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 63.66 us = 0.04% latency, 44.27 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 44.35 us = 0.03% latency, 15.51 MFLOPS)\n",
      "            )\n",
      "            (1): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 386.24 us = 0.23% latency, 21.89 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.02 us = 0.05% latency, 34.36 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.63 us = 0.05% latency, 35.39 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.99 us = 0.04% latency, 45.46 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.01 us = 0.02% latency, 16.78 MFLOPS)\n",
      "            )\n",
      "            (2): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 386.71 us = 0.23% latency, 21.86 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.06 us = 0.05% latency, 34.76 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.44 us = 0.05% latency, 35.93 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 63.66 us = 0.04% latency, 44.27 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.25 us = 0.02% latency, 16.68 MFLOPS)\n",
      "            )\n",
      "            (3): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 396.25 us = 0.24% latency, 21.34 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.73 us = 0.05% latency, 34.06 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.25 us = 0.05% latency, 34.26 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.51 us = 0.04% latency, 45.81 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 46.01 us = 0.03% latency, 14.95 MFLOPS)\n",
      "            )\n",
      "            (4): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 393.87 us = 0.24% latency, 21.47 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.82 us = 0.05% latency, 34.87 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 85.59 us = 0.05% latency, 32.92 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 65.33 us = 0.04% latency, 43.14 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.58 us = 0.02% latency, 17.38 MFLOPS)\n",
      "            )\n",
      "            (5): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 381.23 us = 0.23% latency, 22.18 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.54 us = 0.05% latency, 34.56 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.25 us = 0.05% latency, 36.48 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.47 us = 0.04% latency, 45.11 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.77 us = 0.02% latency, 16.88 MFLOPS)\n",
      "            )\n",
      "            (6): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 374.79 us = 0.23% latency, 22.56 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.35 us = 0.05% latency, 35.07 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.01 us = 0.05% latency, 36.59 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.8 us = 0.04% latency, 46.35 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.34 us = 0.02% latency, 17.49 MFLOPS)\n",
      "            )\n",
      "            (7): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 388.38 us = 0.24% latency, 21.77 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 83.68 us = 0.05% latency, 33.67 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.01 us = 0.05% latency, 36.59 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.51 us = 0.04% latency, 45.81 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.58 us = 0.02% latency, 17.38 MFLOPS)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 108 us = 0.07% latency, 0 FLOPS)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 97.27 us = 0.06% latency, 0 FLOPS)\n",
      "      )\n",
      "      (8): Qwen2DecoderLayer(\n",
      "        50.62 M = 2.76% Params, 4.6 GMACs = 2.42% MACs, 6.5 ms = 3.93% latency, 1.42 TFLOPS\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          16.78 M = 0.91% Params, 4.56 GMACs = 2.4% MACs, 1.5 ms = 0.91% latency, 6.07 TFLOPS\n",
      "          (q_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 318.29 us = 0.19% latency, 6.75 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 77.49 us = 0.05% latency, 27.71 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 298.74 us = 0.18% latency, 7.19 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear(4.19 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 75.34 us = 0.05% latency, 28.5 TFLOPS, in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding(0 = 0% Params, 0 MACs = 0% MACs, 41.48 us = 0.03% latency, 0 FLOPS)\n",
      "        )\n",
      "        (mlp): SteelSoftMoEV3(\n",
      "          33.83 M = 1.84% Params, 33.82 MMACs = 0.02% MACs, 4.63 ms = 2.8% latency, 20.05 GFLOPS\n",
      "          (experts): ModuleList(\n",
      "            (0): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 417.71 us = 0.25% latency, 20.24 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 95.13 us = 0.06% latency, 29.62 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.78 us = 0.05% latency, 34.46 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 64.61 us = 0.04% latency, 43.62 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 43.39 us = 0.03% latency, 15.86 MFLOPS)\n",
      "            )\n",
      "            (1): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 398.87 us = 0.24% latency, 21.2 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 87.26 us = 0.05% latency, 32.29 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.44 us = 0.05% latency, 35.93 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.51 us = 0.04% latency, 45.81 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.77 us = 0.02% latency, 16.88 MFLOPS)\n",
      "            )\n",
      "            (2): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 405.31 us = 0.25% latency, 20.86 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.06 us = 0.05% latency, 34.76 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 101.57 us = 0.06% latency, 27.75 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.99 us = 0.04% latency, 45.46 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.82 us = 0.02% latency, 17.28 MFLOPS)\n",
      "            )\n",
      "            (3): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 380.52 us = 0.23% latency, 22.22 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.54 us = 0.05% latency, 34.56 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.68 us = 0.05% latency, 35.82 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.56 us = 0.04% latency, 46.53 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.48 us = 0.03% latency, 16.58 MFLOPS)\n",
      "            )\n",
      "            (4): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 379.32 us = 0.23% latency, 22.29 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.35 us = 0.05% latency, 35.07 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.68 us = 0.05% latency, 35.82 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.27 us = 0.04% latency, 45.99 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.58 us = 0.02% latency, 17.38 MFLOPS)\n",
      "            )\n",
      "            (5): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 380.99 us = 0.23% latency, 22.19 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.82 us = 0.05% latency, 34.87 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.44 us = 0.05% latency, 35.93 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.32 us = 0.04% latency, 46.72 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.01 us = 0.02% latency, 16.78 MFLOPS)\n",
      "            )\n",
      "            (6): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 373.36 us = 0.23% latency, 22.65 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.35 us = 0.05% latency, 35.07 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.01 us = 0.05% latency, 36.59 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 59.84 us = 0.04% latency, 47.09 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.05 us = 0.02% latency, 17.18 MFLOPS)\n",
      "            )\n",
      "            (7): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 376.22 us = 0.23% latency, 22.47 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.59 us = 0.05% latency, 34.97 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.72 us = 0.05% latency, 36.26 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.27 us = 0.04% latency, 45.99 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.29 us = 0.02% latency, 17.08 MFLOPS)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 100.37 us = 0.06% latency, 0 FLOPS)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 93.7 us = 0.06% latency, 0 FLOPS)\n",
      "      )\n",
      "      (9): Qwen2DecoderLayer(\n",
      "        50.62 M = 2.76% Params, 4.6 GMACs = 2.42% MACs, 6.76 ms = 4.09% latency, 1.36 TFLOPS\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          16.78 M = 0.91% Params, 4.56 GMACs = 2.4% MACs, 1.76 ms = 1.07% latency, 5.17 TFLOPS\n",
      "          (q_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 320.2 us = 0.19% latency, 6.71 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 349.28 us = 0.21% latency, 6.15 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 78.2 us = 0.05% latency, 27.46 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear(4.19 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 76.06 us = 0.05% latency, 28.24 TFLOPS, in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding(0 = 0% Params, 0 MACs = 0% MACs, 40.05 us = 0.02% latency, 0 FLOPS)\n",
      "        )\n",
      "        (mlp): SteelSoftMoEV3(\n",
      "          33.83 M = 1.84% Params, 33.82 MMACs = 0.02% MACs, 4.39 ms = 2.66% latency, 21.13 GFLOPS\n",
      "          (experts): ModuleList(\n",
      "            (0): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 414.85 us = 0.25% latency, 20.38 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 93.94 us = 0.06% latency, 30 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.25 us = 0.05% latency, 34.26 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.7 us = 0.04% latency, 44.94 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 43.39 us = 0.03% latency, 15.86 MFLOPS)\n",
      "            )\n",
      "            (1): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 387.91 us = 0.23% latency, 21.8 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.25 us = 0.05% latency, 34.26 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.59 us = 0.05% latency, 34.97 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.47 us = 0.04% latency, 45.11 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.25 us = 0.02% latency, 16.68 MFLOPS)\n",
      "            )\n",
      "            (2): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 384.09 us = 0.23% latency, 22.01 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.82 us = 0.05% latency, 34.87 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.92 us = 0.05% latency, 35.71 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.51 us = 0.04% latency, 45.81 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.48 us = 0.03% latency, 16.58 MFLOPS)\n",
      "            )\n",
      "            (3): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 381.71 us = 0.23% latency, 22.15 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.06 us = 0.05% latency, 34.76 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.63 us = 0.05% latency, 35.39 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.27 us = 0.04% latency, 45.99 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.29 us = 0.02% latency, 17.08 MFLOPS)\n",
      "            )\n",
      "            (4): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 387.43 us = 0.23% latency, 21.82 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.25 us = 0.05% latency, 34.26 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.44 us = 0.05% latency, 35.93 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.94 us = 0.04% latency, 44.77 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.96 us = 0.03% latency, 16.4 MFLOPS)\n",
      "            )\n",
      "            (5): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 374.79 us = 0.23% latency, 22.56 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.82 us = 0.05% latency, 34.87 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 76.29 us = 0.05% latency, 36.94 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.56 us = 0.04% latency, 46.53 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.58 us = 0.02% latency, 17.38 MFLOPS)\n",
      "            )\n",
      "            (6): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 388.86 us = 0.24% latency, 21.74 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.35 us = 0.05% latency, 35.07 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.49 us = 0.05% latency, 36.37 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 65.09 us = 0.04% latency, 43.3 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.29 us = 0.02% latency, 17.08 MFLOPS)\n",
      "            )\n",
      "            (7): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 381.47 us = 0.23% latency, 22.16 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.3 us = 0.05% latency, 34.66 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.49 us = 0.05% latency, 36.37 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.75 us = 0.04% latency, 45.64 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.05 us = 0.02% latency, 17.18 MFLOPS)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 97.27 us = 0.06% latency, 0 FLOPS)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 91.31 us = 0.06% latency, 0 FLOPS)\n",
      "      )\n",
      "      (10): Qwen2DecoderLayer(\n",
      "        50.62 M = 2.76% Params, 4.6 GMACs = 2.42% MACs, 6.91 ms = 4.18% latency, 1.33 TFLOPS\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          16.78 M = 0.91% Params, 4.56 GMACs = 2.4% MACs, 1.73 ms = 1.05% latency, 5.28 TFLOPS\n",
      "          (q_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 313.28 us = 0.19% latency, 6.85 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 77.01 us = 0.05% latency, 27.89 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 298.74 us = 0.18% latency, 7.19 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear(4.19 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 86.07 us = 0.05% latency, 24.95 TFLOPS, in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding(0 = 0% Params, 0 MACs = 0% MACs, 40.53 us = 0.02% latency, 0 FLOPS)\n",
      "        )\n",
      "        (mlp): SteelSoftMoEV3(\n",
      "          33.83 M = 1.84% Params, 33.82 MMACs = 0.02% MACs, 4.46 ms = 2.7% latency, 20.8 GFLOPS\n",
      "          (experts): ModuleList(\n",
      "            (0): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 431.54 us = 0.26% latency, 19.59 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 97.99 us = 0.06% latency, 28.76 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.73 us = 0.05% latency, 34.06 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 64.37 us = 0.04% latency, 43.78 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 45.78 us = 0.03% latency, 15.03 MFLOPS)\n",
      "            )\n",
      "            (1): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 388.86 us = 0.24% latency, 21.74 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 84.88 us = 0.05% latency, 33.2 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.39 us = 0.05% latency, 35.49 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.7 us = 0.04% latency, 44.94 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.25 us = 0.02% latency, 16.68 MFLOPS)\n",
      "            )\n",
      "            (2): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 385.05 us = 0.23% latency, 21.96 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.35 us = 0.05% latency, 35.07 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.96 us = 0.05% latency, 36.15 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 66.76 us = 0.04% latency, 42.21 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.58 us = 0.02% latency, 17.38 MFLOPS)\n",
      "            )\n",
      "            (3): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 411.75 us = 0.25% latency, 20.53 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.78 us = 0.05% latency, 34.46 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 97.51 us = 0.06% latency, 28.9 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 72.24 us = 0.04% latency, 39.01 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.53 us = 0.02% latency, 16.97 MFLOPS)\n",
      "            )\n",
      "            (4): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 375.51 us = 0.23% latency, 22.52 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.82 us = 0.05% latency, 34.87 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.01 us = 0.05% latency, 36.59 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.56 us = 0.04% latency, 46.53 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 38.86 us = 0.02% latency, 17.7 MFLOPS)\n",
      "            )\n",
      "            (5): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 376.46 us = 0.23% latency, 22.46 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.11 us = 0.05% latency, 35.18 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.68 us = 0.05% latency, 35.82 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 59.84 us = 0.04% latency, 47.09 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.82 us = 0.02% latency, 17.28 MFLOPS)\n",
      "            )\n",
      "            (6): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 399.11 us = 0.24% latency, 21.18 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 91.08 us = 0.06% latency, 30.94 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.72 us = 0.05% latency, 36.26 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 71.53 us = 0.04% latency, 39.4 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.82 us = 0.02% latency, 17.28 MFLOPS)\n",
      "            )\n",
      "            (7): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 380.99 us = 0.23% latency, 22.19 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.97 us = 0.05% latency, 33.96 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.72 us = 0.05% latency, 36.26 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.23 us = 0.04% latency, 45.29 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.82 us = 0.02% latency, 17.28 MFLOPS)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 98.47 us = 0.06% latency, 0 FLOPS)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 93.46 us = 0.06% latency, 0 FLOPS)\n",
      "      )\n",
      "      (11): Qwen2DecoderLayer(\n",
      "        50.62 M = 2.76% Params, 4.6 GMACs = 2.42% MACs, 6.86 ms = 4.15% latency, 1.34 TFLOPS\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          16.78 M = 0.91% Params, 4.56 GMACs = 2.4% MACs, 1.59 ms = 0.97% latency, 5.72 TFLOPS\n",
      "          (q_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 337.6 us = 0.2% latency, 6.36 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 84.64 us = 0.05% latency, 25.37 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 305.41 us = 0.18% latency, 7.03 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear(4.19 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 76.53 us = 0.05% latency, 28.06 TFLOPS, in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding(0 = 0% Params, 0 MACs = 0% MACs, 45.78 us = 0.03% latency, 0 FLOPS)\n",
      "        )\n",
      "        (mlp): SteelSoftMoEV3(\n",
      "          33.83 M = 1.84% Params, 33.82 MMACs = 0.02% MACs, 4.86 ms = 2.94% latency, 19.11 GFLOPS\n",
      "          (experts): ModuleList(\n",
      "            (0): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 433.21 us = 0.26% latency, 19.52 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 101.57 us = 0.06% latency, 27.75 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.25 us = 0.05% latency, 34.26 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 72 us = 0.04% latency, 39.14 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 45.78 us = 0.03% latency, 15.03 MFLOPS)\n",
      "            )\n",
      "            (1): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 379.56 us = 0.23% latency, 22.28 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.3 us = 0.05% latency, 34.66 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.92 us = 0.05% latency, 35.71 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.75 us = 0.04% latency, 45.64 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.29 us = 0.02% latency, 17.08 MFLOPS)\n",
      "            )\n",
      "            (2): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 379.8 us = 0.23% latency, 22.26 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.35 us = 0.05% latency, 35.07 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.15 us = 0.05% latency, 35.6 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.75 us = 0.04% latency, 45.64 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.53 us = 0.02% latency, 16.97 MFLOPS)\n",
      "            )\n",
      "            (3): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 377.42 us = 0.23% latency, 22.4 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.54 us = 0.05% latency, 34.56 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.68 us = 0.05% latency, 35.82 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.56 us = 0.04% latency, 46.53 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.05 us = 0.02% latency, 17.18 MFLOPS)\n",
      "            )\n",
      "            (4): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 386.48 us = 0.23% latency, 21.88 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 87.5 us = 0.05% latency, 32.21 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.39 us = 0.05% latency, 35.49 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.75 us = 0.04% latency, 45.64 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.58 us = 0.02% latency, 17.38 MFLOPS)\n",
      "            )\n",
      "            (5): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 374.08 us = 0.23% latency, 22.6 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.11 us = 0.05% latency, 35.18 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.49 us = 0.05% latency, 36.37 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 59.37 us = 0.04% latency, 47.47 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.82 us = 0.02% latency, 17.28 MFLOPS)\n",
      "            )\n",
      "            (6): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 376.22 us = 0.23% latency, 22.47 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.15 us = 0.05% latency, 35.6 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.25 us = 0.05% latency, 36.48 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.51 us = 0.04% latency, 45.81 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.53 us = 0.02% latency, 16.97 MFLOPS)\n",
      "            )\n",
      "            (7): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 370.98 us = 0.22% latency, 22.79 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.63 us = 0.05% latency, 35.39 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.25 us = 0.05% latency, 36.48 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 59.13 us = 0.04% latency, 47.66 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.82 us = 0.02% latency, 17.28 MFLOPS)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 131.37 us = 0.08% latency, 0 FLOPS)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 93.7 us = 0.06% latency, 0 FLOPS)\n",
      "      )\n",
      "      (12): Qwen2DecoderLayer(\n",
      "        50.62 M = 2.76% Params, 4.6 GMACs = 2.42% MACs, 7.05 ms = 4.27% latency, 1.31 TFLOPS\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          16.78 M = 0.91% Params, 4.56 GMACs = 2.4% MACs, 1.73 ms = 1.05% latency, 5.27 TFLOPS\n",
      "          (q_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 322.58 us = 0.2% latency, 6.66 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 308.04 us = 0.19% latency, 6.97 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 77.01 us = 0.05% latency, 27.89 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear(4.19 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 75.1 us = 0.05% latency, 28.59 TFLOPS, in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding(0 = 0% Params, 0 MACs = 0% MACs, 41.48 us = 0.03% latency, 0 FLOPS)\n",
      "        )\n",
      "        (mlp): SteelSoftMoEV3(\n",
      "          33.83 M = 1.84% Params, 33.82 MMACs = 0.02% MACs, 4.67 ms = 2.83% latency, 19.88 GFLOPS\n",
      "          (experts): ModuleList(\n",
      "            (0): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 418.66 us = 0.25% latency, 20.19 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 98.94 us = 0.06% latency, 28.48 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.35 us = 0.05% latency, 35.07 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.94 us = 0.04% latency, 44.77 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 45.3 us = 0.03% latency, 15.19 MFLOPS)\n",
      "            )\n",
      "            (1): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 394.34 us = 0.24% latency, 21.44 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.54 us = 0.05% latency, 34.56 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.39 us = 0.05% latency, 35.49 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 72.96 us = 0.04% latency, 38.63 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.77 us = 0.02% latency, 16.88 MFLOPS)\n",
      "            )\n",
      "            (2): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 383.38 us = 0.23% latency, 22.05 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 88.45 us = 0.05% latency, 31.86 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.72 us = 0.05% latency, 36.26 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.08 us = 0.04% latency, 46.9 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.82 us = 0.02% latency, 17.28 MFLOPS)\n",
      "            )\n",
      "            (3): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 376.46 us = 0.23% latency, 22.46 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.15 us = 0.05% latency, 35.6 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.44 us = 0.05% latency, 35.93 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.75 us = 0.04% latency, 45.64 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.58 us = 0.02% latency, 17.38 MFLOPS)\n",
      "            )\n",
      "            (4): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 374.32 us = 0.23% latency, 22.59 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.59 us = 0.05% latency, 34.97 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.2 us = 0.05% latency, 36.04 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.08 us = 0.04% latency, 46.9 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 38.86 us = 0.02% latency, 17.7 MFLOPS)\n",
      "            )\n",
      "            (5): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 373.6 us = 0.23% latency, 22.63 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.78 us = 0.05% latency, 34.46 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.72 us = 0.05% latency, 36.26 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 59.84 us = 0.04% latency, 47.09 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.34 us = 0.02% latency, 17.49 MFLOPS)\n",
      "            )\n",
      "            (6): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 389.34 us = 0.24% latency, 21.72 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.06 us = 0.05% latency, 34.76 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.59 us = 0.05% latency, 34.97 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.99 us = 0.04% latency, 45.46 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 44.58 us = 0.03% latency, 15.43 MFLOPS)\n",
      "            )\n",
      "            (7): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 377.42 us = 0.23% latency, 22.4 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.39 us = 0.05% latency, 35.49 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.72 us = 0.05% latency, 36.26 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.75 us = 0.04% latency, 45.64 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.05 us = 0.02% latency, 17.18 MFLOPS)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 101.09 us = 0.06% latency, 0 FLOPS)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 98.71 us = 0.06% latency, 0 FLOPS)\n",
      "      )\n",
      "      (13): Qwen2DecoderLayer(\n",
      "        50.62 M = 2.76% Params, 4.6 GMACs = 2.42% MACs, 6.78 ms = 4.11% latency, 1.36 TFLOPS\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          16.78 M = 0.91% Params, 4.56 GMACs = 2.4% MACs, 1.77 ms = 1.07% latency, 5.16 TFLOPS\n",
      "          (q_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 328.3 us = 0.2% latency, 6.54 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 77.25 us = 0.05% latency, 27.8 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 312.81 us = 0.19% latency, 6.87 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear(4.19 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 75.34 us = 0.05% latency, 28.5 TFLOPS, in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding(0 = 0% Params, 0 MACs = 0% MACs, 41.96 us = 0.03% latency, 0 FLOPS)\n",
      "        )\n",
      "        (mlp): SteelSoftMoEV3(\n",
      "          33.83 M = 1.84% Params, 33.82 MMACs = 0.02% MACs, 4.4 ms = 2.67% latency, 21.07 GFLOPS\n",
      "          (experts): ModuleList(\n",
      "            (0): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 412.23 us = 0.25% latency, 20.51 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 91.55 us = 0.06% latency, 30.78 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.02 us = 0.05% latency, 34.36 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.94 us = 0.04% latency, 44.77 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 44.35 us = 0.03% latency, 15.51 MFLOPS)\n",
      "            )\n",
      "            (1): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 383.14 us = 0.23% latency, 22.07 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.49 us = 0.05% latency, 34.16 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.15 us = 0.05% latency, 35.6 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.04 us = 0.04% latency, 46.17 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.58 us = 0.02% latency, 17.38 MFLOPS)\n",
      "            )\n",
      "            (2): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 386.95 us = 0.23% latency, 21.85 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.78 us = 0.05% latency, 34.46 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.15 us = 0.05% latency, 35.6 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 65.57 us = 0.04% latency, 42.98 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.05 us = 0.02% latency, 17.18 MFLOPS)\n",
      "            )\n",
      "            (3): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 379.56 us = 0.23% latency, 22.28 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.78 us = 0.05% latency, 34.46 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.44 us = 0.05% latency, 35.93 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.27 us = 0.04% latency, 45.99 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.82 us = 0.02% latency, 17.28 MFLOPS)\n",
      "            )\n",
      "            (4): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 424.86 us = 0.26% latency, 19.9 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.63 us = 0.05% latency, 35.39 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.25 us = 0.05% latency, 36.48 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 64.37 us = 0.04% latency, 43.78 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 38.62 us = 0.02% latency, 17.81 MFLOPS)\n",
      "            )\n",
      "            (5): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 373.6 us = 0.23% latency, 22.63 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.59 us = 0.05% latency, 34.97 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.01 us = 0.05% latency, 36.59 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.8 us = 0.04% latency, 46.35 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.58 us = 0.02% latency, 17.38 MFLOPS)\n",
      "            )\n",
      "            (6): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 376.7 us = 0.23% latency, 22.44 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.39 us = 0.05% latency, 35.49 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.44 us = 0.05% latency, 35.93 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.99 us = 0.04% latency, 45.46 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.58 us = 0.02% latency, 17.38 MFLOPS)\n",
      "            )\n",
      "            (7): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 374.56 us = 0.23% latency, 22.57 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.59 us = 0.05% latency, 34.97 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.72 us = 0.05% latency, 36.26 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 59.6 us = 0.04% latency, 47.28 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.82 us = 0.02% latency, 17.28 MFLOPS)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 104.9 us = 0.06% latency, 0 FLOPS)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 90.6 us = 0.05% latency, 0 FLOPS)\n",
      "      )\n",
      "      (14): Qwen2DecoderLayer(\n",
      "        50.62 M = 2.76% Params, 4.6 GMACs = 2.42% MACs, 6.48 ms = 3.92% latency, 1.42 TFLOPS\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          16.78 M = 0.91% Params, 4.56 GMACs = 2.4% MACs, 1.52 ms = 0.92% latency, 6.02 TFLOPS\n",
      "          (q_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 321.63 us = 0.19% latency, 6.68 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 76.53 us = 0.05% latency, 28.06 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 299.93 us = 0.18% latency, 7.16 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear(4.19 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 74.86 us = 0.05% latency, 28.69 TFLOPS, in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding(0 = 0% Params, 0 MACs = 0% MACs, 41.48 us = 0.03% latency, 0 FLOPS)\n",
      "        )\n",
      "        (mlp): SteelSoftMoEV3(\n",
      "          33.83 M = 1.84% Params, 33.82 MMACs = 0.02% MACs, 4.6 ms = 2.78% latency, 20.19 GFLOPS\n",
      "          (experts): ModuleList(\n",
      "            (0): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 411.03 us = 0.25% latency, 20.57 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 91.79 us = 0.06% latency, 30.7 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.54 us = 0.05% latency, 34.56 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.7 us = 0.04% latency, 44.94 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 45.78 us = 0.03% latency, 15.03 MFLOPS)\n",
      "            )\n",
      "            (1): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 384.81 us = 0.23% latency, 21.97 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.73 us = 0.05% latency, 34.06 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.15 us = 0.05% latency, 35.6 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.27 us = 0.04% latency, 45.99 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.48 us = 0.03% latency, 16.58 MFLOPS)\n",
      "            )\n",
      "            (2): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 382.42 us = 0.23% latency, 22.11 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.02 us = 0.05% latency, 34.36 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.96 us = 0.05% latency, 36.15 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 63.66 us = 0.04% latency, 44.27 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.58 us = 0.02% latency, 17.38 MFLOPS)\n",
      "            )\n",
      "            (3): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 379.09 us = 0.23% latency, 22.3 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.63 us = 0.05% latency, 35.39 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.44 us = 0.05% latency, 35.93 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.99 us = 0.04% latency, 45.46 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.82 us = 0.02% latency, 17.28 MFLOPS)\n",
      "            )\n",
      "            (4): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 375.27 us = 0.23% latency, 22.53 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.59 us = 0.05% latency, 34.97 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.49 us = 0.05% latency, 36.37 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.08 us = 0.04% latency, 46.9 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.29 us = 0.02% latency, 17.08 MFLOPS)\n",
      "            )\n",
      "            (5): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 375.99 us = 0.23% latency, 22.49 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.87 us = 0.05% latency, 35.28 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.2 us = 0.05% latency, 36.04 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.27 us = 0.04% latency, 45.99 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.58 us = 0.02% latency, 17.38 MFLOPS)\n",
      "            )\n",
      "            (6): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 375.75 us = 0.23% latency, 22.5 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 84.88 us = 0.05% latency, 33.2 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 76.29 us = 0.05% latency, 36.94 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 59.13 us = 0.04% latency, 47.66 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.1 us = 0.02% latency, 17.6 MFLOPS)\n",
      "            )\n",
      "            (7): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 379.32 us = 0.23% latency, 22.29 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.59 us = 0.05% latency, 34.97 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.92 us = 0.05% latency, 35.71 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.75 us = 0.04% latency, 45.64 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.77 us = 0.02% latency, 16.88 MFLOPS)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 99.18 us = 0.06% latency, 0 FLOPS)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 92.03 us = 0.06% latency, 0 FLOPS)\n",
      "      )\n",
      "      (15): Qwen2DecoderLayer(\n",
      "        50.62 M = 2.76% Params, 4.6 GMACs = 2.42% MACs, 6.75 ms = 4.09% latency, 1.37 TFLOPS\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          16.78 M = 0.91% Params, 4.56 GMACs = 2.4% MACs, 1.72 ms = 1.04% latency, 5.32 TFLOPS\n",
      "          (q_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 316.62 us = 0.19% latency, 6.78 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 299.93 us = 0.18% latency, 7.16 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 77.49 us = 0.05% latency, 27.71 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear(4.19 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 73.91 us = 0.04% latency, 29.06 TFLOPS, in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding(0 = 0% Params, 0 MACs = 0% MACs, 40.53 us = 0.02% latency, 0 FLOPS)\n",
      "        )\n",
      "        (mlp): SteelSoftMoEV3(\n",
      "          33.83 M = 1.84% Params, 33.82 MMACs = 0.02% MACs, 4.42 ms = 2.68% latency, 20.98 GFLOPS\n",
      "          (experts): ModuleList(\n",
      "            (0): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 410.08 us = 0.25% latency, 20.62 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 93.22 us = 0.06% latency, 30.23 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.54 us = 0.05% latency, 34.56 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.23 us = 0.04% latency, 45.29 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 43.87 us = 0.03% latency, 15.68 MFLOPS)\n",
      "            )\n",
      "            (1): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 393.63 us = 0.24% latency, 21.48 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.59 us = 0.05% latency, 34.97 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.44 us = 0.05% latency, 35.93 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 74.86 us = 0.05% latency, 37.64 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.77 us = 0.02% latency, 16.88 MFLOPS)\n",
      "            )\n",
      "            (2): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 470.16 us = 0.28% latency, 17.98 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.25 us = 0.05% latency, 34.26 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 84.88 us = 0.05% latency, 33.2 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.23 us = 0.04% latency, 45.29 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 119.45 us = 0.07% latency, 5.76 MFLOPS)\n",
      "            )\n",
      "            (3): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 379.8 us = 0.23% latency, 22.26 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.11 us = 0.05% latency, 35.18 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.92 us = 0.05% latency, 35.71 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.99 us = 0.04% latency, 45.46 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.53 us = 0.02% latency, 16.97 MFLOPS)\n",
      "            )\n",
      "            (4): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 394.34 us = 0.24% latency, 21.44 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 88.21 us = 0.05% latency, 31.95 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.02 us = 0.05% latency, 34.36 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.94 us = 0.04% latency, 44.77 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.96 us = 0.03% latency, 16.4 MFLOPS)\n",
      "            )\n",
      "            (5): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 374.56 us = 0.23% latency, 22.57 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.11 us = 0.05% latency, 35.18 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.96 us = 0.05% latency, 36.15 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.04 us = 0.04% latency, 46.17 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.58 us = 0.02% latency, 17.38 MFLOPS)\n",
      "            )\n",
      "            (6): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 379.56 us = 0.23% latency, 22.28 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.35 us = 0.05% latency, 35.07 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.87 us = 0.05% latency, 35.28 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.32 us = 0.04% latency, 46.72 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 42.68 us = 0.03% latency, 16.12 MFLOPS)\n",
      "            )\n",
      "            (7): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 374.79 us = 0.23% latency, 22.56 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.87 us = 0.05% latency, 35.28 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.01 us = 0.05% latency, 36.59 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.8 us = 0.04% latency, 46.35 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.29 us = 0.02% latency, 17.08 MFLOPS)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 99.42 us = 0.06% latency, 0 FLOPS)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 97.27 us = 0.06% latency, 0 FLOPS)\n",
      "      )\n",
      "      (16): Qwen2DecoderLayer(\n",
      "        50.62 M = 2.76% Params, 4.6 GMACs = 2.42% MACs, 6.72 ms = 4.07% latency, 1.37 TFLOPS\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          16.78 M = 0.91% Params, 4.56 GMACs = 2.4% MACs, 1.76 ms = 1.07% latency, 5.17 TFLOPS\n",
      "          (q_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 316.14 us = 0.19% latency, 6.79 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 78.44 us = 0.05% latency, 27.38 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 343.56 us = 0.21% latency, 6.25 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear(4.19 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 75.34 us = 0.05% latency, 28.5 TFLOPS, in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding(0 = 0% Params, 0 MACs = 0% MACs, 40.77 us = 0.02% latency, 0 FLOPS)\n",
      "        )\n",
      "        (mlp): SteelSoftMoEV3(\n",
      "          33.83 M = 1.84% Params, 33.82 MMACs = 0.02% MACs, 4.35 ms = 2.63% latency, 21.36 GFLOPS\n",
      "          (experts): ModuleList(\n",
      "            (0): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 409.13 us = 0.25% latency, 20.67 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 92.51 us = 0.06% latency, 30.46 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.35 us = 0.05% latency, 35.07 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.94 us = 0.04% latency, 44.77 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 44.11 us = 0.03% latency, 15.6 MFLOPS)\n",
      "            )\n",
      "            (1): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 383.14 us = 0.23% latency, 22.07 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.73 us = 0.05% latency, 34.06 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.68 us = 0.05% latency, 35.82 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.51 us = 0.04% latency, 45.81 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.53 us = 0.02% latency, 16.97 MFLOPS)\n",
      "            )\n",
      "            (2): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 390.05 us = 0.24% latency, 21.68 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.11 us = 0.05% latency, 35.18 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.11 us = 0.05% latency, 35.18 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 64.13 us = 0.04% latency, 43.94 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 46.49 us = 0.03% latency, 14.8 MFLOPS)\n",
      "            )\n",
      "            (3): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 383.38 us = 0.23% latency, 22.05 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 83.21 us = 0.05% latency, 33.87 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.39 us = 0.05% latency, 35.49 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.27 us = 0.04% latency, 45.99 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.82 us = 0.02% latency, 17.28 MFLOPS)\n",
      "            )\n",
      "            (4): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 399.35 us = 0.24% latency, 21.17 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.06 us = 0.05% latency, 34.76 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 98.94 us = 0.06% latency, 28.48 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.04 us = 0.04% latency, 46.17 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.58 us = 0.02% latency, 17.38 MFLOPS)\n",
      "            )\n",
      "            (5): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 378.37 us = 0.23% latency, 22.35 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.06 us = 0.05% latency, 34.76 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.15 us = 0.05% latency, 35.6 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.8 us = 0.04% latency, 46.35 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.82 us = 0.02% latency, 17.28 MFLOPS)\n",
      "            )\n",
      "            (6): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 371.46 us = 0.22% latency, 22.76 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.87 us = 0.05% latency, 35.28 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.49 us = 0.05% latency, 36.37 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 59.37 us = 0.04% latency, 47.47 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 38.86 us = 0.02% latency, 17.7 MFLOPS)\n",
      "            )\n",
      "            (7): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 375.03 us = 0.23% latency, 22.54 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.87 us = 0.05% latency, 35.28 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.72 us = 0.05% latency, 36.26 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 59.84 us = 0.04% latency, 47.09 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.29 us = 0.02% latency, 17.08 MFLOPS)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 97.27 us = 0.06% latency, 0 FLOPS)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 91.79 us = 0.06% latency, 0 FLOPS)\n",
      "      )\n",
      "      (17): Qwen2DecoderLayer(\n",
      "        50.62 M = 2.76% Params, 4.6 GMACs = 2.42% MACs, 6.45 ms = 3.9% latency, 1.43 TFLOPS\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          16.78 M = 0.91% Params, 4.56 GMACs = 2.4% MACs, 1.52 ms = 0.92% latency, 6.02 TFLOPS\n",
      "          (q_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 320.43 us = 0.19% latency, 6.7 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 77.96 us = 0.05% latency, 27.54 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 300.17 us = 0.18% latency, 7.15 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear(4.19 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 74.86 us = 0.05% latency, 28.69 TFLOPS, in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding(0 = 0% Params, 0 MACs = 0% MACs, 40.05 us = 0.02% latency, 0 FLOPS)\n",
      "        )\n",
      "        (mlp): SteelSoftMoEV3(\n",
      "          33.83 M = 1.84% Params, 33.82 MMACs = 0.02% MACs, 4.57 ms = 2.77% latency, 20.3 GFLOPS\n",
      "          (experts): ModuleList(\n",
      "            (0): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 406.74 us = 0.25% latency, 20.79 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 91.08 us = 0.06% latency, 30.94 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.59 us = 0.05% latency, 34.97 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.23 us = 0.04% latency, 45.29 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 43.87 us = 0.03% latency, 15.68 MFLOPS)\n",
      "            )\n",
      "            (1): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 380.52 us = 0.23% latency, 22.22 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.06 us = 0.05% latency, 34.76 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.68 us = 0.05% latency, 35.82 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.51 us = 0.04% latency, 45.81 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.53 us = 0.02% latency, 16.97 MFLOPS)\n",
      "            )\n",
      "            (2): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 374.56 us = 0.23% latency, 22.57 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.63 us = 0.05% latency, 35.39 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 76.77 us = 0.05% latency, 36.71 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 59.37 us = 0.04% latency, 47.47 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.53 us = 0.02% latency, 16.97 MFLOPS)\n",
      "            )\n",
      "            (3): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 375.51 us = 0.23% latency, 22.52 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.15 us = 0.05% latency, 35.6 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.25 us = 0.05% latency, 36.48 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.32 us = 0.04% latency, 46.72 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.05 us = 0.02% latency, 17.18 MFLOPS)\n",
      "            )\n",
      "            (4): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 375.03 us = 0.23% latency, 22.54 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.87 us = 0.05% latency, 35.28 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.96 us = 0.05% latency, 36.15 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.8 us = 0.04% latency, 46.35 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.58 us = 0.02% latency, 17.38 MFLOPS)\n",
      "            )\n",
      "            (5): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 375.03 us = 0.23% latency, 22.54 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.63 us = 0.05% latency, 35.39 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.15 us = 0.05% latency, 35.6 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.8 us = 0.04% latency, 46.35 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.34 us = 0.02% latency, 17.49 MFLOPS)\n",
      "            )\n",
      "            (6): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 372.41 us = 0.23% latency, 22.7 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.92 us = 0.05% latency, 35.71 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 76.53 us = 0.05% latency, 36.82 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.08 us = 0.04% latency, 46.9 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.82 us = 0.02% latency, 17.28 MFLOPS)\n",
      "            )\n",
      "            (7): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 371.69 us = 0.23% latency, 22.75 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.92 us = 0.05% latency, 35.71 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.49 us = 0.05% latency, 36.37 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.32 us = 0.04% latency, 46.72 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.58 us = 0.02% latency, 17.38 MFLOPS)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 97.04 us = 0.06% latency, 0 FLOPS)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 92.27 us = 0.06% latency, 0 FLOPS)\n",
      "      )\n",
      "      (18): Qwen2DecoderLayer(\n",
      "        50.62 M = 2.76% Params, 4.6 GMACs = 2.42% MACs, 6.81 ms = 4.12% latency, 1.35 TFLOPS\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          16.78 M = 0.91% Params, 4.56 GMACs = 2.4% MACs, 1.73 ms = 1.05% latency, 5.27 TFLOPS\n",
      "          (q_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 317.81 us = 0.19% latency, 6.76 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 310.66 us = 0.19% latency, 6.91 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 76.53 us = 0.05% latency, 28.06 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear(4.19 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 75.82 us = 0.05% latency, 28.32 TFLOPS, in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding(0 = 0% Params, 0 MACs = 0% MACs, 39.34 us = 0.02% latency, 0 FLOPS)\n",
      "        )\n",
      "        (mlp): SteelSoftMoEV3(\n",
      "          33.83 M = 1.84% Params, 33.82 MMACs = 0.02% MACs, 4.44 ms = 2.69% latency, 20.88 GFLOPS\n",
      "          (experts): ModuleList(\n",
      "            (0): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 478.27 us = 0.29% latency, 17.68 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 136.38 us = 0.08% latency, 20.66 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 88.93 us = 0.05% latency, 31.69 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 64.61 us = 0.04% latency, 43.62 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 49.11 us = 0.03% latency, 14.01 MFLOPS)\n",
      "            )\n",
      "            (1): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 404.12 us = 0.24% latency, 20.92 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.73 us = 0.05% latency, 34.06 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 83.92 us = 0.05% latency, 33.58 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.27 us = 0.04% latency, 45.99 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.48 us = 0.03% latency, 16.58 MFLOPS)\n",
      "            )\n",
      "            (2): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 379.8 us = 0.23% latency, 22.26 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.11 us = 0.05% latency, 35.18 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.68 us = 0.05% latency, 35.82 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.04 us = 0.04% latency, 46.17 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.53 us = 0.02% latency, 16.97 MFLOPS)\n",
      "            )\n",
      "            (3): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 379.09 us = 0.23% latency, 22.3 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.73 us = 0.05% latency, 34.06 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.96 us = 0.05% latency, 36.15 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.8 us = 0.04% latency, 46.35 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.1 us = 0.02% latency, 17.6 MFLOPS)\n",
      "            )\n",
      "            (4): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 377.42 us = 0.23% latency, 22.4 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.11 us = 0.05% latency, 35.18 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.49 us = 0.05% latency, 36.37 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.56 us = 0.04% latency, 46.53 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.1 us = 0.02% latency, 17.6 MFLOPS)\n",
      "            )\n",
      "            (5): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 378.13 us = 0.23% latency, 22.36 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.59 us = 0.05% latency, 34.97 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.68 us = 0.05% latency, 35.82 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.56 us = 0.04% latency, 46.53 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.34 us = 0.02% latency, 17.49 MFLOPS)\n",
      "            )\n",
      "            (6): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 393.87 us = 0.24% latency, 21.47 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 85.35 us = 0.05% latency, 33.02 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 83.45 us = 0.05% latency, 33.77 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.7 us = 0.04% latency, 44.94 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.72 us = 0.03% latency, 16.49 MFLOPS)\n",
      "            )\n",
      "            (7): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 383.14 us = 0.23% latency, 22.07 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.06 us = 0.05% latency, 34.76 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.92 us = 0.05% latency, 35.71 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.27 us = 0.04% latency, 45.99 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.01 us = 0.02% latency, 16.78 MFLOPS)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 95.84 us = 0.06% latency, 0 FLOPS)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 117.06 us = 0.07% latency, 0 FLOPS)\n",
      "      )\n",
      "      (19): Qwen2DecoderLayer(\n",
      "        50.62 M = 2.76% Params, 4.6 GMACs = 2.42% MACs, 6.7 ms = 4.06% latency, 1.38 TFLOPS\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          16.78 M = 0.91% Params, 4.56 GMACs = 2.4% MACs, 1.75 ms = 1.06% latency, 5.23 TFLOPS\n",
      "          (q_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 316.14 us = 0.19% latency, 6.79 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 77.25 us = 0.05% latency, 27.8 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 314.47 us = 0.19% latency, 6.83 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear(4.19 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 81.3 us = 0.05% latency, 26.41 TFLOPS, in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding(0 = 0% Params, 0 MACs = 0% MACs, 39.82 us = 0.02% latency, 0 FLOPS)\n",
      "        )\n",
      "        (mlp): SteelSoftMoEV3(\n",
      "          33.83 M = 1.84% Params, 33.82 MMACs = 0.02% MACs, 4.34 ms = 2.63% latency, 21.36 GFLOPS\n",
      "          (experts): ModuleList(\n",
      "            (0): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 415.56 us = 0.25% latency, 20.35 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 93.22 us = 0.06% latency, 30.23 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 83.21 us = 0.05% latency, 33.87 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 63.42 us = 0.04% latency, 44.44 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 43.39 us = 0.03% latency, 15.86 MFLOPS)\n",
      "            )\n",
      "            (1): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 388.86 us = 0.24% latency, 21.74 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 84.4 us = 0.05% latency, 33.39 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.87 us = 0.05% latency, 35.28 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.8 us = 0.04% latency, 46.35 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.25 us = 0.02% latency, 16.68 MFLOPS)\n",
      "            )\n",
      "            (2): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 377.66 us = 0.23% latency, 22.39 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.82 us = 0.05% latency, 34.87 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.96 us = 0.05% latency, 36.15 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.75 us = 0.04% latency, 45.64 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.82 us = 0.02% latency, 17.28 MFLOPS)\n",
      "            )\n",
      "            (3): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 385.05 us = 0.23% latency, 21.96 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 85.35 us = 0.05% latency, 33.02 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.92 us = 0.05% latency, 35.71 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.32 us = 0.04% latency, 46.72 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.77 us = 0.02% latency, 16.88 MFLOPS)\n",
      "            )\n",
      "            (4): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 392.2 us = 0.24% latency, 21.56 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.68 us = 0.05% latency, 35.82 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.87 us = 0.05% latency, 35.28 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.27 us = 0.04% latency, 45.99 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 54.84 us = 0.03% latency, 12.55 MFLOPS)\n",
      "            )\n",
      "            (5): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 375.75 us = 0.23% latency, 22.5 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.87 us = 0.05% latency, 35.28 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.01 us = 0.05% latency, 36.59 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.75 us = 0.04% latency, 45.64 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 38.62 us = 0.02% latency, 17.81 MFLOPS)\n",
      "            )\n",
      "            (6): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 375.51 us = 0.23% latency, 22.52 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.59 us = 0.05% latency, 34.97 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.72 us = 0.05% latency, 36.26 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.32 us = 0.04% latency, 46.72 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.58 us = 0.02% latency, 17.38 MFLOPS)\n",
      "            )\n",
      "            (7): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 375.27 us = 0.23% latency, 22.53 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.35 us = 0.05% latency, 35.07 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.01 us = 0.05% latency, 36.59 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.51 us = 0.04% latency, 45.81 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.29 us = 0.02% latency, 17.08 MFLOPS)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 99.18 us = 0.06% latency, 0 FLOPS)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 92.51 us = 0.06% latency, 0 FLOPS)\n",
      "      )\n",
      "      (20): Qwen2DecoderLayer(\n",
      "        50.62 M = 2.76% Params, 4.6 GMACs = 2.42% MACs, 6.46 ms = 3.91% latency, 1.43 TFLOPS\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          16.78 M = 0.91% Params, 4.56 GMACs = 2.4% MACs, 1.5 ms = 0.91% latency, 6.07 TFLOPS\n",
      "          (q_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 318.53 us = 0.19% latency, 6.74 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 78.68 us = 0.05% latency, 27.29 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 297.31 us = 0.18% latency, 7.22 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear(4.19 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 75.82 us = 0.05% latency, 28.32 TFLOPS, in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding(0 = 0% Params, 0 MACs = 0% MACs, 41.48 us = 0.03% latency, 0 FLOPS)\n",
      "        )\n",
      "        (mlp): SteelSoftMoEV3(\n",
      "          33.83 M = 1.84% Params, 33.82 MMACs = 0.02% MACs, 4.6 ms = 2.78% latency, 20.19 GFLOPS\n",
      "          (experts): ModuleList(\n",
      "            (0): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 411.51 us = 0.25% latency, 20.55 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 93.94 us = 0.06% latency, 30 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.78 us = 0.05% latency, 34.46 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.99 us = 0.04% latency, 45.46 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 44.58 us = 0.03% latency, 15.43 MFLOPS)\n",
      "            )\n",
      "            (1): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 382.9 us = 0.23% latency, 22.08 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 83.68 us = 0.05% latency, 33.67 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.44 us = 0.05% latency, 35.93 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.75 us = 0.04% latency, 45.64 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.34 us = 0.02% latency, 17.49 MFLOPS)\n",
      "            )\n",
      "            (2): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 384.57 us = 0.23% latency, 21.99 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.59 us = 0.05% latency, 34.97 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 86.78 us = 0.05% latency, 32.47 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.32 us = 0.04% latency, 46.72 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.58 us = 0.02% latency, 17.38 MFLOPS)\n",
      "            )\n",
      "            (3): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 372.89 us = 0.23% latency, 22.67 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.11 us = 0.05% latency, 35.18 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.01 us = 0.05% latency, 36.59 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.56 us = 0.04% latency, 46.53 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.58 us = 0.02% latency, 17.38 MFLOPS)\n",
      "            )\n",
      "            (4): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 370.98 us = 0.22% latency, 22.79 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.68 us = 0.05% latency, 35.82 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.49 us = 0.05% latency, 36.37 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.8 us = 0.04% latency, 46.35 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.29 us = 0.02% latency, 17.08 MFLOPS)\n",
      "            )\n",
      "            (5): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 371.69 us = 0.23% latency, 22.75 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.63 us = 0.05% latency, 35.39 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.49 us = 0.05% latency, 36.37 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 59.84 us = 0.04% latency, 47.09 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.58 us = 0.02% latency, 17.38 MFLOPS)\n",
      "            )\n",
      "            (6): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 370.74 us = 0.22% latency, 22.81 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.44 us = 0.05% latency, 35.93 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.25 us = 0.05% latency, 36.48 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 59.37 us = 0.04% latency, 47.47 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.05 us = 0.02% latency, 17.18 MFLOPS)\n",
      "            )\n",
      "            (7): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 370.74 us = 0.22% latency, 22.81 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.87 us = 0.05% latency, 35.28 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 75.82 us = 0.05% latency, 37.17 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 59.84 us = 0.04% latency, 47.09 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.34 us = 0.02% latency, 17.49 MFLOPS)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 96.8 us = 0.06% latency, 0 FLOPS)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 92.03 us = 0.06% latency, 0 FLOPS)\n",
      "      )\n",
      "      (21): Qwen2DecoderLayer(\n",
      "        50.62 M = 2.76% Params, 4.6 GMACs = 2.42% MACs, 6.68 ms = 4.05% latency, 1.38 TFLOPS\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          16.78 M = 0.91% Params, 4.56 GMACs = 2.4% MACs, 1.73 ms = 1.05% latency, 5.28 TFLOPS\n",
      "          (q_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 321.39 us = 0.19% latency, 6.68 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 302.79 us = 0.18% latency, 7.09 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 77.01 us = 0.05% latency, 27.89 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear(4.19 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 74.63 us = 0.05% latency, 28.78 TFLOPS, in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding(0 = 0% Params, 0 MACs = 0% MACs, 39.82 us = 0.02% latency, 0 FLOPS)\n",
      "        )\n",
      "        (mlp): SteelSoftMoEV3(\n",
      "          33.83 M = 1.84% Params, 33.82 MMACs = 0.02% MACs, 4.34 ms = 2.63% latency, 21.39 GFLOPS\n",
      "          (experts): ModuleList(\n",
      "            (0): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 410.32 us = 0.25% latency, 20.61 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 91.79 us = 0.06% latency, 30.7 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.02 us = 0.05% latency, 34.36 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 63.66 us = 0.04% latency, 44.27 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 44.11 us = 0.03% latency, 15.6 MFLOPS)\n",
      "            )\n",
      "            (1): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 400.54 us = 0.24% latency, 21.11 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.73 us = 0.05% latency, 34.06 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 93.46 us = 0.06% latency, 30.15 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.47 us = 0.04% latency, 45.11 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.82 us = 0.02% latency, 17.28 MFLOPS)\n",
      "            )\n",
      "            (2): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 379.09 us = 0.23% latency, 22.3 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.59 us = 0.05% latency, 34.97 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.68 us = 0.05% latency, 35.82 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.75 us = 0.04% latency, 45.64 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.58 us = 0.02% latency, 17.38 MFLOPS)\n",
      "            )\n",
      "            (3): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 382.66 us = 0.23% latency, 22.09 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 85.59 us = 0.05% latency, 32.92 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.2 us = 0.05% latency, 36.04 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.8 us = 0.04% latency, 46.35 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.34 us = 0.02% latency, 17.49 MFLOPS)\n",
      "            )\n",
      "            (4): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 374.79 us = 0.23% latency, 22.56 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.92 us = 0.05% latency, 35.71 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.39 us = 0.05% latency, 35.49 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.51 us = 0.04% latency, 45.81 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.1 us = 0.02% latency, 17.6 MFLOPS)\n",
      "            )\n",
      "            (5): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 368.12 us = 0.22% latency, 22.97 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.87 us = 0.05% latency, 35.28 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 76.77 us = 0.05% latency, 36.71 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 59.37 us = 0.04% latency, 47.47 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 38.62 us = 0.02% latency, 17.81 MFLOPS)\n",
      "            )\n",
      "            (6): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 376.7 us = 0.23% latency, 22.44 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.2 us = 0.05% latency, 36.04 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.78 us = 0.05% latency, 34.46 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.23 us = 0.04% latency, 45.29 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.34 us = 0.02% latency, 17.49 MFLOPS)\n",
      "            )\n",
      "            (7): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 376.22 us = 0.23% latency, 22.47 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.44 us = 0.05% latency, 35.93 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.72 us = 0.05% latency, 36.26 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.51 us = 0.04% latency, 45.81 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.58 us = 0.02% latency, 17.38 MFLOPS)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 95.84 us = 0.06% latency, 0 FLOPS)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 92.51 us = 0.06% latency, 0 FLOPS)\n",
      "      )\n",
      "      (22): Qwen2DecoderLayer(\n",
      "        50.62 M = 2.76% Params, 4.6 GMACs = 2.42% MACs, 6.67 ms = 4.04% latency, 1.38 TFLOPS\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          16.78 M = 0.91% Params, 4.56 GMACs = 2.4% MACs, 1.74 ms = 1.05% latency, 5.25 TFLOPS\n",
      "          (q_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 318.77 us = 0.19% latency, 6.74 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 77.49 us = 0.05% latency, 27.71 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 308.75 us = 0.19% latency, 6.96 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear(4.19 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 75.34 us = 0.05% latency, 28.5 TFLOPS, in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding(0 = 0% Params, 0 MACs = 0% MACs, 42.68 us = 0.03% latency, 0 FLOPS)\n",
      "        )\n",
      "        (mlp): SteelSoftMoEV3(\n",
      "          33.83 M = 1.84% Params, 33.82 MMACs = 0.02% MACs, 4.32 ms = 2.61% latency, 21.49 GFLOPS\n",
      "          (experts): ModuleList(\n",
      "            (0): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 406.03 us = 0.25% latency, 20.82 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 91.08 us = 0.06% latency, 30.94 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.78 us = 0.05% latency, 34.46 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.51 us = 0.04% latency, 45.81 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 43.63 us = 0.03% latency, 15.77 MFLOPS)\n",
      "            )\n",
      "            (1): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 379.56 us = 0.23% latency, 22.28 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.3 us = 0.05% latency, 34.66 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.68 us = 0.05% latency, 35.82 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.27 us = 0.04% latency, 45.99 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.29 us = 0.02% latency, 17.08 MFLOPS)\n",
      "            )\n",
      "            (2): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 375.99 us = 0.23% latency, 22.49 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.11 us = 0.05% latency, 35.18 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.25 us = 0.05% latency, 36.48 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 59.6 us = 0.04% latency, 47.28 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.1 us = 0.02% latency, 17.6 MFLOPS)\n",
      "            )\n",
      "            (3): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 385.05 us = 0.23% latency, 21.96 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 85.35 us = 0.05% latency, 33.02 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.2 us = 0.05% latency, 36.04 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.27 us = 0.04% latency, 45.99 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.77 us = 0.02% latency, 16.88 MFLOPS)\n",
      "            )\n",
      "            (4): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 387.19 us = 0.23% latency, 21.84 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.39 us = 0.05% latency, 35.49 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 87.26 us = 0.05% latency, 32.29 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.75 us = 0.04% latency, 45.64 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.05 us = 0.02% latency, 17.18 MFLOPS)\n",
      "            )\n",
      "            (5): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 377.18 us = 0.23% latency, 22.42 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.11 us = 0.05% latency, 35.18 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.44 us = 0.05% latency, 35.93 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.8 us = 0.04% latency, 46.35 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.82 us = 0.02% latency, 17.28 MFLOPS)\n",
      "            )\n",
      "            (6): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 387.91 us = 0.23% latency, 21.8 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 84.16 us = 0.05% latency, 33.48 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.73 us = 0.05% latency, 34.06 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 61.04 us = 0.04% latency, 46.17 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.01 us = 0.02% latency, 16.78 MFLOPS)\n",
      "            )\n",
      "            (7): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 372.41 us = 0.23% latency, 22.7 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.92 us = 0.05% latency, 35.71 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.49 us = 0.05% latency, 36.37 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 59.6 us = 0.04% latency, 47.28 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.82 us = 0.02% latency, 17.28 MFLOPS)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 103.47 us = 0.06% latency, 0 FLOPS)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 92.98 us = 0.06% latency, 0 FLOPS)\n",
      "      )\n",
      "      (23): Qwen2DecoderLayer(\n",
      "        50.62 M = 2.76% Params, 4.6 GMACs = 2.42% MACs, 6.48 ms = 3.92% latency, 1.42 TFLOPS\n",
      "        (self_attn): Qwen2SdpaAttention(\n",
      "          16.78 M = 0.91% Params, 4.56 GMACs = 2.4% MACs, 1.51 ms = 0.92% latency, 6.03 TFLOPS\n",
      "          (q_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 323.3 us = 0.2% latency, 6.64 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (k_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 77.72 us = 0.05% latency, 27.63 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (v_proj): Linear(4.2 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 302.31 us = 0.18% latency, 7.1 TFLOPS, in_features=2048, out_features=2048, bias=True)\n",
      "          (o_proj): Linear(4.19 M = 0.23% Params, 1.07 GMACs = 0.57% MACs, 75.58 us = 0.05% latency, 28.41 TFLOPS, in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): Qwen2RotaryEmbedding(0 = 0% Params, 0 MACs = 0% MACs, 41.01 us = 0.02% latency, 0 FLOPS)\n",
      "        )\n",
      "        (mlp): SteelSoftMoEV3(\n",
      "          33.83 M = 1.84% Params, 33.82 MMACs = 0.02% MACs, 4.61 ms = 2.79% latency, 20.13 GFLOPS\n",
      "          (experts): ModuleList(\n",
      "            (0): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 409.36 us = 0.25% latency, 20.65 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 92.27 us = 0.06% latency, 30.54 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.3 us = 0.05% latency, 34.66 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.7 us = 0.04% latency, 44.94 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 44.58 us = 0.03% latency, 15.43 MFLOPS)\n",
      "            )\n",
      "            (1): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 385.52 us = 0.23% latency, 21.93 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 82.25 us = 0.05% latency, 34.26 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.39 us = 0.05% latency, 35.49 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.32 us = 0.04% latency, 46.72 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 41.48 us = 0.03% latency, 16.58 MFLOPS)\n",
      "            )\n",
      "            (2): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 377.66 us = 0.23% latency, 22.39 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 81.54 us = 0.05% latency, 34.56 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.72 us = 0.05% latency, 36.26 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.08 us = 0.04% latency, 46.9 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.82 us = 0.02% latency, 17.28 MFLOPS)\n",
      "            )\n",
      "            (3): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 374.56 us = 0.23% latency, 22.57 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.87 us = 0.05% latency, 35.28 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.25 us = 0.05% latency, 36.48 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.56 us = 0.04% latency, 46.53 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.34 us = 0.02% latency, 17.49 MFLOPS)\n",
      "            )\n",
      "            (4): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 382.66 us = 0.23% latency, 22.09 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.92 us = 0.05% latency, 35.71 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 78.68 us = 0.05% latency, 35.82 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.8 us = 0.04% latency, 46.35 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 44.35 us = 0.03% latency, 15.51 MFLOPS)\n",
      "            )\n",
      "            (5): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 376.7 us = 0.23% latency, 22.44 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.63 us = 0.05% latency, 35.39 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.96 us = 0.05% latency, 36.15 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 60.56 us = 0.04% latency, 46.53 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 40.53 us = 0.02% latency, 16.97 MFLOPS)\n",
      "            )\n",
      "            (6): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 376.7 us = 0.23% latency, 22.44 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 80.11 us = 0.05% latency, 35.18 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 77.96 us = 0.05% latency, 36.15 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 62.94 us = 0.04% latency, 44.77 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.34 us = 0.02% latency, 17.49 MFLOPS)\n",
      "            )\n",
      "            (7): SteelMLP(\n",
      "              4.23 M = 0.23% Params, 4.23 MMACs = 0% MACs, 369.07 us = 0.22% latency, 22.91 GFLOPS\n",
      "              (gate_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 79.63 us = 0.05% latency, 35.39 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (up_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 76.29 us = 0.05% latency, 36.94 GFLOPS, in_features=2048, out_features=688, bias=False)\n",
      "              (down_proj): Linear(1.41 M = 0.08% Params, 1.41 MMACs = 0% MACs, 58.89 us = 0.04% latency, 47.85 GFLOPS, in_features=688, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 39.34 us = 0.02% latency, 17.49 MFLOPS)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 98.47 us = 0.06% latency, 0 FLOPS)\n",
      "        (post_attention_layernorm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 90.84 us = 0.05% latency, 0 FLOPS)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen2RMSNorm(2.05 K = 0% Params, 0 MACs = 0% MACs, 95.37 us = 0.06% latency, 0 FLOPS)\n",
      "  )\n",
      "  (lm_head): Linear(311.16 M = 16.94% Params, 79.66 GMACs = 41.93% MACs, 781.06 us = 0.47% latency, 203.97 TFLOPS, in_features=2048, out_features=151936, bias=False)\n",
      ")\n",
      "------------------------------------------------------------------------------\n",
      "[2024-05-12 03:36:43,445] [INFO] [profiler.py:226:end_profile] Flops profiler finished\n",
      "FLOPs: 380.59 G\n",
      "MACs: 189.99 GMACs\n",
      "Params: 1.84 B\n",
      "tensor([[[ 0.5508, -0.6172,  0.6016,  ..., -0.0332,  1.0078,  0.0332],\n",
      "         [ 0.7695, -0.7266,  0.5000,  ..., -0.0255,  0.8750, -0.1001],\n",
      "         [ 0.6836, -0.7148,  0.3359,  ...,  0.0503,  0.7773, -0.4180],\n",
      "         ...,\n",
      "         [ 0.1895, -0.6484,  0.4336,  ...,  0.6758, -0.2314, -0.4434],\n",
      "         [ 0.1855, -0.6211,  0.4570,  ...,  0.6797, -0.2363, -0.4512],\n",
      "         [ 0.1875, -0.6172,  0.4121,  ...,  0.6836, -0.1992, -0.4336]]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# RuntimeError: FlashAttention only support fp16 and bf16 data type\n",
    "seed = 666\n",
    "torch.manual_seed(seed)  # 设置随机种子\n",
    "torch.cuda.manual_seed(seed)  # 设置CUDA的随机种子\n",
    "torch.cuda.manual_seed_all(seed)  # 如果使用多个GPU，设置所有GPU的随机种子\n",
    "np.random.seed(seed)\n",
    "fake_input = torch.randint(1, 10000, (1, 256),dtype=torch.long, device=model.device)\n",
    "input_dict = {\"input_ids\": fake_input, \"labels\": fake_input.clone()}\n",
    "# model = model.to(torch.float32)\n",
    "# flops, macs, params = get_model_profile(model, kwargs=input_dict, print_profile=True, detailed=True)\n",
    "# print(\"FLOPs:\", flops)\n",
    "# print(\"MACs:\", macs)\n",
    "# print(\"Params:\", params)\n",
    "# output = model(fake_input)\n",
    "# print(output.logits[:,:,:10])\n",
    "# print(\"*\"*20)\n",
    "#===========================================================\n",
    "model = model.to(torch.bfloat16)\n",
    "flops, macs, params = get_model_profile(model, kwargs=input_dict, print_profile=True, detailed=True)\n",
    "print(\"FLOPs:\", flops)\n",
    "print(\"MACs:\", macs)\n",
    "print(\"Params:\", params)\n",
    "output = model(fake_input)\n",
    "print(output.logits[:,:,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试 rms+rope一致性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flash_attn.layers.rotary import apply_rotary_emb_func as __apply_rotary_emb_func\n",
    "from flash_attn.ops.rms_norm import rms_norm as __rms_norm\n",
    "from torch import nn\n",
    "import torch\n",
    "class Qwen2RMSNorm(nn.Module):\n",
    "    def __init__(self, hidden_size, eps=1e-6):\n",
    "        \"\"\"\n",
    "        Qwen2RMSNorm is equivalent to T5LayerNorm\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "        self.variance_epsilon = eps\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        input_dtype = hidden_states.dtype\n",
    "        hidden_states = hidden_states.to(torch.float32)\n",
    "        variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
    "        hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)\n",
    "        return self.weight * hidden_states.to(input_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "tensor([[ 0.3965, -0.6992, -1.8359, -0.8242, -1.3672,  1.4688,  0.1836,  1.0703,\n",
      "         -1.0859, -1.9062, -0.2969, -0.3633, -0.9648, -0.0815,  0.1748, -0.3105]],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor([[ 0.3965, -0.6992, -1.8359, -0.8242, -1.3672,  1.4688,  0.1836,  1.0703,\n",
      "         -1.0859, -1.9062, -0.2969, -0.3633, -0.9648, -0.0815,  0.1748, -0.3105]],\n",
      "       device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<DropoutAddLayerNormFnBackward>)\n"
     ]
    }
   ],
   "source": [
    "eps = 1e-6\n",
    "dim = 16\n",
    "input  = torch.randn([1,dim],device=\"cuda:0\",dtype=torch.bfloat16)\n",
    "torch_rmsnorm = Qwen2RMSNorm(dim, eps=eps).to(\"cuda:0\")\n",
    "print(torch_rmsnorm.weight.dtype)\n",
    "output1 = torch_rmsnorm(input)\n",
    "#=\n",
    "output2 = __rms_norm(input, torch_rmsnorm.weight, torch_rmsnorm.variance_epsilon)\n",
    "print(output1)\n",
    "print(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test recurrentgemma\n",
    "from transformers import AutoConfig\n",
    "from recurrentgemma.modeling_recurrent_gemma import RecurrentGemmaForCausalLM\n",
    "config = AutoConfig.from_pretrained(\"./recurrentgemma\",trust_remote_code=True)\n",
    "model = RecurrentGemmaForCausalLM(config)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/calfa100/gqs/Steel-LLM/pretrain_modify_from_TinyLlama/model\n",
      "zhanshijin: use torch rmsnorm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'optimizer': {'state': {'lm_head.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-1.0488e-06, -7.1102e-06,  1.1775e-06,  ...,  4.8751e-06,\n",
       "              7.7625e-07, -1.2856e-06],\n",
       "            [ 3.5733e-07,  2.1447e-06,  1.1023e-05,  ...,  2.0839e-06,\n",
       "             -3.6291e-06,  3.7009e-06],\n",
       "            [-1.6473e-06, -1.7232e-06, -5.8710e-07,  ...,  8.9671e-07,\n",
       "              1.4101e-06, -1.6188e-06],\n",
       "            ...,\n",
       "            [-1.2707e-10, -3.7696e-10,  1.0281e-10,  ..., -8.1038e-11,\n",
       "             -4.5841e-11,  6.3461e-10],\n",
       "            [-1.1979e-10, -3.7911e-10,  8.7173e-11,  ..., -8.9802e-11,\n",
       "             -4.4945e-11,  6.3324e-10],\n",
       "            [-1.2511e-10, -3.7976e-10,  1.0645e-10,  ..., -9.3724e-11,\n",
       "             -3.7553e-11,  6.2820e-10]]),\n",
       "    'exp_avg_sq': tensor([[3.0918e-10, 2.2391e-10, 1.7112e-10,  ..., 1.8098e-10, 1.7663e-10,\n",
       "             2.9262e-10],\n",
       "            [4.9223e-10, 4.5523e-10, 7.3779e-10,  ..., 4.0494e-10, 3.7681e-10,\n",
       "             3.0057e-10],\n",
       "            [5.8961e-11, 9.3681e-11, 5.8231e-11,  ..., 5.2582e-11, 3.5957e-11,\n",
       "             7.5191e-11],\n",
       "            ...,\n",
       "            [8.7180e-19, 1.5173e-18, 1.6623e-18,  ..., 6.8656e-19, 2.5637e-19,\n",
       "             1.1859e-18],\n",
       "            [8.5456e-19, 1.4791e-18, 1.6640e-18,  ..., 6.9022e-19, 2.6565e-19,\n",
       "             1.1602e-18],\n",
       "            [8.5543e-19, 1.4668e-18, 1.7258e-18,  ..., 6.8325e-19, 2.5756e-19,\n",
       "             1.1676e-18]])},\n",
       "   'model.embed_tokens.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 3.1692e-07,  6.6491e-07,  9.6271e-08,  ...,  2.9705e-07,\n",
       "             -9.8976e-08,  9.9089e-08],\n",
       "            [-9.9010e-09,  5.5160e-07,  2.4469e-07,  ...,  3.0794e-07,\n",
       "              3.9439e-09,  3.0798e-07],\n",
       "            [ 8.2411e-08,  4.4312e-07, -3.6341e-07,  ..., -1.7044e-07,\n",
       "             -7.8203e-08, -3.6117e-07],\n",
       "            ...,\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00]]),\n",
       "    'exp_avg_sq': tensor([[3.1401e-12, 3.5462e-12, 3.3107e-12,  ..., 3.4765e-12, 7.8024e-13,\n",
       "             3.3666e-12],\n",
       "            [1.1115e-12, 3.4868e-12, 1.4814e-12,  ..., 1.4914e-12, 1.9545e-12,\n",
       "             3.3262e-12],\n",
       "            [9.2848e-13, 2.1833e-12, 4.2065e-13,  ..., 8.6588e-13, 1.0120e-12,\n",
       "             2.4887e-12],\n",
       "            ...,\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "             0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "             0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "             0.0000e+00]])},\n",
       "   'model.norm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 7.6186e-06, -7.5892e-06, -1.3387e-05,  ..., -2.3441e-05,\n",
       "            -1.7953e-05, -2.0686e-05]),\n",
       "    'exp_avg_sq': tensor([1.3475e-09, 1.3976e-09, 1.2836e-09,  ..., 2.2880e-09, 2.5607e-09,\n",
       "            2.2239e-09])},\n",
       "   'model.layers.0.input_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 5.5333e-07, -3.7423e-06, -1.1256e-05,  ..., -1.1236e-05,\n",
       "            -5.3475e-06, -9.2834e-06]),\n",
       "    'exp_avg_sq': tensor([2.9482e-09, 2.3127e-09, 2.1438e-09,  ..., 4.5696e-09, 3.5086e-09,\n",
       "            1.8073e-09])},\n",
       "   'model.layers.0.mlp.down_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-4.1813e-08,  7.4298e-07,  2.0783e-07,  ..., -1.5216e-07,\n",
       "             -3.3371e-07,  4.7949e-08],\n",
       "            [ 3.2648e-08,  1.0353e-06,  2.7765e-07,  ...,  2.5407e-07,\n",
       "              8.5374e-08,  3.5079e-07],\n",
       "            [-4.9285e-08,  6.9185e-07,  7.6458e-08,  ...,  6.0443e-07,\n",
       "             -1.4579e-07,  2.1453e-07],\n",
       "            ...,\n",
       "            [-3.1755e-08, -9.1184e-07,  5.8288e-07,  ...,  2.9519e-07,\n",
       "              6.0618e-07, -1.1232e-07],\n",
       "            [ 1.6617e-08,  9.5340e-07, -3.1314e-08,  ..., -4.3518e-07,\n",
       "              6.4049e-07, -1.3938e-08],\n",
       "            [ 7.6389e-08, -4.4344e-07,  3.0073e-07,  ...,  6.9385e-07,\n",
       "              3.5172e-07,  2.8883e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.6435e-14, 4.3827e-12, 1.4055e-12,  ..., 3.5998e-12, 3.1038e-12,\n",
       "             1.1857e-12],\n",
       "            [2.1865e-14, 6.0552e-12, 1.5271e-12,  ..., 4.3071e-12, 4.2317e-12,\n",
       "             1.0411e-12],\n",
       "            [1.5513e-14, 4.9305e-12, 1.3184e-12,  ..., 4.0671e-12, 2.0535e-12,\n",
       "             8.6510e-13],\n",
       "            ...,\n",
       "            [3.0873e-14, 7.0206e-12, 1.3280e-12,  ..., 4.0818e-12, 4.9331e-12,\n",
       "             1.4093e-12],\n",
       "            [2.6640e-14, 6.5754e-12, 1.2386e-12,  ..., 5.1632e-12, 1.9611e-12,\n",
       "             1.0656e-12],\n",
       "            [3.6155e-14, 6.8011e-12, 1.3073e-12,  ..., 3.7590e-12, 2.9435e-12,\n",
       "             1.5697e-12]])},\n",
       "   'model.layers.0.mlp.gate_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 4.5421e-09,  1.6123e-08,  1.4154e-08,  ..., -1.4165e-09,\n",
       "              6.1771e-09,  1.1352e-09],\n",
       "            [ 5.2513e-08, -2.2009e-08,  5.6946e-08,  ..., -1.7001e-07,\n",
       "              1.1429e-07,  8.0407e-08],\n",
       "            [-1.5687e-08,  3.1150e-08,  2.8518e-08,  ...,  2.0925e-08,\n",
       "             -1.2569e-07,  2.5802e-08],\n",
       "            ...,\n",
       "            [-2.0985e-08,  7.4481e-08, -3.4647e-08,  ...,  4.1983e-08,\n",
       "             -1.5258e-07,  4.9145e-08],\n",
       "            [-8.0266e-08, -1.1695e-07, -1.1961e-07,  ...,  3.8152e-08,\n",
       "              2.3975e-07, -8.0792e-08],\n",
       "            [ 1.6824e-08,  6.2674e-08,  5.5954e-08,  ...,  8.7538e-09,\n",
       "              3.0269e-08, -2.0818e-08]]),\n",
       "    'exp_avg_sq': tensor([[5.5792e-15, 6.6865e-15, 3.8167e-15,  ..., 3.2134e-15, 1.4894e-14,\n",
       "             5.2326e-15],\n",
       "            [1.2707e-13, 1.6801e-13, 1.0525e-13,  ..., 2.1450e-13, 2.4120e-13,\n",
       "             2.3394e-13],\n",
       "            [6.3797e-14, 1.0054e-13, 4.1409e-14,  ..., 5.3435e-14, 1.0186e-13,\n",
       "             6.9090e-14],\n",
       "            ...,\n",
       "            [1.5002e-13, 2.1555e-13, 1.3201e-13,  ..., 2.3061e-13, 2.9111e-13,\n",
       "             2.7287e-13],\n",
       "            [8.7004e-14, 1.1415e-13, 7.8414e-14,  ..., 1.5820e-13, 1.7867e-13,\n",
       "             1.2035e-13],\n",
       "            [4.1692e-14, 1.1951e-13, 3.4840e-14,  ..., 7.6442e-14, 2.0274e-13,\n",
       "             4.7147e-14]])},\n",
       "   'model.layers.0.mlp.up_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 5.0999e-08,  2.7441e-08, -1.1401e-08,  ...,  2.5783e-09,\n",
       "              2.2977e-08,  6.1501e-09],\n",
       "            [-2.2415e-07,  6.1254e-08,  5.6535e-08,  ...,  6.2966e-09,\n",
       "             -2.0885e-07,  1.3310e-07],\n",
       "            [ 8.0299e-08,  2.0367e-08, -3.0974e-08,  ..., -1.0243e-07,\n",
       "             -4.9746e-08,  5.6958e-08],\n",
       "            ...,\n",
       "            [-9.3395e-08, -1.0242e-07,  1.7841e-08,  ..., -4.7386e-08,\n",
       "              1.6519e-07,  1.7101e-07],\n",
       "            [-5.1639e-08, -5.8454e-08,  1.9291e-08,  ..., -3.7075e-08,\n",
       "             -9.3793e-08,  7.6344e-08],\n",
       "            [-1.0977e-07, -4.7472e-10,  6.6840e-09,  ..., -8.0391e-08,\n",
       "              6.3315e-08,  4.2741e-08]]),\n",
       "    'exp_avg_sq': tensor([[1.2394e-14, 1.4527e-14, 6.3564e-15,  ..., 7.1604e-15, 2.9254e-14,\n",
       "             1.2543e-14],\n",
       "            [3.3182e-13, 3.9098e-13, 2.4990e-13,  ..., 3.4772e-13, 3.6019e-13,\n",
       "             4.4535e-13],\n",
       "            [1.6361e-13, 1.4519e-13, 1.2381e-13,  ..., 1.0403e-13, 2.1677e-13,\n",
       "             1.4195e-13],\n",
       "            ...,\n",
       "            [1.7006e-13, 2.5452e-13, 7.0039e-14,  ..., 2.5182e-13, 5.2176e-13,\n",
       "             2.8069e-13],\n",
       "            [1.1680e-13, 1.1240e-13, 1.2012e-13,  ..., 1.1841e-13, 2.6204e-13,\n",
       "             1.6756e-13],\n",
       "            [1.0268e-13, 1.4971e-13, 8.2090e-14,  ..., 1.4328e-13, 2.3700e-13,\n",
       "             1.6109e-13]])},\n",
       "   'model.layers.0.post_attention_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-2.7314e-06, -8.0505e-06, -1.9744e-07,  ..., -9.4590e-07,\n",
       "            -1.9177e-06,  1.5769e-05]),\n",
       "    'exp_avg_sq': tensor([2.8585e-10, 7.3749e-10, 5.1414e-10,  ..., 6.2063e-10, 1.0458e-09,\n",
       "            9.8346e-10])},\n",
       "   'model.layers.0.self_attn.k_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 8.9303e-08, -1.6517e-07, -1.2129e-07,  ..., -7.5700e-09,\n",
       "             8.0042e-10, -2.9007e-09]),\n",
       "    'exp_avg_sq': tensor([1.4699e-12, 2.0126e-12, 7.2258e-13,  ..., 1.0872e-15, 1.8811e-16,\n",
       "            4.4818e-16])},\n",
       "   'model.layers.0.self_attn.k_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 2.2244e-08, -1.7475e-08, -5.1396e-09,  ...,  1.0334e-08,\n",
       "              2.5637e-08,  2.9703e-08],\n",
       "            [-1.7743e-09,  1.3187e-08,  2.4201e-08,  ...,  5.9096e-09,\n",
       "              2.3892e-08, -1.3277e-08],\n",
       "            [-5.7321e-09,  3.1844e-08,  2.9579e-08,  ..., -2.8387e-09,\n",
       "              1.9670e-08,  9.5038e-09],\n",
       "            ...,\n",
       "            [ 1.8477e-08,  5.3167e-08, -1.2234e-08,  ..., -3.1260e-08,\n",
       "             -3.6229e-08, -3.7809e-09],\n",
       "            [-9.7787e-09, -3.2969e-08, -1.6161e-08,  ...,  4.0128e-10,\n",
       "              3.2504e-08,  3.1117e-08],\n",
       "            [ 2.0276e-08,  7.3227e-08,  1.2246e-08,  ..., -6.8572e-10,\n",
       "             -1.5164e-08, -5.1268e-08]]),\n",
       "    'exp_avg_sq': tensor([[2.6026e-14, 1.7871e-14, 1.3138e-14,  ..., 2.2883e-14, 2.7309e-14,\n",
       "             3.8120e-14],\n",
       "            [2.3659e-14, 1.9878e-14, 7.4035e-15,  ..., 1.8775e-14, 1.3153e-14,\n",
       "             2.4324e-14],\n",
       "            [1.2770e-14, 9.8706e-15, 7.9806e-15,  ..., 2.4059e-14, 1.7936e-14,\n",
       "             1.7178e-14],\n",
       "            ...,\n",
       "            [7.4767e-14, 7.7008e-14, 4.8729e-14,  ..., 1.9321e-13, 4.0887e-13,\n",
       "             1.8029e-13],\n",
       "            [9.2905e-15, 2.0839e-14, 8.4581e-15,  ..., 1.4905e-14, 4.1464e-14,\n",
       "             1.3108e-14],\n",
       "            [6.3950e-14, 5.0770e-14, 2.0125e-14,  ..., 7.0177e-14, 1.5245e-13,\n",
       "             7.8318e-14]])},\n",
       "   'model.layers.0.self_attn.o_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 2.6546e-07,  4.8164e-07,  2.1140e-07,  ...,  4.8920e-07,\n",
       "             -5.5930e-09,  7.4794e-08],\n",
       "            [-2.0965e-08,  4.0338e-07, -1.9234e-07,  ..., -8.3565e-07,\n",
       "              5.3093e-08,  3.0597e-07],\n",
       "            [ 4.0548e-07,  3.4740e-07, -6.5778e-10,  ..., -9.8954e-07,\n",
       "             -3.4356e-08,  3.3528e-07],\n",
       "            ...,\n",
       "            [ 4.8786e-08,  1.2685e-07, -1.0137e-08,  ..., -6.8719e-07,\n",
       "             -4.2519e-07,  1.8926e-08],\n",
       "            [-2.5596e-07,  7.0106e-08, -1.8721e-07,  ...,  6.0853e-07,\n",
       "             -2.1382e-07,  3.7237e-08],\n",
       "            [-1.4674e-07, -1.6203e-07,  6.2277e-07,  ...,  5.1636e-07,\n",
       "             -4.5280e-08,  5.5614e-08]]),\n",
       "    'exp_avg_sq': tensor([[1.3434e-12, 3.3547e-12, 1.3813e-12,  ..., 8.7328e-11, 6.1690e-13,\n",
       "             1.1708e-12],\n",
       "            [1.3264e-12, 4.0774e-12, 2.7979e-12,  ..., 6.0451e-11, 7.7670e-13,\n",
       "             7.4622e-13],\n",
       "            [1.8388e-12, 2.1414e-12, 1.5379e-12,  ..., 7.9532e-11, 1.0364e-12,\n",
       "             6.3152e-13],\n",
       "            ...,\n",
       "            [1.1143e-12, 2.6050e-12, 3.8339e-12,  ..., 9.3262e-11, 1.3894e-12,\n",
       "             7.1206e-13],\n",
       "            [2.2649e-12, 3.2861e-12, 4.1859e-12,  ..., 7.2727e-11, 1.0672e-12,\n",
       "             7.6700e-13],\n",
       "            [1.0915e-12, 2.1001e-12, 2.8870e-12,  ..., 1.0231e-10, 1.0820e-12,\n",
       "             1.0096e-12]])},\n",
       "   'model.layers.0.self_attn.q_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 1.3174e-09,  1.4740e-07,  6.5737e-07,  ..., -3.1321e-08,\n",
       "            -1.8918e-07,  2.8425e-06]),\n",
       "    'exp_avg_sq': tensor([1.5770e-12, 1.7109e-12, 2.0219e-12,  ..., 6.5127e-11, 6.1824e-12,\n",
       "            2.9110e-11])},\n",
       "   'model.layers.0.self_attn.q_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 9.6548e-09, -3.3052e-08, -2.4596e-08,  ...,  3.5549e-09,\n",
       "              5.0040e-09,  4.7873e-08],\n",
       "            [ 2.0657e-08,  3.0732e-09,  1.2109e-08,  ..., -6.9446e-10,\n",
       "              1.3346e-08, -7.6976e-09],\n",
       "            [-2.8813e-08, -1.6779e-08, -3.0823e-09,  ..., -4.8953e-09,\n",
       "             -3.8517e-08,  3.3243e-08],\n",
       "            ...,\n",
       "            [ 8.0581e-08,  1.5005e-07, -1.2986e-07,  ..., -3.3075e-08,\n",
       "             -8.4194e-08,  2.8007e-07],\n",
       "            [ 1.7872e-07,  1.7092e-07,  8.0202e-08,  ...,  8.0812e-08,\n",
       "              3.3462e-08,  4.6087e-08],\n",
       "            [ 1.5455e-07, -2.8500e-07, -6.6018e-08,  ..., -2.5629e-07,\n",
       "             -2.4121e-07,  1.9543e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.8721e-14, 2.2944e-14, 1.1827e-14,  ..., 9.7043e-15, 1.4282e-14,\n",
       "             3.1141e-14],\n",
       "            [1.8915e-14, 3.5908e-14, 1.1443e-14,  ..., 1.5272e-14, 1.9685e-14,\n",
       "             2.2518e-14],\n",
       "            [1.3507e-14, 2.9902e-14, 9.8084e-15,  ..., 9.4949e-15, 2.2178e-14,\n",
       "             1.8628e-14],\n",
       "            ...,\n",
       "            [4.1011e-13, 3.6251e-13, 3.2806e-13,  ..., 4.2068e-13, 3.7000e-13,\n",
       "             6.9436e-13],\n",
       "            [8.9082e-14, 1.9728e-13, 8.4863e-14,  ..., 1.4549e-13, 1.6138e-13,\n",
       "             9.9356e-14],\n",
       "            [3.8660e-13, 4.8203e-13, 3.3056e-13,  ..., 3.4261e-13, 4.6858e-13,\n",
       "             8.1991e-13]])},\n",
       "   'model.layers.0.self_attn.v_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-1.6492e-05, -4.6835e-07, -7.0809e-06,  ...,  1.0729e-05,\n",
       "             1.0768e-06, -9.8587e-06]),\n",
       "    'exp_avg_sq': tensor([2.5883e-09, 2.1218e-09, 2.1434e-09,  ..., 4.5789e-09, 1.6521e-09,\n",
       "            8.8104e-10])},\n",
       "   'model.layers.0.self_attn.v_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 1.3376e-07, -3.0742e-07,  2.0065e-07,  ..., -3.1338e-07,\n",
       "              1.5033e-08,  5.1909e-07],\n",
       "            [ 6.8642e-08, -3.3968e-08, -3.4492e-07,  ...,  3.4459e-07,\n",
       "             -6.3025e-08, -3.4848e-07],\n",
       "            [ 1.0655e-07,  4.2442e-07,  1.0990e-10,  ..., -6.0806e-08,\n",
       "              7.0240e-08,  8.7728e-08],\n",
       "            ...,\n",
       "            [-4.1051e-07, -1.1139e-06,  1.2393e-07,  ...,  1.1394e-07,\n",
       "              4.0760e-07, -5.1794e-08],\n",
       "            [-1.1247e-07, -7.5333e-08, -8.6335e-08,  ...,  1.0500e-07,\n",
       "             -7.1922e-08, -7.4490e-09],\n",
       "            [-2.5810e-07, -9.6484e-08,  3.3531e-08,  ..., -1.1438e-07,\n",
       "              1.8301e-07,  2.4431e-07]]),\n",
       "    'exp_avg_sq': tensor([[9.7407e-13, 1.4602e-12, 7.8310e-13,  ..., 1.3714e-12, 1.7278e-12,\n",
       "             1.6054e-12],\n",
       "            [9.0133e-13, 1.3535e-12, 8.2081e-13,  ..., 1.9574e-12, 1.3493e-12,\n",
       "             2.0087e-12],\n",
       "            [1.3760e-12, 1.6599e-12, 5.3464e-13,  ..., 2.2504e-12, 1.3469e-12,\n",
       "             1.7310e-12],\n",
       "            ...,\n",
       "            [7.4745e-12, 5.4034e-12, 4.7652e-12,  ..., 6.2763e-12, 4.4597e-12,\n",
       "             4.8261e-12],\n",
       "            [8.3139e-13, 3.5254e-13, 3.6590e-13,  ..., 1.0520e-12, 1.5074e-12,\n",
       "             8.6700e-13],\n",
       "            [7.7586e-13, 7.2544e-13, 3.8267e-13,  ..., 3.3111e-13, 7.5817e-13,\n",
       "             7.0514e-13]])},\n",
       "   'model.layers.1.input_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 3.9375e-06,  4.1260e-06, -4.8390e-06,  ..., -2.9654e-06,\n",
       "             7.6837e-07, -5.2689e-07]),\n",
       "    'exp_avg_sq': tensor([1.8935e-10, 2.0637e-10, 1.7017e-10,  ..., 2.5077e-10, 1.6263e-10,\n",
       "            1.5117e-10])},\n",
       "   'model.layers.1.mlp.down_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 4.5509e-07, -1.3540e-07,  5.1618e-07,  ...,  3.9343e-07,\n",
       "             -4.3666e-07, -2.1255e-08],\n",
       "            [-2.3550e-08, -9.0495e-10, -1.1242e-07,  ...,  4.0241e-08,\n",
       "             -1.7832e-07, -1.1571e-08],\n",
       "            [-5.9777e-07,  1.6366e-07,  6.0174e-07,  ..., -4.9857e-07,\n",
       "             -1.4911e-07,  2.9647e-07],\n",
       "            ...,\n",
       "            [-6.0224e-08, -1.3888e-07, -7.2533e-07,  ..., -4.0036e-07,\n",
       "              3.7863e-07,  5.0765e-07],\n",
       "            [ 2.4198e-07, -5.8867e-08, -1.8262e-07,  ...,  5.6866e-07,\n",
       "              2.3384e-07,  7.4541e-07],\n",
       "            [ 8.3364e-07, -3.8566e-07, -9.4053e-08,  ..., -4.1942e-07,\n",
       "             -5.2439e-08, -2.5071e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.8186e-12, 1.0422e-12, 3.8692e-12,  ..., 2.1126e-12, 4.5771e-12,\n",
       "             2.1220e-12],\n",
       "            [2.6978e-12, 1.1161e-12, 1.8082e-12,  ..., 1.3848e-12, 2.2694e-12,\n",
       "             1.4074e-12],\n",
       "            [2.4036e-12, 1.8077e-12, 5.4061e-12,  ..., 3.7981e-12, 2.7113e-12,\n",
       "             1.9331e-12],\n",
       "            ...,\n",
       "            [2.8835e-12, 1.6556e-12, 3.1895e-12,  ..., 2.4296e-12, 3.0390e-12,\n",
       "             2.4871e-12],\n",
       "            [3.2403e-12, 2.2568e-12, 3.2558e-12,  ..., 2.2728e-12, 3.9537e-12,\n",
       "             2.8467e-12],\n",
       "            [2.7832e-12, 2.0163e-12, 3.3364e-12,  ..., 1.5693e-12, 2.0939e-12,\n",
       "             2.4107e-12]])},\n",
       "   'model.layers.1.mlp.gate_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-4.7245e-08, -1.4093e-07,  3.3808e-08,  ...,  1.5094e-07,\n",
       "              1.9871e-07,  3.1022e-09],\n",
       "            [-1.0188e-08,  1.6989e-07,  1.1575e-07,  ..., -1.1963e-07,\n",
       "             -8.7498e-09, -1.0576e-07],\n",
       "            [ 1.7399e-07,  2.6727e-07, -5.6481e-08,  ..., -3.5595e-08,\n",
       "              2.3989e-07,  5.8438e-08],\n",
       "            ...,\n",
       "            [ 1.5286e-07, -3.3908e-08, -3.3921e-08,  ..., -1.4220e-08,\n",
       "              3.2120e-07, -2.4256e-07],\n",
       "            [-2.3229e-07,  9.1372e-08,  5.3577e-08,  ..., -1.1271e-07,\n",
       "             -5.4218e-08, -6.1746e-08],\n",
       "            [ 7.7874e-08, -1.3902e-07, -8.7273e-08,  ..., -2.5335e-07,\n",
       "              2.3353e-07,  1.0524e-07]]),\n",
       "    'exp_avg_sq': tensor([[4.5033e-13, 5.9951e-13, 4.3101e-13,  ..., 7.9913e-13, 5.6551e-13,\n",
       "             5.9327e-13],\n",
       "            [3.9621e-13, 4.4887e-13, 2.0966e-13,  ..., 4.5179e-13, 3.9709e-13,\n",
       "             4.3889e-13],\n",
       "            [5.5076e-13, 8.3647e-13, 4.0651e-13,  ..., 8.4205e-13, 5.9172e-13,\n",
       "             8.4175e-13],\n",
       "            ...,\n",
       "            [5.8651e-13, 3.7030e-13, 2.6966e-13,  ..., 4.2529e-13, 5.6146e-13,\n",
       "             5.8626e-13],\n",
       "            [3.0483e-13, 3.3246e-13, 3.1764e-13,  ..., 3.6354e-13, 3.1324e-13,\n",
       "             4.3027e-13],\n",
       "            [9.6329e-13, 3.7920e-13, 5.4707e-13,  ..., 6.5855e-13, 5.0530e-13,\n",
       "             8.0989e-13]])},\n",
       "   'model.layers.1.mlp.up_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-3.4029e-08, -1.5179e-07, -3.3463e-08,  ...,  3.2886e-07,\n",
       "              1.2329e-08, -1.1352e-07],\n",
       "            [-5.0451e-08, -1.1149e-07, -1.5140e-07,  ..., -3.0091e-08,\n",
       "              6.5725e-08,  2.1967e-07],\n",
       "            [ 1.3321e-07, -2.9727e-07,  1.3726e-07,  ...,  1.3256e-07,\n",
       "              3.2568e-07, -1.5770e-07],\n",
       "            ...,\n",
       "            [ 4.3002e-08,  1.4146e-07, -1.2468e-07,  ...,  2.9123e-08,\n",
       "              2.7128e-08,  7.6037e-08],\n",
       "            [ 9.5419e-08,  1.7689e-07,  2.8118e-07,  ..., -4.7912e-08,\n",
       "              4.4608e-08, -1.4731e-08],\n",
       "            [-1.1384e-07,  1.9674e-07,  1.0594e-07,  ..., -2.3977e-07,\n",
       "             -2.9035e-07,  3.9358e-08]]),\n",
       "    'exp_avg_sq': tensor([[5.9220e-13, 5.1660e-13, 5.6861e-13,  ..., 6.9359e-13, 7.3458e-13,\n",
       "             9.0032e-13],\n",
       "            [3.7679e-13, 4.5016e-13, 4.1219e-13,  ..., 3.5133e-13, 6.1883e-13,\n",
       "             4.1047e-13],\n",
       "            [5.6174e-13, 8.6257e-13, 5.6534e-13,  ..., 6.7570e-13, 1.0348e-12,\n",
       "             9.6555e-13],\n",
       "            ...,\n",
       "            [4.5539e-13, 4.3959e-13, 4.8764e-13,  ..., 3.1023e-13, 4.8954e-13,\n",
       "             5.4007e-13],\n",
       "            [7.5100e-13, 5.8114e-13, 5.2217e-13,  ..., 4.0469e-13, 5.4991e-13,\n",
       "             9.7694e-13],\n",
       "            [3.0895e-13, 5.4546e-13, 3.2357e-13,  ..., 6.6586e-13, 9.0187e-13,\n",
       "             7.8271e-13]])},\n",
       "   'model.layers.1.post_attention_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-2.7421e-06,  1.3121e-06, -1.9848e-06,  ...,  7.8277e-06,\n",
       "            -4.2860e-07,  5.2145e-06]),\n",
       "    'exp_avg_sq': tensor([2.1182e-10, 2.7395e-10, 3.0293e-10,  ..., 3.5352e-10, 2.1269e-10,\n",
       "            1.7903e-10])},\n",
       "   'model.layers.1.self_attn.k_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 7.4781e-07,  8.5570e-07, -5.4782e-07,  ...,  2.5856e-11,\n",
       "            -1.8489e-10, -8.2232e-11]),\n",
       "    'exp_avg_sq': tensor([1.0998e-11, 1.9595e-11, 1.3243e-11,  ..., 7.4207e-18, 2.0740e-18,\n",
       "            2.5107e-18])},\n",
       "   'model.layers.1.self_attn.k_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-2.9875e-07,  1.3629e-07, -4.2196e-08,  ...,  1.5237e-07,\n",
       "             -2.9715e-07, -2.4537e-07],\n",
       "            [-2.1073e-07,  1.6686e-08, -3.1574e-08,  ...,  7.6187e-08,\n",
       "             -1.8331e-07, -8.2552e-08],\n",
       "            [ 1.2908e-07,  3.9238e-08,  3.9281e-08,  ..., -2.5147e-08,\n",
       "              5.2284e-08,  1.1413e-08],\n",
       "            ...,\n",
       "            [ 2.0489e-08,  5.6036e-09,  2.1699e-08,  ...,  2.5019e-09,\n",
       "              7.4041e-09,  2.3302e-08],\n",
       "            [ 3.1025e-09, -1.3612e-08,  3.5501e-09,  ...,  1.3945e-09,\n",
       "             -2.4095e-09, -2.0194e-08],\n",
       "            [ 3.6663e-09,  1.7489e-08, -1.3412e-08,  ..., -3.8126e-09,\n",
       "             -6.4068e-10,  1.9663e-08]]),\n",
       "    'exp_avg_sq': tensor([[1.2556e-12, 1.6854e-12, 1.5292e-12,  ..., 1.5903e-12, 8.2584e-13,\n",
       "             1.4174e-12],\n",
       "            [5.0181e-13, 6.6159e-13, 5.4072e-13,  ..., 6.8998e-13, 3.1723e-13,\n",
       "             5.7055e-13],\n",
       "            [1.6120e-13, 1.9527e-13, 1.7024e-13,  ..., 1.6934e-13, 1.5256e-13,\n",
       "             2.3973e-13],\n",
       "            ...,\n",
       "            [8.8385e-15, 7.2420e-15, 1.0265e-14,  ..., 1.4113e-14, 7.6200e-15,\n",
       "             8.9143e-15],\n",
       "            [2.4880e-15, 3.3089e-15, 3.3918e-15,  ..., 6.1917e-15, 2.5358e-15,\n",
       "             2.4332e-15],\n",
       "            [1.6813e-15, 4.0420e-15, 2.2903e-15,  ..., 2.9863e-15, 2.3652e-15,\n",
       "             2.0516e-15]])},\n",
       "   'model.layers.1.self_attn.o_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 7.7843e-07,  1.0240e-06, -3.3762e-07,  ..., -7.7513e-08,\n",
       "             -1.4272e-07,  1.9252e-08],\n",
       "            [ 5.6165e-07, -1.2843e-07,  6.0134e-07,  ...,  5.8840e-08,\n",
       "              9.8967e-08,  7.7641e-08],\n",
       "            [ 3.5137e-07, -6.0988e-07, -1.5313e-07,  ...,  1.0953e-07,\n",
       "              3.3373e-08, -4.4881e-08],\n",
       "            ...,\n",
       "            [ 9.5296e-07, -9.5434e-07,  4.3510e-07,  ..., -3.3353e-08,\n",
       "              8.7241e-08, -1.7669e-07],\n",
       "            [-2.4066e-07, -1.2703e-08,  9.6169e-08,  ...,  1.1983e-07,\n",
       "              1.1787e-07,  4.5804e-09],\n",
       "            [-5.2479e-07,  3.6133e-07,  1.4863e-06,  ..., -6.8612e-08,\n",
       "              4.0274e-08,  8.8099e-08]]),\n",
       "    'exp_avg_sq': tensor([[8.4789e-12, 6.0856e-12, 5.3627e-12,  ..., 5.7415e-13, 3.5702e-13,\n",
       "             2.9587e-13],\n",
       "            [7.6401e-12, 4.0681e-12, 5.5393e-12,  ..., 5.3047e-13, 3.3479e-13,\n",
       "             3.2893e-13],\n",
       "            [7.9822e-12, 5.0429e-12, 5.2792e-12,  ..., 6.5269e-13, 2.4538e-13,\n",
       "             5.6487e-13],\n",
       "            ...,\n",
       "            [7.4923e-12, 6.1458e-12, 6.6471e-12,  ..., 4.7019e-13, 4.1203e-13,\n",
       "             2.7703e-13],\n",
       "            [7.2952e-12, 6.3290e-12, 5.5108e-12,  ..., 5.5271e-13, 3.1955e-13,\n",
       "             2.9744e-13],\n",
       "            [1.0198e-11, 7.4755e-12, 9.0766e-12,  ..., 4.5293e-13, 2.1689e-13,\n",
       "             2.8970e-13]])},\n",
       "   'model.layers.1.self_attn.q_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-2.4868e-07,  1.0780e-06,  9.2241e-07,  ...,  5.3755e-07,\n",
       "             3.6792e-08, -5.9275e-08]),\n",
       "    'exp_avg_sq': tensor([9.7624e-11, 5.5030e-11, 2.3762e-11,  ..., 3.9402e-12, 3.0262e-13,\n",
       "            3.3159e-13])},\n",
       "   'model.layers.1.self_attn.q_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 6.7675e-08,  1.6853e-07, -4.0985e-08,  ..., -1.6987e-07,\n",
       "             -1.4703e-07, -6.1219e-09],\n",
       "            [ 5.6545e-08,  1.6149e-07, -3.5108e-08,  ..., -6.2164e-08,\n",
       "             -4.6614e-08,  1.2487e-07],\n",
       "            [-6.1482e-08, -1.1602e-07,  4.6064e-08,  ...,  6.4385e-08,\n",
       "              6.3829e-08,  1.9110e-08],\n",
       "            ...,\n",
       "            [ 1.6509e-08,  3.2603e-08, -2.2551e-08,  ..., -2.7910e-08,\n",
       "             -5.4169e-08, -6.0830e-10],\n",
       "            [-1.0768e-08, -7.4073e-09,  1.4635e-08,  ...,  3.4925e-09,\n",
       "              1.2995e-08, -1.1759e-08],\n",
       "            [ 1.4867e-09,  6.6953e-09, -1.2023e-08,  ..., -3.2584e-09,\n",
       "              1.7899e-09, -2.4808e-09]]),\n",
       "    'exp_avg_sq': tensor([[4.9633e-13, 6.1711e-13, 5.1831e-13,  ..., 1.3907e-12, 4.9272e-13,\n",
       "             7.4893e-13],\n",
       "            [3.0983e-13, 3.7800e-13, 3.2901e-13,  ..., 3.7457e-13, 1.4217e-13,\n",
       "             3.9047e-13],\n",
       "            [1.7286e-13, 1.4550e-13, 1.6364e-13,  ..., 4.0580e-13, 2.7349e-13,\n",
       "             2.0980e-13],\n",
       "            ...,\n",
       "            [2.0657e-14, 2.7565e-14, 1.7489e-14,  ..., 1.5908e-14, 1.2131e-14,\n",
       "             1.5910e-14],\n",
       "            [9.4978e-16, 2.7667e-15, 1.6384e-15,  ..., 2.5403e-15, 1.6433e-15,\n",
       "             3.0517e-15],\n",
       "            [1.4501e-15, 4.9165e-15, 1.4345e-15,  ..., 1.4600e-15, 8.2451e-16,\n",
       "             1.4979e-15]])},\n",
       "   'model.layers.1.self_attn.v_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-4.5092e-06,  6.0786e-06,  6.7763e-06,  ...,  1.2209e-05,\n",
       "            -4.5727e-07,  9.2993e-06]),\n",
       "    'exp_avg_sq': tensor([2.3952e-09, 1.2812e-09, 4.1438e-09,  ..., 9.9576e-10, 6.2191e-10,\n",
       "            7.7691e-10])},\n",
       "   'model.layers.1.self_attn.v_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 5.5892e-07,  4.4215e-07, -1.3629e-07,  ...,  2.3052e-07,\n",
       "              1.8535e-07,  1.3503e-07],\n",
       "            [-3.7149e-08,  3.1679e-07,  9.6967e-08,  ...,  2.2048e-07,\n",
       "              2.5834e-07,  2.4614e-07],\n",
       "            [-2.8469e-07,  4.9776e-07,  3.7792e-07,  ..., -7.8684e-07,\n",
       "              4.3285e-07,  3.2986e-07],\n",
       "            ...,\n",
       "            [-1.2256e-08, -1.2697e-07,  3.1826e-09,  ...,  1.6297e-07,\n",
       "              1.6955e-08, -8.9336e-08],\n",
       "            [-8.7722e-08,  1.5417e-07, -1.3974e-07,  ..., -4.5881e-08,\n",
       "              5.3512e-08,  1.5328e-07],\n",
       "            [-1.2626e-07,  3.6737e-08,  2.8094e-08,  ...,  4.8127e-08,\n",
       "             -1.0165e-07, -4.0310e-08]]),\n",
       "    'exp_avg_sq': tensor([[2.2908e-12, 2.0984e-12, 1.7675e-12,  ..., 2.1689e-12, 2.3061e-12,\n",
       "             3.6320e-12],\n",
       "            [1.7065e-12, 2.0425e-12, 2.4170e-12,  ..., 2.0029e-12, 2.5636e-12,\n",
       "             3.7809e-12],\n",
       "            [2.4133e-12, 1.9087e-12, 2.3939e-12,  ..., 2.6554e-12, 1.5170e-12,\n",
       "             3.9063e-12],\n",
       "            ...,\n",
       "            [2.1121e-13, 3.8092e-13, 2.8396e-13,  ..., 3.0549e-13, 3.4643e-13,\n",
       "             2.9196e-13],\n",
       "            [1.9624e-13, 3.0109e-13, 1.6170e-13,  ..., 1.5099e-13, 1.4058e-13,\n",
       "             2.5679e-13],\n",
       "            [2.0923e-13, 2.1101e-13, 3.3507e-13,  ..., 2.9072e-13, 4.1771e-13,\n",
       "             3.5522e-13]])},\n",
       "   'model.layers.10.input_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 2.0403e-06, -8.3651e-06,  5.3325e-06,  ...,  8.9790e-06,\n",
       "             7.5960e-06, -5.2647e-06]),\n",
       "    'exp_avg_sq': tensor([1.0042e-09, 6.6855e-10, 5.5772e-10,  ..., 8.4416e-10, 5.9510e-10,\n",
       "            6.9706e-10])},\n",
       "   'model.layers.10.mlp.down_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-1.2635e-07, -4.8481e-07,  4.9099e-08,  ..., -4.8145e-07,\n",
       "              3.7911e-07, -1.1413e-06],\n",
       "            [-4.1823e-07,  2.9577e-07,  2.9295e-07,  ..., -6.9896e-08,\n",
       "             -6.4939e-08, -1.7372e-07],\n",
       "            [-6.4853e-08, -1.0420e-06, -4.8310e-07,  ...,  9.3903e-07,\n",
       "              5.1470e-07,  5.6031e-07],\n",
       "            ...,\n",
       "            [-8.3292e-07,  6.1830e-07, -5.0495e-07,  ..., -3.7119e-07,\n",
       "              4.9633e-07, -5.3640e-08],\n",
       "            [-5.4987e-07,  1.4365e-06, -4.1792e-07,  ..., -7.6700e-07,\n",
       "              4.2452e-08, -6.6367e-07],\n",
       "            [ 8.8838e-07, -2.7280e-07, -7.0058e-07,  ..., -3.7273e-07,\n",
       "              1.1765e-06, -6.8482e-07]]),\n",
       "    'exp_avg_sq': tensor([[4.0374e-12, 8.2242e-12, 3.7589e-12,  ..., 7.0897e-12, 4.4809e-12,\n",
       "             7.2390e-12],\n",
       "            [3.9490e-12, 1.1141e-11, 4.6960e-12,  ..., 6.1324e-12, 3.9555e-12,\n",
       "             7.3680e-12],\n",
       "            [3.9356e-12, 8.5954e-12, 4.7304e-12,  ..., 9.0828e-12, 5.1287e-12,\n",
       "             7.6853e-12],\n",
       "            ...,\n",
       "            [4.5054e-12, 5.9269e-12, 5.0516e-12,  ..., 8.3562e-12, 5.1757e-12,\n",
       "             4.2588e-12],\n",
       "            [3.8122e-12, 1.1625e-11, 5.2831e-12,  ..., 6.9233e-12, 5.9702e-12,\n",
       "             4.0982e-12],\n",
       "            [4.7266e-12, 1.0634e-11, 5.2666e-12,  ..., 8.4075e-12, 6.4966e-12,\n",
       "             5.4645e-12]])},\n",
       "   'model.layers.10.mlp.gate_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 4.6940e-07,  2.2400e-07,  2.6679e-07,  ...,  1.0536e-07,\n",
       "              1.7904e-07,  1.2164e-07],\n",
       "            [-5.7980e-07, -8.0782e-09,  4.4637e-07,  ...,  7.7803e-07,\n",
       "             -3.1664e-07,  2.3113e-07],\n",
       "            [-2.0917e-07,  3.6223e-07, -7.2703e-08,  ...,  1.8465e-07,\n",
       "              4.0607e-07,  1.3585e-07],\n",
       "            ...,\n",
       "            [-5.8247e-07,  6.3255e-07, -3.9801e-07,  ..., -6.2164e-07,\n",
       "              5.3010e-07, -4.5622e-07],\n",
       "            [ 7.3465e-08, -8.7190e-08,  1.7965e-07,  ...,  4.2576e-07,\n",
       "             -2.1676e-07, -7.7060e-07],\n",
       "            [ 1.2240e-07, -2.9905e-07,  1.2085e-07,  ..., -7.1029e-07,\n",
       "              1.6294e-07,  2.6425e-07]]),\n",
       "    'exp_avg_sq': tensor([[3.9600e-12, 2.8538e-12, 2.8395e-12,  ..., 3.7908e-12, 2.0647e-12,\n",
       "             2.8055e-12],\n",
       "            [7.2283e-12, 6.2015e-12, 5.1467e-12,  ..., 6.3890e-12, 7.8196e-12,\n",
       "             7.9166e-12],\n",
       "            [2.9949e-12, 2.9617e-12, 4.2535e-12,  ..., 3.2794e-12, 3.0980e-12,\n",
       "             4.8835e-12],\n",
       "            ...,\n",
       "            [4.5283e-12, 3.0403e-12, 4.4501e-12,  ..., 8.7869e-12, 4.9333e-12,\n",
       "             3.8309e-12],\n",
       "            [5.6029e-12, 2.4154e-12, 6.0232e-12,  ..., 2.8365e-12, 5.4292e-12,\n",
       "             5.1220e-12],\n",
       "            [4.8702e-12, 2.9736e-12, 5.3875e-12,  ..., 5.2347e-12, 4.0721e-12,\n",
       "             3.7804e-12]])},\n",
       "   'model.layers.10.mlp.up_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-1.2757e-07, -1.4278e-07,  4.3520e-07,  ..., -6.6722e-07,\n",
       "             -2.2035e-08, -6.5245e-07],\n",
       "            [-8.1711e-07,  3.0001e-07,  2.0971e-08,  ...,  1.0170e-06,\n",
       "              6.2188e-08, -1.0236e-06],\n",
       "            [ 2.6765e-07,  6.1810e-07,  4.9031e-07,  ..., -1.1562e-07,\n",
       "              1.2638e-07,  3.6565e-07],\n",
       "            ...,\n",
       "            [-1.3818e-08, -2.0688e-07,  4.1614e-07,  ..., -5.5256e-07,\n",
       "             -3.2982e-08,  1.7270e-07],\n",
       "            [-1.2590e-07,  3.9062e-07, -3.8007e-07,  ..., -2.6189e-07,\n",
       "             -2.3669e-07, -2.6744e-07],\n",
       "            [ 4.6352e-08,  1.0647e-07,  5.0239e-07,  ...,  1.9427e-07,\n",
       "             -1.6197e-07,  9.0945e-07]]),\n",
       "    'exp_avg_sq': tensor([[2.2652e-12, 1.7834e-12, 3.5059e-12,  ..., 3.0355e-12, 3.4182e-12,\n",
       "             3.2615e-12],\n",
       "            [6.9887e-12, 6.1240e-12, 5.7849e-12,  ..., 6.4913e-12, 5.1238e-12,\n",
       "             4.6058e-12],\n",
       "            [3.6777e-12, 2.9576e-12, 3.1596e-12,  ..., 2.2282e-12, 3.0845e-12,\n",
       "             2.8866e-12],\n",
       "            ...,\n",
       "            [2.5613e-12, 3.3641e-12, 2.5897e-12,  ..., 4.8501e-12, 1.9801e-12,\n",
       "             4.0889e-12],\n",
       "            [2.9355e-12, 1.8168e-12, 2.5577e-12,  ..., 2.9504e-12, 2.0713e-12,\n",
       "             3.0807e-12],\n",
       "            [2.9723e-12, 3.6657e-12, 5.3740e-12,  ..., 2.8631e-12, 4.0386e-12,\n",
       "             4.3920e-12]])},\n",
       "   'model.layers.10.post_attention_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 3.7250e-06,  9.7088e-06,  9.7105e-06,  ..., -1.3035e-06,\n",
       "            -4.7825e-06, -7.1036e-06]),\n",
       "    'exp_avg_sq': tensor([8.2579e-10, 1.0909e-09, 1.1281e-09,  ..., 6.0285e-10, 7.8091e-10,\n",
       "            8.6679e-10])},\n",
       "   'model.layers.10.self_attn.k_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-3.8559e-07, -7.3251e-07, -5.1390e-08,  ..., -1.7522e-09,\n",
       "             6.4590e-10,  7.2041e-09]),\n",
       "    'exp_avg_sq': tensor([1.1022e-11, 9.2595e-12, 1.3770e-11,  ..., 3.3524e-16, 3.7639e-16,\n",
       "            3.7199e-16])},\n",
       "   'model.layers.10.self_attn.k_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-1.0771e-07, -2.7762e-07,  1.5829e-07,  ...,  9.3751e-09,\n",
       "              2.1611e-07,  4.1138e-08],\n",
       "            [ 3.4482e-07,  1.7809e-07,  1.6497e-07,  ..., -6.9858e-08,\n",
       "              2.9230e-07,  2.3833e-07],\n",
       "            [ 4.7609e-08, -5.6941e-08, -4.0152e-07,  ..., -3.3219e-07,\n",
       "              3.3995e-07,  3.2215e-08],\n",
       "            ...,\n",
       "            [ 1.5761e-07, -3.6019e-07,  3.0911e-07,  ...,  1.6030e-07,\n",
       "              7.4270e-09, -2.3418e-07],\n",
       "            [-3.1779e-07,  5.9727e-07, -1.2158e-07,  ...,  1.3116e-07,\n",
       "             -2.6229e-08, -1.7807e-07],\n",
       "            [ 2.4190e-07,  2.7022e-07, -1.8538e-07,  ...,  3.5477e-07,\n",
       "              7.3342e-07, -1.5212e-07]]),\n",
       "    'exp_avg_sq': tensor([[9.6274e-13, 7.9847e-13, 7.5807e-13,  ..., 4.7188e-13, 6.9992e-13,\n",
       "             7.2126e-13],\n",
       "            [6.0284e-13, 6.7936e-13, 9.8997e-13,  ..., 6.8894e-13, 6.0983e-13,\n",
       "             9.8672e-13],\n",
       "            [6.4391e-13, 9.1608e-13, 1.0396e-12,  ..., 9.2071e-13, 1.2026e-12,\n",
       "             1.0488e-12],\n",
       "            ...,\n",
       "            [2.6337e-12, 3.7037e-12, 6.7949e-12,  ..., 2.1417e-12, 3.0070e-12,\n",
       "             2.4062e-12],\n",
       "            [3.6648e-12, 7.1194e-12, 4.4119e-12,  ..., 3.2563e-12, 3.3859e-12,\n",
       "             3.3106e-12],\n",
       "            [3.5612e-12, 5.1918e-12, 3.8176e-12,  ..., 2.9113e-12, 3.4046e-12,\n",
       "             2.7995e-12]])},\n",
       "   'model.layers.10.self_attn.o_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 4.2243e-07, -8.0265e-07,  2.2484e-07,  ...,  4.4543e-07,\n",
       "             -1.6748e-07, -6.7151e-07],\n",
       "            [-5.3191e-07,  1.8447e-07, -1.3259e-06,  ...,  3.8017e-07,\n",
       "             -8.6277e-07,  1.3576e-06],\n",
       "            [ 8.3972e-08, -1.2309e-06, -5.6347e-07,  ..., -2.4096e-07,\n",
       "              5.1325e-07,  3.8205e-07],\n",
       "            ...,\n",
       "            [ 2.0173e-07, -7.5443e-07, -5.2341e-07,  ..., -3.6349e-07,\n",
       "              9.3745e-07, -8.7525e-07],\n",
       "            [ 1.4121e-06, -3.6880e-07, -1.0184e-07,  ..., -4.1451e-07,\n",
       "              1.9696e-07,  5.2822e-07],\n",
       "            [-2.1721e-07,  2.9503e-07,  5.8667e-07,  ...,  2.2646e-08,\n",
       "             -2.7733e-07, -2.0775e-07]]),\n",
       "    'exp_avg_sq': tensor([[7.2387e-12, 7.2999e-12, 8.4572e-12,  ..., 4.9930e-12, 7.4840e-12,\n",
       "             6.0742e-12],\n",
       "            [8.6146e-12, 6.6080e-12, 8.5870e-12,  ..., 5.8581e-12, 9.0304e-12,\n",
       "             7.5348e-12],\n",
       "            [9.6772e-12, 1.0290e-11, 9.9375e-12,  ..., 5.0675e-12, 7.3834e-12,\n",
       "             7.7034e-12],\n",
       "            ...,\n",
       "            [8.2094e-12, 7.9075e-12, 4.6789e-12,  ..., 4.3034e-12, 1.0223e-11,\n",
       "             9.2082e-12],\n",
       "            [9.5047e-12, 6.1216e-12, 8.5540e-12,  ..., 9.1615e-12, 8.1422e-12,\n",
       "             8.2816e-12],\n",
       "            [6.6466e-12, 6.0029e-12, 7.2943e-12,  ..., 4.5358e-12, 1.2514e-11,\n",
       "             7.9667e-12]])},\n",
       "   'model.layers.10.self_attn.q_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 2.4392e-08, -7.2638e-07, -6.0635e-07,  ..., -2.8925e-07,\n",
       "            -3.1266e-06, -2.0800e-06]),\n",
       "    'exp_avg_sq': tensor([8.1904e-12, 7.7788e-12, 1.0691e-11,  ..., 3.4764e-11, 5.2147e-11,\n",
       "            6.6709e-11])},\n",
       "   'model.layers.10.self_attn.q_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 1.7674e-07,  1.6524e-07,  2.1565e-07,  ..., -1.9798e-09,\n",
       "             -4.5724e-08, -2.7357e-07],\n",
       "            [ 2.4096e-07, -3.8716e-07, -1.9615e-08,  ...,  4.8179e-08,\n",
       "             -1.1131e-07,  2.4217e-07],\n",
       "            [ 9.6953e-08,  1.4513e-07,  1.8243e-07,  ..., -2.2098e-07,\n",
       "              2.9045e-07,  1.4655e-07],\n",
       "            ...,\n",
       "            [-6.2824e-07, -4.5574e-07,  2.7583e-07,  ..., -4.6270e-08,\n",
       "             -5.0837e-07, -1.3728e-06],\n",
       "            [ 4.3681e-07, -4.6517e-07,  2.2163e-07,  ..., -4.0137e-07,\n",
       "             -4.5292e-07, -4.2909e-07],\n",
       "            [ 4.8825e-07, -1.0931e-07,  5.1626e-08,  ...,  1.9363e-07,\n",
       "              3.6783e-07, -3.4564e-07]]),\n",
       "    'exp_avg_sq': tensor([[7.0926e-13, 8.6328e-13, 6.6073e-13,  ..., 5.0842e-13, 5.0293e-13,\n",
       "             4.5050e-13],\n",
       "            [5.6187e-13, 8.8075e-13, 5.9695e-13,  ..., 4.5629e-13, 7.8810e-13,\n",
       "             7.1559e-13],\n",
       "            [1.0033e-12, 1.3809e-12, 1.0558e-12,  ..., 8.0339e-13, 9.7019e-13,\n",
       "             8.8399e-13],\n",
       "            ...,\n",
       "            [5.2214e-12, 5.6406e-12, 4.8490e-12,  ..., 2.5492e-12, 4.3136e-12,\n",
       "             4.3403e-12],\n",
       "            [2.4857e-12, 4.2202e-12, 3.5506e-12,  ..., 2.4267e-12, 3.8512e-12,\n",
       "             3.4820e-12],\n",
       "            [3.5108e-12, 5.1850e-12, 3.1403e-12,  ..., 2.8070e-12, 3.0580e-12,\n",
       "             4.1040e-12]])},\n",
       "   'model.layers.10.self_attn.v_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-1.0229e-05,  3.9546e-06, -8.6914e-06,  ...,  6.2876e-06,\n",
       "             8.5399e-06,  7.3455e-06]),\n",
       "    'exp_avg_sq': tensor([1.0490e-09, 1.7597e-09, 1.9119e-09,  ..., 1.3106e-09, 1.0517e-09,\n",
       "            1.5514e-09])},\n",
       "   'model.layers.10.self_attn.v_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 1.1167e-07,  5.2861e-08,  3.9910e-07,  ...,  2.9651e-07,\n",
       "              1.5507e-07,  6.0324e-07],\n",
       "            [ 3.9177e-07,  3.5419e-08, -1.4262e-07,  ..., -5.4859e-07,\n",
       "              4.2033e-07,  1.7599e-07],\n",
       "            [-6.5591e-07, -8.9127e-07,  5.7827e-08,  ..., -7.5542e-07,\n",
       "              4.3784e-07, -7.1609e-07],\n",
       "            ...,\n",
       "            [-7.9858e-07, -8.8571e-08, -3.1687e-07,  ...,  6.9437e-07,\n",
       "              9.4160e-08, -4.1996e-07],\n",
       "            [-9.1119e-07,  2.0707e-07,  9.3372e-08,  ..., -6.3580e-07,\n",
       "             -1.9908e-07, -1.5344e-07],\n",
       "            [-1.3040e-07,  3.7571e-07, -2.6695e-07,  ..., -7.6903e-07,\n",
       "              5.6653e-07,  1.0367e-06]]),\n",
       "    'exp_avg_sq': tensor([[3.7979e-12, 6.8935e-12, 5.6723e-12,  ..., 5.0745e-12, 2.5453e-12,\n",
       "             4.1281e-12],\n",
       "            [4.9508e-12, 5.7711e-12, 4.5628e-12,  ..., 5.0368e-12, 4.4038e-12,\n",
       "             3.3953e-12],\n",
       "            [3.5421e-12, 5.9161e-12, 3.9822e-12,  ..., 5.3249e-12, 2.9867e-12,\n",
       "             3.0389e-12],\n",
       "            ...,\n",
       "            [5.1856e-12, 5.3102e-12, 2.8808e-12,  ..., 4.3398e-12, 5.1746e-12,\n",
       "             4.2657e-12],\n",
       "            [1.0909e-11, 5.7734e-12, 6.1288e-12,  ..., 5.6446e-12, 6.4221e-12,\n",
       "             5.5409e-12],\n",
       "            [1.2381e-11, 7.0983e-12, 5.6968e-12,  ..., 6.0122e-12, 3.4072e-12,\n",
       "             5.6969e-12]])},\n",
       "   'model.layers.11.input_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-2.8292e-06,  7.4020e-07,  1.3300e-06,  ..., -7.6680e-06,\n",
       "            -4.3620e-08, -3.6611e-07]),\n",
       "    'exp_avg_sq': tensor([5.8588e-10, 1.1854e-09, 9.6705e-10,  ..., 8.8363e-10, 7.3350e-10,\n",
       "            6.9891e-10])},\n",
       "   'model.layers.11.mlp.down_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 1.7288e-07,  6.4907e-07, -5.1381e-07,  ..., -1.3036e-08,\n",
       "             -2.5952e-08,  3.0804e-07],\n",
       "            [-4.8572e-08,  8.7889e-07, -5.1754e-08,  ...,  2.0541e-07,\n",
       "              9.0139e-07, -8.2538e-07],\n",
       "            [-3.9794e-07, -9.6300e-07,  5.6160e-08,  ...,  2.0893e-07,\n",
       "             -9.8451e-07, -3.2399e-07],\n",
       "            ...,\n",
       "            [-4.7584e-08,  2.4385e-07,  5.3776e-07,  ..., -4.5463e-07,\n",
       "              9.1040e-07,  1.0532e-07],\n",
       "            [ 6.0988e-08, -2.7173e-07, -2.4178e-07,  ...,  1.5373e-07,\n",
       "              1.6209e-08,  2.8875e-07],\n",
       "            [-3.8991e-08,  2.5131e-07, -1.3031e-06,  ..., -5.4054e-07,\n",
       "              2.2223e-07, -1.4832e-07]]),\n",
       "    'exp_avg_sq': tensor([[6.4294e-12, 6.6611e-12, 4.6812e-12,  ..., 4.8742e-12, 4.7618e-12,\n",
       "             6.0296e-12],\n",
       "            [6.1568e-12, 6.4519e-12, 2.9526e-12,  ..., 4.4232e-12, 4.4049e-12,\n",
       "             7.6032e-12],\n",
       "            [4.7555e-12, 6.6624e-12, 3.7435e-12,  ..., 4.2563e-12, 6.2138e-12,\n",
       "             7.5568e-12],\n",
       "            ...,\n",
       "            [6.2782e-12, 4.4102e-12, 3.1779e-12,  ..., 5.4394e-12, 6.6155e-12,\n",
       "             7.9645e-12],\n",
       "            [5.6877e-12, 6.6364e-12, 4.7100e-12,  ..., 2.6908e-12, 5.9173e-12,\n",
       "             7.2743e-12],\n",
       "            [4.4367e-12, 5.7754e-12, 5.2455e-12,  ..., 3.8094e-12, 5.0067e-12,\n",
       "             7.9513e-12]])},\n",
       "   'model.layers.11.mlp.gate_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-8.1714e-09, -3.9922e-08, -4.6882e-07,  ...,  6.4736e-07,\n",
       "              6.3657e-07, -5.3303e-07],\n",
       "            [-1.0113e-06,  3.4693e-07, -1.5598e-07,  ...,  8.1196e-08,\n",
       "              9.0438e-07, -9.1918e-08],\n",
       "            [ 1.9337e-08, -1.8048e-09, -4.3984e-07,  ...,  8.5231e-08,\n",
       "             -1.5257e-07,  2.2584e-08],\n",
       "            ...,\n",
       "            [ 4.8195e-08, -5.4113e-07, -7.7618e-07,  ..., -2.5753e-07,\n",
       "              1.4965e-07,  4.0669e-08],\n",
       "            [ 3.4532e-07, -5.4650e-07, -1.9039e-07,  ..., -9.0520e-07,\n",
       "             -9.8732e-07, -1.7326e-07],\n",
       "            [-1.1197e-07,  4.0480e-07,  5.2866e-07,  ...,  5.1960e-07,\n",
       "              3.3048e-07,  1.7606e-07]]),\n",
       "    'exp_avg_sq': tensor([[3.0797e-12, 5.4401e-12, 4.1260e-12,  ..., 5.0841e-12, 5.3505e-12,\n",
       "             4.9452e-12],\n",
       "            [3.9344e-12, 2.8659e-12, 2.1329e-12,  ..., 3.3308e-12, 4.4107e-12,\n",
       "             2.6807e-12],\n",
       "            [3.3009e-12, 2.2246e-12, 4.9173e-12,  ..., 7.0663e-12, 3.0687e-12,\n",
       "             2.9321e-12],\n",
       "            ...,\n",
       "            [2.4414e-12, 3.7572e-12, 4.7759e-12,  ..., 3.9737e-12, 3.2134e-12,\n",
       "             2.7969e-12],\n",
       "            [6.6391e-12, 6.3398e-12, 6.3489e-12,  ..., 6.6956e-12, 5.1504e-12,\n",
       "             5.1340e-12],\n",
       "            [5.9540e-12, 4.9329e-12, 5.7650e-12,  ..., 3.7302e-12, 4.4375e-12,\n",
       "             3.6214e-12]])},\n",
       "   'model.layers.11.mlp.up_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 1.8625e-09,  3.7233e-07, -3.5615e-07,  ..., -1.1677e-06,\n",
       "              1.8917e-08,  9.2006e-09],\n",
       "            [ 9.7880e-08, -1.2601e-08,  4.4326e-07,  ..., -1.0493e-07,\n",
       "              5.3150e-08, -3.9817e-07],\n",
       "            [-2.4035e-07, -7.9440e-07,  4.0208e-07,  ...,  9.1653e-08,\n",
       "              1.9158e-07,  4.5952e-07],\n",
       "            ...,\n",
       "            [ 1.6509e-08,  1.6123e-07,  3.4727e-07,  ..., -3.7097e-07,\n",
       "              3.9741e-07, -1.5353e-07],\n",
       "            [-5.2054e-07, -6.6352e-07,  5.4490e-08,  ..., -4.7957e-07,\n",
       "             -6.6754e-07, -5.9497e-07],\n",
       "            [ 5.8443e-08, -2.6122e-07,  7.8109e-07,  ..., -8.3299e-07,\n",
       "              3.0423e-07, -3.8987e-07]]),\n",
       "    'exp_avg_sq': tensor([[3.0429e-12, 2.6013e-12, 2.4749e-12,  ..., 3.3498e-12, 2.8363e-12,\n",
       "             2.2984e-12],\n",
       "            [2.6846e-12, 3.4229e-12, 2.4015e-12,  ..., 3.3774e-12, 3.4187e-12,\n",
       "             3.0430e-12],\n",
       "            [4.1351e-12, 3.3003e-12, 5.1860e-12,  ..., 6.2460e-12, 4.7494e-12,\n",
       "             5.3683e-12],\n",
       "            ...,\n",
       "            [2.6328e-12, 3.6515e-12, 5.4319e-12,  ..., 4.0665e-12, 3.5175e-12,\n",
       "             4.4528e-12],\n",
       "            [7.1489e-12, 4.2848e-12, 3.7330e-12,  ..., 3.3235e-12, 4.5648e-12,\n",
       "             2.6209e-12],\n",
       "            [3.1768e-12, 5.7136e-12, 8.7387e-12,  ..., 7.2402e-12, 4.2440e-12,\n",
       "             4.3665e-12]])},\n",
       "   'model.layers.11.post_attention_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-3.9866e-06, -5.0771e-06, -1.5699e-05,  ..., -5.1208e-06,\n",
       "             2.9496e-06,  5.9807e-06]),\n",
       "    'exp_avg_sq': tensor([5.1432e-10, 1.1401e-09, 1.1303e-09,  ..., 1.0459e-09, 6.6979e-10,\n",
       "            9.6558e-10])},\n",
       "   'model.layers.11.self_attn.k_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 2.8730e-07, -1.2318e-07, -1.3223e-06,  ..., -3.0954e-10,\n",
       "             7.2014e-09,  1.0690e-08]),\n",
       "    'exp_avg_sq': tensor([7.7791e-12, 1.3673e-11, 1.9002e-11,  ..., 4.1966e-16, 4.0990e-16,\n",
       "            4.3034e-16])},\n",
       "   'model.layers.11.self_attn.k_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 1.8504e-07, -2.2093e-07, -1.7205e-07,  ...,  6.9095e-07,\n",
       "             -8.5263e-08,  1.2882e-07],\n",
       "            [-1.4994e-07, -5.4773e-07,  1.7990e-07,  ..., -1.8998e-08,\n",
       "              3.0142e-07,  5.5729e-08],\n",
       "            [-2.3485e-07, -2.1288e-07, -5.2043e-08,  ..., -2.5815e-07,\n",
       "             -2.0358e-07,  6.0758e-08],\n",
       "            ...,\n",
       "            [-5.2328e-08,  6.6003e-07, -7.0560e-08,  ..., -9.3906e-08,\n",
       "              1.7064e-07,  1.2439e-08],\n",
       "            [ 7.4285e-07, -1.2831e-07,  4.4851e-07,  ..., -1.7353e-07,\n",
       "             -4.0225e-07,  2.6082e-07],\n",
       "            [ 3.2689e-07, -4.5195e-07,  2.9893e-08,  ..., -4.3906e-08,\n",
       "              3.0888e-07, -6.5196e-07]]),\n",
       "    'exp_avg_sq': tensor([[8.6194e-13, 1.3922e-12, 8.7619e-13,  ..., 1.2683e-12, 7.7635e-13,\n",
       "             9.1436e-13],\n",
       "            [1.0535e-12, 1.6468e-12, 1.8516e-12,  ..., 1.0464e-12, 1.8636e-12,\n",
       "             1.3333e-12],\n",
       "            [1.0547e-12, 1.4598e-12, 1.2319e-12,  ..., 1.1427e-12, 1.1232e-12,\n",
       "             2.0369e-12],\n",
       "            ...,\n",
       "            [2.8588e-12, 8.6535e-12, 6.3535e-12,  ..., 8.2683e-12, 7.7094e-12,\n",
       "             5.5086e-12],\n",
       "            [3.0126e-12, 5.8290e-12, 3.7689e-12,  ..., 2.6643e-12, 3.4020e-12,\n",
       "             3.6819e-12],\n",
       "            [2.7197e-12, 5.1983e-12, 4.2107e-12,  ..., 7.1327e-12, 5.8566e-12,\n",
       "             5.9236e-12]])},\n",
       "   'model.layers.11.self_attn.o_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-5.4981e-07,  6.9282e-08, -2.1692e-07,  ...,  1.6193e-06,\n",
       "              1.6649e-06, -2.6351e-06],\n",
       "            [ 1.1235e-06, -1.0950e-06, -9.3903e-07,  ...,  1.4570e-07,\n",
       "             -1.9123e-06,  1.7178e-06],\n",
       "            [-5.5057e-07, -5.6545e-07,  1.7291e-06,  ..., -1.1711e-06,\n",
       "             -5.4488e-07, -5.9809e-07],\n",
       "            ...,\n",
       "            [ 1.4379e-06,  9.9503e-07,  4.0300e-07,  ..., -1.7840e-07,\n",
       "              2.4337e-07, -9.6276e-08],\n",
       "            [ 5.0002e-07,  1.6662e-07,  3.3892e-07,  ..., -2.1565e-06,\n",
       "             -2.5615e-07, -5.3358e-07],\n",
       "            [-2.5193e-07, -2.2846e-07, -4.9164e-07,  ...,  4.9800e-07,\n",
       "             -1.0063e-06, -1.8357e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.3669e-11, 1.2974e-11, 1.0602e-11,  ..., 1.9995e-11, 1.4541e-11,\n",
       "             2.4315e-11],\n",
       "            [1.4914e-11, 1.7005e-11, 1.0274e-11,  ..., 2.2893e-11, 2.4230e-11,\n",
       "             1.7625e-11],\n",
       "            [1.2551e-11, 1.7218e-11, 1.3940e-11,  ..., 3.0115e-11, 2.0647e-11,\n",
       "             1.7960e-11],\n",
       "            ...,\n",
       "            [1.0826e-11, 2.3480e-11, 8.7331e-12,  ..., 2.6080e-11, 2.1299e-11,\n",
       "             2.3040e-11],\n",
       "            [2.1670e-11, 1.5995e-11, 7.3754e-12,  ..., 2.9412e-11, 2.8033e-11,\n",
       "             1.7888e-11],\n",
       "            [9.6326e-12, 1.4427e-11, 6.3042e-12,  ..., 2.6045e-11, 1.9331e-11,\n",
       "             1.4881e-11]])},\n",
       "   'model.layers.11.self_attn.q_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 6.8199e-07, -6.1246e-07, -9.3121e-07,  ...,  3.5399e-06,\n",
       "            -3.7390e-06, -1.2279e-06]),\n",
       "    'exp_avg_sq': tensor([8.8870e-12, 3.1624e-11, 9.0191e-12,  ..., 2.8161e-10, 1.4966e-10,\n",
       "            3.5943e-10])},\n",
       "   'model.layers.11.self_attn.q_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-9.8897e-08,  2.8079e-08, -6.5623e-08,  ..., -1.5035e-07,\n",
       "              1.0797e-07, -3.4290e-07],\n",
       "            [ 6.0626e-08,  7.2244e-09, -1.6935e-07,  ..., -3.1937e-07,\n",
       "             -4.8928e-07,  3.9017e-07],\n",
       "            [-6.0181e-08, -2.5095e-07,  8.1143e-07,  ..., -2.2248e-07,\n",
       "              8.3039e-08, -8.6219e-08],\n",
       "            ...,\n",
       "            [-1.6963e-07, -6.0278e-07,  8.0498e-08,  ..., -1.0427e-07,\n",
       "             -4.5333e-07,  4.4947e-07],\n",
       "            [ 7.3730e-07, -5.8888e-07, -2.9667e-07,  ..., -7.3953e-07,\n",
       "             -1.1531e-07, -7.4689e-08],\n",
       "            [-5.8449e-07, -1.0670e-06, -1.0666e-06,  ..., -2.4258e-07,\n",
       "             -2.6063e-07, -4.7734e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.2869e-12, 1.2516e-12, 1.4410e-12,  ..., 1.1022e-12, 8.2887e-13,\n",
       "             1.6537e-12],\n",
       "            [9.8314e-13, 2.0233e-12, 1.6573e-12,  ..., 2.3359e-12, 2.7754e-12,\n",
       "             2.2971e-12],\n",
       "            [9.6770e-13, 1.3105e-12, 2.2837e-12,  ..., 1.3003e-12, 1.6403e-12,\n",
       "             1.1914e-12],\n",
       "            ...,\n",
       "            [5.0992e-12, 7.9445e-12, 1.0898e-11,  ..., 8.3474e-12, 8.7398e-12,\n",
       "             8.6176e-12],\n",
       "            [5.4393e-12, 2.1549e-11, 1.1885e-11,  ..., 7.1927e-12, 6.1839e-12,\n",
       "             4.3944e-12],\n",
       "            [7.3903e-12, 3.1685e-11, 1.9131e-11,  ..., 1.1240e-11, 8.9074e-12,\n",
       "             9.6494e-12]])},\n",
       "   'model.layers.11.self_attn.v_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-1.3643e-05, -7.5215e-06,  6.1837e-06,  ...,  1.2663e-05,\n",
       "             7.0225e-06,  1.7584e-06]),\n",
       "    'exp_avg_sq': tensor([2.4871e-09, 1.4438e-09, 2.9683e-09,  ..., 2.1696e-09, 1.3169e-09,\n",
       "            1.2793e-09])},\n",
       "   'model.layers.11.self_attn.v_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 2.1319e-08, -8.7950e-07, -5.6514e-07,  ..., -2.5323e-07,\n",
       "             -1.4661e-08,  7.3860e-07],\n",
       "            [ 6.8807e-08, -1.0030e-06, -1.1339e-06,  ...,  3.0349e-07,\n",
       "              4.9839e-07,  4.0428e-07],\n",
       "            [ 5.5918e-07, -4.7619e-07,  4.5309e-08,  ...,  8.5591e-08,\n",
       "             -6.6123e-07,  3.2236e-07],\n",
       "            ...,\n",
       "            [ 3.4956e-07,  1.8177e-07,  2.7180e-07,  ...,  7.8502e-07,\n",
       "             -4.6970e-07,  8.9869e-07],\n",
       "            [ 6.1525e-08, -7.9511e-07,  4.8698e-07,  ..., -2.5918e-07,\n",
       "             -2.4199e-07,  2.5668e-07],\n",
       "            [-2.1002e-07, -5.4995e-07,  2.5680e-07,  ...,  4.6685e-07,\n",
       "             -7.4202e-07,  2.7629e-07]]),\n",
       "    'exp_avg_sq': tensor([[9.0252e-12, 7.1806e-12, 1.0014e-11,  ..., 1.6024e-11, 9.2575e-12,\n",
       "             1.2140e-11],\n",
       "            [6.2188e-12, 7.7965e-12, 7.1438e-12,  ..., 5.9952e-12, 7.0457e-12,\n",
       "             1.1021e-11],\n",
       "            [1.6163e-11, 1.4222e-11, 1.3986e-11,  ..., 1.0296e-11, 8.9955e-12,\n",
       "             1.4660e-11],\n",
       "            ...,\n",
       "            [8.9338e-12, 8.2941e-12, 1.4776e-11,  ..., 1.2699e-11, 1.6322e-11,\n",
       "             1.6704e-11],\n",
       "            [1.0031e-11, 1.2091e-11, 2.1500e-11,  ..., 1.6697e-11, 1.7140e-11,\n",
       "             1.7983e-11],\n",
       "            [9.2507e-12, 1.3894e-11, 1.1862e-11,  ..., 1.3501e-11, 2.1352e-11,\n",
       "             8.2410e-12]])},\n",
       "   'model.layers.12.input_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-6.5322e-07, -2.5485e-06,  2.8966e-06,  ...,  2.0320e-08,\n",
       "            -4.6577e-06,  4.3184e-07]),\n",
       "    'exp_avg_sq': tensor([9.1174e-10, 6.3902e-10, 1.1011e-09,  ..., 4.3934e-10, 6.7840e-10,\n",
       "            7.9884e-10])},\n",
       "   'model.layers.12.mlp.down_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 9.2962e-07, -1.0081e-07, -1.3593e-08,  ..., -1.0048e-07,\n",
       "             -9.3494e-07, -4.0309e-07],\n",
       "            [-4.0441e-07, -6.6820e-07, -4.6144e-07,  ...,  4.0153e-07,\n",
       "              6.4423e-07,  9.5599e-07],\n",
       "            [-4.2120e-07, -5.9706e-07, -1.7047e-07,  ..., -7.3079e-09,\n",
       "              8.1031e-07, -2.7435e-07],\n",
       "            ...,\n",
       "            [-2.9411e-07,  3.2003e-07,  5.7117e-07,  ..., -1.1834e-07,\n",
       "             -1.1985e-06,  1.2449e-07],\n",
       "            [ 2.2234e-07, -5.5188e-07,  2.8789e-07,  ...,  2.1454e-07,\n",
       "             -2.7751e-07,  6.1754e-07],\n",
       "            [ 3.5852e-07,  5.0983e-07, -9.2655e-07,  ...,  6.2774e-07,\n",
       "              6.7816e-07, -2.2485e-07]]),\n",
       "    'exp_avg_sq': tensor([[5.4330e-12, 6.8873e-12, 5.4354e-12,  ..., 5.9436e-12, 1.0011e-11,\n",
       "             4.7739e-12],\n",
       "            [3.7419e-12, 6.6028e-12, 7.8232e-12,  ..., 7.6420e-12, 9.1337e-12,\n",
       "             6.2591e-12],\n",
       "            [7.0945e-12, 6.9530e-12, 7.6078e-12,  ..., 3.9585e-12, 8.8124e-12,\n",
       "             7.7521e-12],\n",
       "            ...,\n",
       "            [5.5301e-12, 7.5037e-12, 4.8358e-12,  ..., 6.7482e-12, 7.1299e-12,\n",
       "             3.6117e-12],\n",
       "            [3.9987e-12, 6.1470e-12, 5.0066e-12,  ..., 6.5693e-12, 6.7091e-12,\n",
       "             5.7511e-12],\n",
       "            [5.1871e-12, 7.8660e-12, 6.6966e-12,  ..., 6.2019e-12, 8.0039e-12,\n",
       "             6.9220e-12]])},\n",
       "   'model.layers.12.mlp.gate_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 4.1765e-07,  6.4792e-07, -2.2953e-07,  ...,  1.4728e-07,\n",
       "              2.4188e-07, -2.3147e-07],\n",
       "            [-2.6475e-07,  1.2376e-07, -2.5436e-07,  ..., -4.5451e-07,\n",
       "             -3.9272e-07,  1.0514e-06],\n",
       "            [-4.8141e-07, -5.7523e-07, -6.5587e-08,  ..., -1.2174e-07,\n",
       "             -8.9767e-08,  1.1754e-06],\n",
       "            ...,\n",
       "            [ 8.8787e-07,  6.8579e-07,  1.2206e-07,  ...,  1.0461e-06,\n",
       "             -1.2893e-06, -4.0537e-07],\n",
       "            [ 9.6479e-08,  7.6378e-07,  5.7906e-07,  ...,  1.2888e-07,\n",
       "              4.7070e-07,  1.4756e-08],\n",
       "            [ 6.2670e-07, -4.4606e-07,  4.6094e-07,  ..., -1.3471e-07,\n",
       "              9.0337e-07,  9.7946e-07]]),\n",
       "    'exp_avg_sq': tensor([[4.9377e-12, 4.1726e-12, 3.3329e-12,  ..., 6.6806e-12, 3.6164e-12,\n",
       "             5.5682e-12],\n",
       "            [7.3566e-12, 6.0562e-12, 6.7084e-12,  ..., 7.4906e-12, 6.8697e-12,\n",
       "             9.6435e-12],\n",
       "            [5.1788e-12, 5.4869e-12, 4.7270e-12,  ..., 4.8727e-12, 5.5832e-12,\n",
       "             1.0382e-11],\n",
       "            ...,\n",
       "            [7.1393e-12, 6.3629e-12, 5.1516e-12,  ..., 5.9529e-12, 7.3180e-12,\n",
       "             6.3193e-12],\n",
       "            [6.8694e-12, 3.6047e-12, 5.0302e-12,  ..., 5.5107e-12, 4.7259e-12,\n",
       "             6.3013e-12],\n",
       "            [9.1670e-12, 4.3938e-12, 3.0873e-12,  ..., 3.9102e-12, 6.9758e-12,\n",
       "             9.7322e-12]])},\n",
       "   'model.layers.12.mlp.up_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 2.5074e-07, -1.0987e-07, -5.3291e-07,  ...,  1.6383e-07,\n",
       "              1.9077e-07, -1.5293e-06],\n",
       "            [ 2.4453e-07,  1.8930e-07, -5.5052e-07,  ...,  9.7134e-07,\n",
       "              5.4677e-07, -4.8941e-07],\n",
       "            [ 1.0145e-07, -3.7126e-07,  6.9062e-07,  ..., -6.0566e-07,\n",
       "             -5.4585e-07, -1.1715e-06],\n",
       "            ...,\n",
       "            [ 3.3174e-07,  1.1248e-07,  2.7059e-07,  ..., -1.5298e-07,\n",
       "             -3.2450e-07,  7.5608e-07],\n",
       "            [ 6.9471e-08, -2.5318e-07, -1.0755e-06,  ...,  3.9031e-07,\n",
       "             -7.3528e-07,  3.7639e-08],\n",
       "            [-6.4507e-07,  6.4503e-08,  1.1661e-07,  ..., -1.1931e-07,\n",
       "              9.2358e-07, -7.1582e-07]]),\n",
       "    'exp_avg_sq': tensor([[4.7838e-12, 3.9468e-12, 4.6693e-12,  ..., 4.9641e-12, 5.0324e-12,\n",
       "             5.7223e-12],\n",
       "            [5.6863e-12, 7.0152e-12, 5.9894e-12,  ..., 7.5860e-12, 4.9232e-12,\n",
       "             8.1273e-12],\n",
       "            [3.7748e-12, 5.4270e-12, 4.6442e-12,  ..., 5.2594e-12, 4.0736e-12,\n",
       "             6.8506e-12],\n",
       "            ...,\n",
       "            [3.7748e-12, 4.7642e-12, 4.8770e-12,  ..., 5.4657e-12, 2.4766e-12,\n",
       "             4.5612e-12],\n",
       "            [3.4386e-12, 3.9973e-12, 4.1842e-12,  ..., 3.5362e-12, 5.6356e-12,\n",
       "             3.7430e-12],\n",
       "            [7.1652e-12, 4.6443e-12, 4.3231e-12,  ..., 5.1850e-12, 4.7751e-12,\n",
       "             6.3258e-12]])},\n",
       "   'model.layers.12.post_attention_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-1.3915e-08, -1.5467e-05, -8.1122e-06,  ..., -1.2964e-05,\n",
       "             7.2043e-07, -1.4130e-05]),\n",
       "    'exp_avg_sq': tensor([7.0585e-10, 9.5162e-10, 1.1199e-09,  ..., 1.1182e-09, 9.9128e-10,\n",
       "            6.4835e-10])},\n",
       "   'model.layers.12.self_attn.k_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-2.4958e-06, -1.6032e-06,  3.0207e-06,  ..., -1.8413e-09,\n",
       "             4.0890e-09,  1.9870e-09]),\n",
       "    'exp_avg_sq': tensor([3.5172e-11, 2.1878e-11, 2.5839e-11,  ..., 3.5539e-16, 2.4116e-16,\n",
       "            2.5248e-16])},\n",
       "   'model.layers.12.self_attn.k_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 5.5467e-07, -8.7526e-07,  3.9129e-07,  ...,  8.4868e-08,\n",
       "             -5.5733e-07,  1.6865e-07],\n",
       "            [ 3.8283e-07,  1.1692e-07,  1.3005e-07,  ...,  3.1844e-07,\n",
       "             -3.0396e-07, -4.1628e-07],\n",
       "            [ 8.4592e-08,  3.0440e-07,  3.9721e-07,  ..., -7.8041e-08,\n",
       "             -1.6886e-07, -5.0092e-07],\n",
       "            ...,\n",
       "            [-5.9455e-07, -6.1281e-07, -3.1694e-07,  ..., -4.3222e-07,\n",
       "              6.3154e-07, -4.0571e-07],\n",
       "            [ 6.7154e-07,  3.9411e-07,  2.8625e-07,  ...,  5.3085e-07,\n",
       "              6.8378e-08, -6.4009e-07],\n",
       "            [ 1.3607e-07, -7.9123e-07,  1.7576e-07,  ..., -7.0919e-08,\n",
       "              1.0130e-07, -4.1507e-07]]),\n",
       "    'exp_avg_sq': tensor([[3.9759e-12, 5.1186e-12, 3.8560e-12,  ..., 2.5494e-12, 5.1087e-12,\n",
       "             2.8279e-12],\n",
       "            [2.0225e-12, 3.6895e-12, 3.1835e-12,  ..., 2.3103e-12, 3.0028e-12,\n",
       "             2.3691e-12],\n",
       "            [2.6262e-12, 3.0370e-12, 2.4857e-12,  ..., 1.9292e-12, 3.9553e-12,\n",
       "             2.5923e-12],\n",
       "            ...,\n",
       "            [3.3474e-12, 3.3028e-12, 2.2448e-12,  ..., 2.2933e-12, 3.9040e-12,\n",
       "             2.6220e-12],\n",
       "            [2.7002e-12, 2.8073e-12, 3.1245e-12,  ..., 1.7297e-12, 2.2530e-12,\n",
       "             2.2967e-12],\n",
       "            [2.0866e-12, 4.5677e-12, 2.2741e-12,  ..., 3.1629e-12, 2.7186e-12,\n",
       "             3.8792e-12]])},\n",
       "   'model.layers.12.self_attn.o_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-5.9954e-08, -1.6508e-06, -6.7904e-08,  ...,  1.0031e-06,\n",
       "             -1.5481e-06,  9.1032e-08],\n",
       "            [-9.7012e-07,  4.3353e-07,  8.7892e-07,  ...,  7.7310e-07,\n",
       "              7.3842e-07, -9.6332e-07],\n",
       "            [-3.1765e-07, -5.2996e-07,  2.5339e-08,  ..., -6.7304e-07,\n",
       "              1.4420e-06, -1.0802e-07],\n",
       "            ...,\n",
       "            [ 7.7407e-07,  4.8390e-07, -1.8652e-06,  ..., -7.0163e-08,\n",
       "              1.1085e-07,  4.4980e-07],\n",
       "            [-1.5597e-06,  2.6948e-07,  5.9765e-07,  ..., -1.5889e-07,\n",
       "              2.1780e-07, -4.1708e-07],\n",
       "            [-3.5737e-07, -1.6939e-06, -3.9422e-07,  ..., -5.5659e-07,\n",
       "              1.0870e-06, -2.7438e-08]]),\n",
       "    'exp_avg_sq': tensor([[6.1502e-12, 1.2042e-11, 1.3007e-11,  ..., 1.1512e-11, 9.0003e-12,\n",
       "             1.1041e-11],\n",
       "            [1.0120e-11, 1.3448e-11, 1.5380e-11,  ..., 8.0597e-12, 8.4912e-12,\n",
       "             1.3845e-11],\n",
       "            [1.2258e-11, 9.6755e-12, 1.5371e-11,  ..., 1.1152e-11, 8.2816e-12,\n",
       "             9.7506e-12],\n",
       "            ...,\n",
       "            [8.2254e-12, 1.7756e-11, 2.3347e-11,  ..., 7.4565e-12, 9.5042e-12,\n",
       "             7.9823e-12],\n",
       "            [1.8622e-11, 1.1631e-11, 8.0486e-12,  ..., 1.4524e-11, 1.0717e-11,\n",
       "             1.2478e-11],\n",
       "            [1.6741e-11, 1.0243e-11, 1.7288e-11,  ..., 1.5549e-11, 8.1753e-12,\n",
       "             9.9628e-12]])},\n",
       "   'model.layers.12.self_attn.q_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-2.6151e-06,  3.2221e-07, -7.1382e-07,  ..., -1.4564e-06,\n",
       "             7.7985e-07,  5.9912e-07]),\n",
       "    'exp_avg_sq': tensor([3.7717e-11, 2.6896e-11, 4.0565e-11,  ..., 3.7394e-11, 3.0463e-11,\n",
       "            2.9547e-11])},\n",
       "   'model.layers.12.self_attn.q_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 5.0814e-07, -6.0192e-07,  2.6715e-07,  ...,  1.4097e-07,\n",
       "             -1.4774e-07,  3.0582e-07],\n",
       "            [-3.5063e-07,  8.8412e-08, -2.3593e-07,  ...,  8.2974e-07,\n",
       "             -1.6156e-07, -1.5132e-07],\n",
       "            [-5.7352e-08,  8.2083e-07,  5.4490e-07,  ...,  2.7529e-07,\n",
       "              4.1411e-07,  3.9639e-07],\n",
       "            ...,\n",
       "            [ 6.0550e-07,  1.5951e-07, -9.0607e-08,  ..., -4.4940e-07,\n",
       "             -4.3976e-07, -5.2263e-08],\n",
       "            [-2.5327e-07,  3.4038e-08, -7.4979e-08,  ..., -3.5312e-07,\n",
       "              1.4095e-07, -4.2793e-07],\n",
       "            [-5.5745e-07,  2.1162e-07, -6.4020e-08,  ..., -1.1465e-08,\n",
       "              3.5809e-07, -6.8616e-07]]),\n",
       "    'exp_avg_sq': tensor([[4.0452e-12, 3.6544e-12, 4.3246e-12,  ..., 3.9461e-12, 4.3017e-12,\n",
       "             5.6922e-12],\n",
       "            [2.6907e-12, 3.3337e-12, 2.0230e-12,  ..., 2.9081e-12, 3.2262e-12,\n",
       "             2.9447e-12],\n",
       "            [3.1036e-12, 6.0156e-12, 3.9112e-12,  ..., 3.7507e-12, 5.1241e-12,\n",
       "             3.0907e-12],\n",
       "            ...,\n",
       "            [2.1732e-12, 3.2259e-12, 2.9157e-12,  ..., 2.6659e-12, 3.7770e-12,\n",
       "             2.8772e-12],\n",
       "            [1.6494e-12, 1.9698e-12, 3.9136e-12,  ..., 3.0320e-12, 3.4606e-12,\n",
       "             2.7397e-12],\n",
       "            [1.7954e-12, 3.4199e-12, 2.3608e-12,  ..., 2.2701e-12, 3.6577e-12,\n",
       "             3.9720e-12]])},\n",
       "   'model.layers.12.self_attn.v_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-8.7072e-06, -5.0353e-06, -2.3428e-06,  ..., -1.2080e-05,\n",
       "             7.2053e-06,  6.7016e-06]),\n",
       "    'exp_avg_sq': tensor([1.3654e-09, 1.6622e-09, 7.6359e-10,  ..., 1.9947e-09, 1.1214e-09,\n",
       "            1.1427e-09])},\n",
       "   'model.layers.12.self_attn.v_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 2.8902e-07,  1.6469e-06, -1.0244e-06,  ...,  7.6166e-07,\n",
       "             -1.3443e-06,  3.2884e-07],\n",
       "            [ 4.2704e-07, -5.9344e-07, -7.3733e-07,  ...,  4.9467e-07,\n",
       "              2.1310e-07,  6.2037e-07],\n",
       "            [-7.7872e-07, -1.0460e-06, -7.4520e-07,  ..., -8.2429e-08,\n",
       "             -7.7380e-07,  4.8292e-07],\n",
       "            ...,\n",
       "            [-6.6718e-07, -9.5812e-08, -6.2665e-07,  ...,  2.7102e-07,\n",
       "             -9.0108e-07,  8.5306e-07],\n",
       "            [-8.9455e-07,  7.6178e-07, -6.7397e-07,  ...,  2.5498e-07,\n",
       "             -6.1871e-07,  2.2414e-07],\n",
       "            [-9.1930e-07, -7.3040e-07, -2.2411e-07,  ...,  4.8350e-07,\n",
       "              6.1459e-07, -5.2747e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.0970e-11, 1.4268e-11, 7.4330e-12,  ..., 1.1920e-11, 1.1224e-11,\n",
       "             9.5431e-12],\n",
       "            [8.3616e-12, 1.8237e-11, 9.1888e-12,  ..., 1.2108e-11, 6.5330e-12,\n",
       "             1.4187e-11],\n",
       "            [1.2869e-11, 1.0414e-11, 1.0086e-11,  ..., 1.3309e-11, 1.1823e-11,\n",
       "             9.4555e-12],\n",
       "            ...,\n",
       "            [6.1296e-12, 1.2360e-11, 1.1518e-11,  ..., 8.5775e-12, 6.4722e-12,\n",
       "             5.9489e-12],\n",
       "            [4.1178e-12, 7.3778e-12, 1.5524e-11,  ..., 1.2931e-11, 1.0270e-11,\n",
       "             4.9788e-12],\n",
       "            [7.2085e-12, 7.1077e-12, 6.8920e-12,  ..., 7.0122e-12, 8.8150e-12,\n",
       "             5.8303e-12]])},\n",
       "   'model.layers.13.input_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 3.0968e-06,  2.3204e-06, -8.5470e-07,  ...,  9.8972e-07,\n",
       "             2.1363e-06,  3.6139e-06]),\n",
       "    'exp_avg_sq': tensor([3.6463e-10, 7.5471e-10, 4.3884e-10,  ..., 6.5755e-10, 5.4726e-10,\n",
       "            6.9638e-10])},\n",
       "   'model.layers.13.mlp.down_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-1.0080e-07, -1.0246e-06,  1.4184e-07,  ...,  1.1678e-06,\n",
       "              1.4905e-07, -3.9003e-08],\n",
       "            [ 5.3101e-07,  9.1288e-07,  1.3501e-07,  ...,  1.7738e-07,\n",
       "              2.2516e-07, -7.0921e-07],\n",
       "            [ 1.8814e-07, -5.5383e-07, -2.1826e-07,  ..., -1.3269e-07,\n",
       "             -1.1328e-06,  5.0312e-07],\n",
       "            ...,\n",
       "            [ 2.0901e-07, -1.0538e-06, -6.1121e-07,  ..., -6.2258e-07,\n",
       "              1.7653e-07,  5.6185e-07],\n",
       "            [ 3.3309e-07,  1.1863e-06,  1.6625e-06,  ..., -3.0569e-07,\n",
       "             -1.8721e-07, -4.5751e-07],\n",
       "            [ 2.4355e-08,  3.3181e-08, -9.8030e-07,  ...,  9.5616e-07,\n",
       "              1.0757e-06, -2.2180e-07]]),\n",
       "    'exp_avg_sq': tensor([[3.9364e-12, 1.4526e-11, 7.1093e-12,  ..., 1.0655e-11, 5.6183e-12,\n",
       "             4.7104e-12],\n",
       "            [6.4415e-12, 1.7762e-11, 5.7026e-12,  ..., 9.0768e-12, 5.3170e-12,\n",
       "             3.2015e-12],\n",
       "            [3.8751e-12, 2.9943e-11, 6.6532e-12,  ..., 9.1168e-12, 5.3377e-12,\n",
       "             4.9142e-12],\n",
       "            ...,\n",
       "            [5.4332e-12, 2.7655e-11, 6.1310e-12,  ..., 5.6095e-12, 4.6113e-12,\n",
       "             7.3211e-12],\n",
       "            [6.3532e-12, 2.9137e-11, 8.0075e-12,  ..., 4.3137e-12, 4.5120e-12,\n",
       "             5.2259e-12],\n",
       "            [5.5990e-12, 1.4593e-11, 6.7109e-12,  ..., 6.0591e-12, 6.4662e-12,\n",
       "             6.5904e-12]])},\n",
       "   'model.layers.13.mlp.gate_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 4.2242e-07,  1.5567e-07, -1.0216e-06,  ...,  4.4921e-08,\n",
       "             -2.3785e-07,  3.1673e-07],\n",
       "            [ 2.8747e-08, -7.0850e-07, -5.7213e-07,  ..., -2.7786e-07,\n",
       "             -3.8982e-07,  2.0993e-07],\n",
       "            [ 2.3464e-07, -2.3064e-07, -5.6222e-08,  ...,  8.9975e-08,\n",
       "              3.8754e-07,  5.3082e-07],\n",
       "            ...,\n",
       "            [-4.0405e-07, -2.7387e-07, -4.9702e-07,  ..., -1.2653e-06,\n",
       "             -1.0795e-07,  4.8007e-07],\n",
       "            [-3.9492e-07, -3.8746e-07,  3.5927e-07,  ..., -4.6009e-07,\n",
       "              9.4107e-07, -2.4214e-07],\n",
       "            [ 1.5276e-07, -5.3263e-07, -3.5335e-08,  ..., -1.9451e-07,\n",
       "             -5.2098e-07, -4.2977e-07]]),\n",
       "    'exp_avg_sq': tensor([[5.0083e-12, 6.1151e-12, 5.0576e-12,  ..., 4.5563e-12, 5.1576e-12,\n",
       "             6.9601e-12],\n",
       "            [4.6975e-12, 1.1009e-11, 1.1454e-11,  ..., 9.1105e-12, 7.0663e-12,\n",
       "             8.7440e-12],\n",
       "            [6.7130e-12, 3.4837e-12, 3.6612e-12,  ..., 3.7389e-12, 4.4319e-12,\n",
       "             3.6146e-12],\n",
       "            ...,\n",
       "            [4.8698e-12, 5.5887e-12, 5.6350e-12,  ..., 5.8122e-12, 5.0031e-12,\n",
       "             3.4051e-12],\n",
       "            [2.8028e-12, 3.1624e-12, 3.6636e-12,  ..., 5.8797e-12, 3.8072e-12,\n",
       "             4.1234e-12],\n",
       "            [2.8057e-12, 2.7238e-12, 4.4138e-12,  ..., 2.7561e-12, 4.5902e-12,\n",
       "             3.8630e-12]])},\n",
       "   'model.layers.13.mlp.up_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 2.5508e-07, -7.0503e-08,  8.7644e-08,  ..., -4.8231e-07,\n",
       "              9.1433e-07,  1.0273e-06],\n",
       "            [-9.2014e-07,  2.5604e-07,  5.0993e-07,  ..., -7.1376e-07,\n",
       "             -9.3187e-07, -5.7691e-07],\n",
       "            [ 5.3011e-07, -6.2168e-07,  1.2408e-07,  ..., -8.4806e-07,\n",
       "             -2.2881e-07,  4.2842e-07],\n",
       "            ...,\n",
       "            [-9.0625e-07, -7.0058e-07, -2.1447e-07,  ...,  2.8303e-07,\n",
       "             -2.1162e-07,  3.6166e-09],\n",
       "            [-4.4967e-07, -2.4361e-07,  1.9837e-07,  ...,  5.7628e-07,\n",
       "              3.3260e-08,  3.4589e-08],\n",
       "            [-4.4320e-07, -4.4884e-07, -3.2015e-08,  ..., -3.8616e-08,\n",
       "              2.5723e-08,  4.0028e-07]]),\n",
       "    'exp_avg_sq': tensor([[3.5618e-12, 3.8479e-12, 2.7748e-12,  ..., 4.4684e-12, 3.1732e-12,\n",
       "             3.7237e-12],\n",
       "            [4.7413e-12, 4.1335e-12, 7.9639e-12,  ..., 3.7196e-12, 6.8225e-12,\n",
       "             5.9748e-12],\n",
       "            [4.7551e-12, 4.0893e-12, 3.2951e-12,  ..., 5.7848e-12, 3.7068e-12,\n",
       "             3.9012e-12],\n",
       "            ...,\n",
       "            [4.7549e-12, 4.6893e-12, 5.1126e-12,  ..., 4.3480e-12, 6.3497e-12,\n",
       "             2.9288e-12],\n",
       "            [4.1490e-12, 4.3619e-12, 5.1402e-12,  ..., 4.3440e-12, 3.6300e-12,\n",
       "             3.6397e-12],\n",
       "            [3.1368e-12, 2.6929e-12, 2.9679e-12,  ..., 2.7889e-12, 2.7214e-12,\n",
       "             3.5363e-12]])},\n",
       "   'model.layers.13.post_attention_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 3.5970e-06, -4.5144e-06,  1.2648e-06,  ..., -4.2268e-06,\n",
       "             6.4671e-06, -1.0359e-06]),\n",
       "    'exp_avg_sq': tensor([1.1183e-09, 7.3210e-10, 1.0124e-09,  ..., 5.9451e-10, 1.0435e-09,\n",
       "            5.9302e-10])},\n",
       "   'model.layers.13.self_attn.k_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-1.2309e-07, -7.8563e-07, -1.3855e-07,  ..., -2.9624e-09,\n",
       "            -1.5122e-09, -3.8763e-09]),\n",
       "    'exp_avg_sq': tensor([2.1277e-11, 1.3490e-11, 2.3311e-11,  ..., 1.9301e-16, 2.3765e-16,\n",
       "            2.4722e-16])},\n",
       "   'model.layers.13.self_attn.k_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 3.4516e-07,  3.6919e-07, -1.2368e-07,  ...,  2.5176e-08,\n",
       "              9.7867e-10,  8.8025e-08],\n",
       "            [ 2.8385e-07,  4.4158e-07, -6.0125e-08,  ..., -2.7009e-07,\n",
       "             -1.1164e-07, -1.7864e-07],\n",
       "            [ 8.3491e-08,  8.8574e-08, -1.4787e-07,  ...,  4.3029e-07,\n",
       "             -2.3236e-07,  2.2485e-07],\n",
       "            ...,\n",
       "            [-2.1066e-07, -7.6391e-08,  5.6999e-09,  ..., -9.0186e-08,\n",
       "              3.0937e-07, -4.8711e-08],\n",
       "            [ 5.1333e-07, -6.1647e-07,  6.1855e-07,  ..., -2.0788e-07,\n",
       "             -2.5140e-08,  1.5835e-07],\n",
       "            [-2.7821e-07,  1.0538e-07, -3.7526e-07,  ..., -2.1630e-07,\n",
       "              8.6662e-08,  8.4976e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.5257e-12, 2.1458e-12, 1.2554e-12,  ..., 1.9020e-12, 3.6730e-12,\n",
       "             1.9314e-12],\n",
       "            [1.8340e-12, 1.8595e-12, 7.3943e-13,  ..., 3.1419e-12, 1.0741e-12,\n",
       "             2.1160e-12],\n",
       "            [1.8979e-12, 1.1227e-12, 7.7240e-13,  ..., 6.8071e-12, 1.0344e-12,\n",
       "             4.8381e-12],\n",
       "            ...,\n",
       "            [2.3969e-12, 2.4820e-12, 2.2740e-12,  ..., 2.1189e-12, 1.2289e-12,\n",
       "             3.3533e-12],\n",
       "            [1.1645e-12, 2.8631e-12, 2.0354e-12,  ..., 1.5351e-12, 3.3903e-12,\n",
       "             1.4139e-12],\n",
       "            [2.0435e-12, 2.5239e-12, 2.4216e-12,  ..., 1.5597e-12, 2.0867e-12,\n",
       "             3.0248e-12]])},\n",
       "   'model.layers.13.self_attn.o_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-5.8489e-07, -2.4116e-08,  4.9972e-07,  ...,  8.9457e-07,\n",
       "              5.1829e-07,  6.5293e-07],\n",
       "            [ 1.8556e-07,  3.4946e-07, -1.7588e-07,  ...,  6.5467e-09,\n",
       "             -4.1820e-08,  1.9261e-07],\n",
       "            [ 7.5060e-07, -1.3114e-07,  6.7504e-08,  ..., -5.0470e-08,\n",
       "              2.6016e-07, -8.6934e-07],\n",
       "            ...,\n",
       "            [-4.4628e-07,  7.6192e-07,  9.5226e-07,  ...,  1.4989e-07,\n",
       "             -1.6351e-07,  3.4080e-07],\n",
       "            [ 7.1148e-07,  2.8919e-07, -4.1204e-07,  ...,  6.3159e-07,\n",
       "             -5.4577e-07,  4.5572e-07],\n",
       "            [-3.1738e-07,  3.2996e-07, -1.4114e-07,  ...,  9.1172e-08,\n",
       "             -1.9068e-07,  1.0763e-07]]),\n",
       "    'exp_avg_sq': tensor([[6.7052e-12, 7.0439e-12, 5.4475e-12,  ..., 8.5617e-12, 8.8472e-12,\n",
       "             1.4674e-11],\n",
       "            [6.2501e-12, 4.5293e-12, 6.8727e-12,  ..., 8.3523e-12, 1.1616e-11,\n",
       "             2.2416e-11],\n",
       "            [6.2936e-12, 5.3403e-12, 4.8477e-12,  ..., 1.2696e-11, 1.2342e-11,\n",
       "             1.4893e-11],\n",
       "            ...,\n",
       "            [8.2581e-12, 3.8507e-12, 4.5526e-12,  ..., 1.1743e-11, 1.1885e-11,\n",
       "             1.9571e-11],\n",
       "            [9.4004e-12, 6.0882e-12, 5.0713e-12,  ..., 7.4613e-12, 1.0394e-11,\n",
       "             1.5522e-11],\n",
       "            [5.6249e-12, 3.4760e-12, 4.5087e-12,  ..., 9.4346e-12, 1.3953e-11,\n",
       "             1.3863e-11]])},\n",
       "   'model.layers.13.self_attn.q_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 1.0693e-07, -6.6023e-07,  2.6576e-08,  ..., -4.6632e-07,\n",
       "             1.2395e-07, -9.5053e-07]),\n",
       "    'exp_avg_sq': tensor([5.9108e-11, 1.8196e-11, 1.0203e-11,  ..., 2.8371e-11, 2.9022e-11,\n",
       "            2.0274e-11])},\n",
       "   'model.layers.13.self_attn.q_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-6.3749e-09,  2.3300e-08, -4.2212e-07,  ...,  3.7833e-07,\n",
       "              1.1175e-07,  3.4826e-07],\n",
       "            [ 4.0380e-07,  3.2224e-07,  1.4371e-07,  ..., -1.3476e-08,\n",
       "             -1.3561e-07, -1.8634e-07],\n",
       "            [ 9.3882e-08, -3.0645e-07,  2.4137e-07,  ..., -1.2186e-07,\n",
       "              1.2691e-07,  2.4121e-07],\n",
       "            ...,\n",
       "            [ 1.4292e-07, -4.6659e-07,  3.9509e-07,  ...,  3.8765e-07,\n",
       "              2.6599e-07, -4.0141e-07],\n",
       "            [-2.2226e-07,  2.5680e-07,  6.7449e-07,  ...,  1.8972e-07,\n",
       "             -8.3508e-07, -1.3643e-06],\n",
       "            [ 3.8383e-07,  3.2531e-07, -2.0368e-07,  ..., -4.1613e-08,\n",
       "              2.9459e-07,  1.4243e-08]]),\n",
       "    'exp_avg_sq': tensor([[1.3455e-12, 4.1822e-12, 4.2823e-11,  ..., 1.1172e-11, 1.9267e-12,\n",
       "             2.3436e-12],\n",
       "            [1.1864e-12, 3.9014e-12, 5.0327e-12,  ..., 9.9294e-13, 1.6322e-12,\n",
       "             1.2558e-12],\n",
       "            [7.5333e-13, 1.8803e-12, 2.0698e-12,  ..., 8.5229e-13, 1.4687e-12,\n",
       "             8.8284e-13],\n",
       "            ...,\n",
       "            [1.2617e-12, 2.5011e-12, 2.3302e-12,  ..., 1.8049e-12, 2.0515e-12,\n",
       "             2.6222e-12],\n",
       "            [3.0792e-12, 2.6759e-12, 2.4738e-12,  ..., 2.4941e-12, 3.3301e-12,\n",
       "             5.5223e-12],\n",
       "            [2.4565e-12, 3.8630e-12, 2.6729e-12,  ..., 2.2423e-12, 2.2683e-12,\n",
       "             1.8147e-12]])},\n",
       "   'model.layers.13.self_attn.v_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 2.1895e-06, -3.2895e-06,  2.2337e-06,  ..., -3.9508e-06,\n",
       "             5.6821e-06,  2.8877e-06]),\n",
       "    'exp_avg_sq': tensor([8.5650e-10, 1.3652e-09, 6.3906e-10,  ..., 8.7937e-10, 1.1005e-09,\n",
       "            8.3927e-10])},\n",
       "   'model.layers.13.self_attn.v_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-1.2093e-06, -3.6567e-07,  7.9641e-08,  ...,  1.5842e-08,\n",
       "              1.0355e-06, -6.3388e-07],\n",
       "            [-4.3733e-07,  4.2091e-07, -5.1102e-07,  ..., -2.1360e-07,\n",
       "             -4.8887e-07, -8.9397e-07],\n",
       "            [-1.7142e-07, -4.5904e-07,  6.1677e-07,  ..., -2.8547e-07,\n",
       "             -5.5085e-07,  1.4444e-08],\n",
       "            ...,\n",
       "            [-1.1042e-06, -8.1284e-07,  4.6152e-07,  ...,  3.0755e-07,\n",
       "              5.1489e-07,  2.2759e-08],\n",
       "            [ 4.7774e-08, -6.6450e-07, -3.9379e-07,  ...,  4.8313e-07,\n",
       "              1.7943e-07, -4.2076e-07],\n",
       "            [ 3.1668e-08, -1.8813e-07,  5.0511e-07,  ...,  7.9156e-07,\n",
       "              9.8100e-07, -1.2553e-06]]),\n",
       "    'exp_avg_sq': tensor([[1.4374e-11, 1.1771e-11, 8.3301e-12,  ..., 2.1354e-11, 2.2891e-11,\n",
       "             1.7010e-11],\n",
       "            [5.1189e-12, 8.7451e-12, 4.5781e-12,  ..., 4.8861e-12, 5.2870e-12,\n",
       "             5.0389e-12],\n",
       "            [3.1281e-12, 4.7330e-12, 3.2741e-12,  ..., 3.1132e-12, 5.2793e-12,\n",
       "             3.1976e-12],\n",
       "            ...,\n",
       "            [7.8554e-12, 1.2373e-11, 9.7704e-12,  ..., 6.8465e-12, 7.2690e-12,\n",
       "             7.5323e-12],\n",
       "            [9.9870e-12, 1.2717e-11, 9.7653e-12,  ..., 9.0505e-12, 1.1551e-11,\n",
       "             1.4083e-11],\n",
       "            [7.9859e-12, 1.0107e-11, 7.8240e-12,  ..., 9.2376e-12, 1.3285e-11,\n",
       "             1.3918e-11]])},\n",
       "   'model.layers.14.input_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-4.8977e-06, -3.7441e-07, -6.2028e-06,  ...,  5.3564e-06,\n",
       "            -2.5321e-06, -1.7555e-06]),\n",
       "    'exp_avg_sq': tensor([8.1542e-10, 4.4970e-10, 6.0882e-10,  ..., 6.1052e-10, 6.5223e-10,\n",
       "            6.8960e-10])},\n",
       "   'model.layers.14.mlp.down_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-2.8872e-07,  9.4457e-08,  1.0609e-07,  ..., -1.9238e-07,\n",
       "             -4.2134e-07,  2.2408e-07],\n",
       "            [-6.7713e-07, -3.1485e-07,  1.2026e-07,  ..., -1.9702e-07,\n",
       "              4.6776e-07, -9.5063e-07],\n",
       "            [-3.7585e-07, -4.6012e-07, -1.0669e-06,  ..., -5.6566e-07,\n",
       "             -3.3739e-07,  5.1273e-07],\n",
       "            ...,\n",
       "            [ 5.4998e-07,  3.2992e-07,  3.2097e-07,  ..., -3.0761e-07,\n",
       "             -5.0841e-07, -3.3669e-07],\n",
       "            [ 7.7201e-07, -4.7088e-07,  8.2591e-07,  ..., -2.3053e-07,\n",
       "             -7.7882e-07, -1.1748e-06],\n",
       "            [-5.3335e-08, -2.8781e-07,  5.9973e-07,  ..., -2.0766e-07,\n",
       "              1.1029e-06,  5.6717e-07]]),\n",
       "    'exp_avg_sq': tensor([[6.5418e-12, 5.7708e-12, 7.9674e-12,  ..., 6.4548e-12, 7.9828e-12,\n",
       "             9.8597e-12],\n",
       "            [7.9802e-12, 6.1226e-12, 7.1879e-12,  ..., 5.4849e-12, 7.3234e-12,\n",
       "             9.6879e-12],\n",
       "            [5.2389e-12, 5.5802e-12, 9.0910e-12,  ..., 6.5247e-12, 7.1771e-12,\n",
       "             9.3344e-12],\n",
       "            ...,\n",
       "            [6.2377e-12, 5.3258e-12, 1.0710e-11,  ..., 6.6683e-12, 6.5258e-12,\n",
       "             1.1407e-11],\n",
       "            [6.1153e-12, 3.9235e-12, 6.4480e-12,  ..., 5.8416e-12, 5.7172e-12,\n",
       "             1.2736e-11],\n",
       "            [7.1993e-12, 6.7405e-12, 1.3432e-11,  ..., 7.6141e-12, 1.0380e-11,\n",
       "             9.4058e-12]])},\n",
       "   'model.layers.14.mlp.gate_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 6.1328e-07,  6.7262e-07, -4.4663e-07,  ...,  7.3076e-07,\n",
       "              5.0262e-07,  4.9851e-07],\n",
       "            [-2.1681e-08,  5.1944e-08,  3.8791e-07,  ..., -2.3558e-08,\n",
       "              7.6774e-08, -6.6944e-07],\n",
       "            [ 2.9581e-07,  1.0489e-07,  3.2069e-07,  ..., -9.8267e-07,\n",
       "              1.6415e-07,  9.7653e-07],\n",
       "            ...,\n",
       "            [-5.3490e-07,  6.7824e-07, -6.6889e-07,  ...,  5.7718e-07,\n",
       "             -6.5565e-08, -5.6699e-08],\n",
       "            [ 4.9430e-08, -2.4578e-07, -3.4462e-07,  ...,  4.5448e-07,\n",
       "              7.7110e-07,  1.0619e-06],\n",
       "            [ 5.1180e-07, -3.4468e-07, -7.9141e-07,  ...,  1.8715e-07,\n",
       "             -1.3897e-06,  8.0042e-07]]),\n",
       "    'exp_avg_sq': tensor([[5.1969e-12, 4.6713e-12, 6.2137e-12,  ..., 5.9316e-12, 4.0424e-12,\n",
       "             3.6072e-12],\n",
       "            [6.1176e-12, 5.7422e-12, 4.6879e-12,  ..., 4.2464e-12, 3.6721e-12,\n",
       "             4.6006e-12],\n",
       "            [5.2097e-12, 7.9656e-12, 8.6402e-12,  ..., 5.8846e-12, 5.0547e-12,\n",
       "             8.6775e-12],\n",
       "            ...,\n",
       "            [4.7907e-12, 7.7999e-12, 7.6213e-12,  ..., 4.4303e-12, 6.1695e-12,\n",
       "             7.5717e-12],\n",
       "            [4.4554e-12, 7.1623e-12, 7.0890e-12,  ..., 5.3630e-12, 7.8356e-12,\n",
       "             6.7941e-12],\n",
       "            [4.1467e-12, 1.0062e-11, 1.1127e-11,  ..., 6.0755e-12, 1.0702e-11,\n",
       "             8.5166e-12]])},\n",
       "   'model.layers.14.mlp.up_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 3.0950e-07,  1.7905e-07, -1.0464e-07,  ...,  2.3313e-07,\n",
       "             -1.0486e-06,  5.8013e-07],\n",
       "            [-5.4594e-07, -5.5594e-07, -5.9141e-10,  ..., -2.6809e-07,\n",
       "              7.4099e-07,  1.7056e-07],\n",
       "            [-1.2551e-07,  3.5301e-07, -9.5709e-07,  ...,  2.7267e-07,\n",
       "              6.7145e-07,  2.0052e-07],\n",
       "            ...,\n",
       "            [ 2.6549e-07,  1.8278e-07,  2.5801e-07,  ..., -4.9963e-08,\n",
       "             -1.4101e-07,  1.2724e-07],\n",
       "            [ 1.0395e-07, -5.3563e-07,  1.1633e-07,  ..., -4.9003e-08,\n",
       "              3.5945e-07, -2.7030e-07],\n",
       "            [ 1.5837e-08,  4.4635e-07, -2.2353e-07,  ...,  1.8903e-07,\n",
       "             -9.0187e-07, -4.3900e-07]]),\n",
       "    'exp_avg_sq': tensor([[7.6453e-12, 5.8583e-12, 6.0828e-12,  ..., 6.1981e-12, 5.0304e-12,\n",
       "             7.4774e-12],\n",
       "            [3.7157e-12, 3.5333e-12, 2.2818e-12,  ..., 4.7384e-12, 4.9136e-12,\n",
       "             3.7036e-12],\n",
       "            [4.9194e-12, 7.7872e-12, 6.7612e-12,  ..., 4.3324e-12, 4.9326e-12,\n",
       "             3.7745e-12],\n",
       "            ...,\n",
       "            [4.1898e-12, 4.1442e-12, 5.5483e-12,  ..., 6.1294e-12, 5.5909e-12,\n",
       "             4.9559e-12],\n",
       "            [4.7426e-12, 6.2091e-12, 6.4060e-12,  ..., 5.8433e-12, 5.3834e-12,\n",
       "             4.1105e-12],\n",
       "            [1.0677e-11, 8.2692e-12, 8.2403e-12,  ..., 1.0393e-11, 1.1856e-11,\n",
       "             6.8714e-12]])},\n",
       "   'model.layers.14.post_attention_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-4.2304e-06, -9.2896e-06, -1.0833e-05,  ...,  8.4593e-06,\n",
       "             3.5337e-06,  1.1703e-06]),\n",
       "    'exp_avg_sq': tensor([5.3604e-10, 9.5403e-10, 6.9574e-10,  ..., 1.1955e-09, 7.1652e-10,\n",
       "            8.4245e-10])},\n",
       "   'model.layers.14.self_attn.k_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-1.1680e-06, -1.4336e-06,  6.6302e-07,  ...,  2.8959e-10,\n",
       "            -2.8492e-10,  3.0632e-09]),\n",
       "    'exp_avg_sq': tensor([9.3354e-12, 9.1373e-12, 6.4711e-12,  ..., 1.4496e-16, 2.6982e-16,\n",
       "            2.5761e-16])},\n",
       "   'model.layers.14.self_attn.k_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 6.4766e-08,  9.5259e-08, -1.0396e-07,  ...,  1.4327e-07,\n",
       "              4.2867e-08,  3.7377e-07],\n",
       "            [ 1.0261e-07, -2.8697e-08, -1.8734e-07,  ..., -2.3984e-07,\n",
       "              1.3292e-07, -2.1096e-08],\n",
       "            [ 2.1693e-07,  3.6116e-08, -3.0313e-07,  ..., -2.8045e-07,\n",
       "             -5.6548e-08,  1.6100e-07],\n",
       "            ...,\n",
       "            [-1.5141e-07,  3.3001e-07,  6.7707e-07,  ...,  4.1198e-07,\n",
       "             -5.5684e-09, -1.5798e-07],\n",
       "            [-5.6391e-07, -2.2986e-07,  6.0158e-07,  ..., -2.0117e-07,\n",
       "             -2.4935e-07,  1.5525e-07],\n",
       "            [ 8.6352e-07, -1.0016e-06,  4.3923e-07,  ..., -4.5570e-07,\n",
       "              4.4384e-07,  1.8306e-08]]),\n",
       "    'exp_avg_sq': tensor([[6.3505e-13, 7.6806e-13, 6.1254e-13,  ..., 7.1535e-13, 8.5682e-13,\n",
       "             1.3668e-12],\n",
       "            [6.6619e-13, 1.0573e-12, 9.5340e-13,  ..., 8.2300e-13, 5.6530e-13,\n",
       "             7.8771e-13],\n",
       "            [7.4277e-13, 7.7140e-13, 9.6947e-13,  ..., 4.7546e-13, 1.0194e-12,\n",
       "             7.6753e-13],\n",
       "            ...,\n",
       "            [2.4980e-12, 4.1658e-12, 3.0617e-12,  ..., 3.9725e-12, 3.6690e-12,\n",
       "             3.3511e-12],\n",
       "            [3.9822e-12, 2.7876e-12, 4.4819e-12,  ..., 3.2766e-12, 2.2330e-12,\n",
       "             3.1150e-12],\n",
       "            [3.2983e-12, 4.5953e-12, 4.9616e-12,  ..., 3.2964e-12, 3.8365e-12,\n",
       "             4.0481e-12]])},\n",
       "   'model.layers.14.self_attn.o_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-2.7805e-07, -1.0252e-06,  6.7208e-07,  ...,  9.3664e-07,\n",
       "             -2.4963e-09, -8.7056e-08],\n",
       "            [-1.2554e-07,  8.6443e-07,  4.0460e-07,  ..., -4.0260e-07,\n",
       "             -1.6654e-07,  6.5851e-08],\n",
       "            [-9.5982e-07, -5.8633e-07,  8.4960e-08,  ..., -4.2612e-07,\n",
       "              6.2283e-08, -7.9399e-07],\n",
       "            ...,\n",
       "            [-5.8592e-08,  2.3025e-07, -4.5276e-07,  ..., -2.0441e-07,\n",
       "             -3.0266e-07,  7.7091e-07],\n",
       "            [ 6.2069e-08,  6.7288e-07,  4.5707e-07,  ..., -8.1252e-08,\n",
       "             -5.4576e-07, -2.3831e-07],\n",
       "            [-4.4434e-07, -5.5669e-07, -2.3685e-07,  ...,  5.0242e-08,\n",
       "             -6.4093e-08,  4.8237e-07]]),\n",
       "    'exp_avg_sq': tensor([[4.8958e-12, 5.2804e-12, 2.6840e-12,  ..., 5.8739e-12, 3.4045e-12,\n",
       "             5.9431e-12],\n",
       "            [5.0983e-12, 4.8444e-12, 3.6027e-12,  ..., 3.8858e-12, 3.6762e-12,\n",
       "             2.8999e-12],\n",
       "            [5.9698e-12, 3.7822e-12, 4.0810e-12,  ..., 6.7287e-12, 3.5185e-12,\n",
       "             5.6156e-12],\n",
       "            ...,\n",
       "            [5.3250e-12, 3.2422e-12, 4.4543e-12,  ..., 5.0582e-12, 4.6906e-12,\n",
       "             4.5906e-12],\n",
       "            [3.9937e-12, 5.1637e-12, 3.6899e-12,  ..., 4.5817e-12, 3.3034e-12,\n",
       "             2.9655e-12],\n",
       "            [7.0403e-12, 6.2386e-12, 3.0179e-12,  ..., 3.6028e-12, 4.0843e-12,\n",
       "             3.6816e-12]])},\n",
       "   'model.layers.14.self_attn.q_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-2.4248e-07, -4.9079e-07,  4.2269e-07,  ...,  1.7231e-06,\n",
       "            -1.5268e-06, -1.0102e-06]),\n",
       "    'exp_avg_sq': tensor([3.5559e-12, 5.5104e-12, 7.3675e-12,  ..., 7.4394e-11, 8.7204e-11,\n",
       "            4.9184e-11])},\n",
       "   'model.layers.14.self_attn.q_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-1.2316e-08,  2.0715e-07, -1.7281e-08,  ..., -2.4238e-07,\n",
       "              1.7895e-07,  3.1297e-07],\n",
       "            [-2.4204e-07,  1.9252e-07,  4.8249e-09,  ...,  2.4641e-07,\n",
       "             -1.5877e-08, -4.1132e-07],\n",
       "            [ 1.5244e-07,  1.8640e-07, -2.2645e-07,  ...,  8.0266e-08,\n",
       "             -3.5073e-08, -4.1235e-07],\n",
       "            ...,\n",
       "            [ 5.3834e-07,  2.3574e-07,  8.2656e-08,  ...,  5.4188e-07,\n",
       "             -1.0264e-07,  6.2396e-07],\n",
       "            [-3.3649e-07,  2.0979e-08,  1.0169e-07,  ..., -3.4039e-08,\n",
       "             -9.6023e-07,  1.3328e-07],\n",
       "            [-3.8864e-07,  2.5783e-09, -2.6283e-07,  ...,  4.8122e-07,\n",
       "             -4.0217e-07,  5.9568e-07]]),\n",
       "    'exp_avg_sq': tensor([[9.0890e-13, 1.1431e-12, 8.3712e-13,  ..., 9.6523e-13, 6.7250e-13,\n",
       "             1.3741e-12],\n",
       "            [6.8144e-13, 9.2516e-13, 1.0463e-12,  ..., 9.5914e-13, 6.7318e-13,\n",
       "             1.1214e-12],\n",
       "            [8.8222e-13, 7.7253e-13, 9.5633e-13,  ..., 1.3154e-12, 1.3792e-12,\n",
       "             1.1586e-12],\n",
       "            ...,\n",
       "            [1.7095e-12, 2.9759e-12, 3.6342e-12,  ..., 3.1707e-12, 2.7733e-12,\n",
       "             4.0107e-12],\n",
       "            [3.8111e-12, 2.8055e-12, 2.0783e-12,  ..., 2.3171e-12, 3.6400e-12,\n",
       "             3.4522e-12],\n",
       "            [2.3650e-12, 2.8516e-12, 2.8145e-12,  ..., 2.5216e-12, 2.1890e-12,\n",
       "             3.0239e-12]])},\n",
       "   'model.layers.14.self_attn.v_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 8.6100e-07,  2.9897e-06,  2.8999e-06,  ...,  4.9726e-07,\n",
       "            -6.2702e-06, -9.8953e-06]),\n",
       "    'exp_avg_sq': tensor([1.2690e-09, 7.5229e-10, 3.9378e-10,  ..., 4.2738e-09, 1.6922e-09,\n",
       "            2.1603e-09])},\n",
       "   'model.layers.14.self_attn.v_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-2.2045e-07,  4.1714e-08, -5.0789e-07,  ...,  8.4366e-09,\n",
       "             -3.0001e-07,  5.9843e-08],\n",
       "            [-2.8787e-07, -2.4357e-07, -4.6777e-08,  ..., -1.7004e-07,\n",
       "             -7.0438e-07, -1.3905e-07],\n",
       "            [ 2.3667e-07, -9.3360e-08, -2.9511e-07,  ..., -5.7039e-07,\n",
       "              1.0125e-07, -5.1872e-09],\n",
       "            ...,\n",
       "            [ 6.7209e-07,  3.6895e-07,  8.1591e-07,  ...,  3.8302e-07,\n",
       "              3.4023e-08, -1.5989e-07],\n",
       "            [ 4.3181e-07,  4.9217e-07,  8.0105e-07,  ..., -9.5679e-07,\n",
       "             -8.6676e-08, -6.0180e-07],\n",
       "            [-8.7418e-08, -4.7240e-07, -6.5286e-07,  ..., -1.2384e-06,\n",
       "             -5.0382e-07, -3.4746e-07]]),\n",
       "    'exp_avg_sq': tensor([[6.4475e-12, 6.8648e-12, 7.9829e-12,  ..., 3.2627e-12, 3.9561e-12,\n",
       "             5.9350e-12],\n",
       "            [2.7394e-12, 4.2913e-12, 3.6816e-12,  ..., 2.9034e-12, 3.3696e-12,\n",
       "             2.8229e-12],\n",
       "            [2.5911e-12, 2.1837e-12, 3.5971e-12,  ..., 2.3789e-12, 1.5731e-12,\n",
       "             4.0938e-12],\n",
       "            ...,\n",
       "            [6.0001e-12, 1.0398e-11, 7.7770e-12,  ..., 5.1339e-12, 6.4534e-12,\n",
       "             5.9450e-12],\n",
       "            [4.5705e-12, 5.9152e-12, 5.6522e-12,  ..., 4.8565e-12, 6.1380e-12,\n",
       "             9.8030e-12],\n",
       "            [6.9728e-12, 5.7717e-12, 6.7021e-12,  ..., 8.0841e-12, 5.7372e-12,\n",
       "             4.7311e-12]])},\n",
       "   'model.layers.15.input_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 1.1631e-05, -9.4164e-06, -7.1565e-06,  ..., -4.0955e-06,\n",
       "             1.0299e-05, -6.8274e-06]),\n",
       "    'exp_avg_sq': tensor([8.4159e-10, 6.8424e-10, 6.5927e-10,  ..., 3.4876e-10, 4.0979e-10,\n",
       "            8.1988e-10])},\n",
       "   'model.layers.15.mlp.down_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-6.0872e-07, -1.9597e-07, -8.7777e-08,  ...,  8.1039e-07,\n",
       "              9.7613e-07, -4.6946e-08],\n",
       "            [-7.6256e-07, -7.3783e-07, -1.4212e-06,  ...,  3.9359e-07,\n",
       "              2.4935e-07,  3.9615e-10],\n",
       "            [ 1.4895e-07,  2.6065e-07, -1.0890e-06,  ..., -2.1415e-07,\n",
       "              7.8913e-07, -7.8141e-08],\n",
       "            ...,\n",
       "            [-4.6794e-09, -4.3192e-07, -8.4203e-07,  ..., -8.3148e-08,\n",
       "             -3.9998e-07,  3.9854e-07],\n",
       "            [ 2.5060e-07,  2.4212e-07,  1.1591e-07,  ...,  5.5735e-07,\n",
       "             -5.5455e-07, -1.3784e-08],\n",
       "            [-3.8541e-07, -1.1119e-06, -2.6824e-07,  ..., -4.7648e-07,\n",
       "              1.9684e-07,  2.4001e-07]]),\n",
       "    'exp_avg_sq': tensor([[4.9783e-12, 9.9015e-12, 6.3348e-12,  ..., 5.9443e-12, 6.9130e-12,\n",
       "             4.7852e-12],\n",
       "            [7.5938e-12, 7.6971e-12, 6.5505e-12,  ..., 4.4319e-12, 4.2648e-12,\n",
       "             6.2355e-12],\n",
       "            [9.4062e-12, 9.7037e-12, 8.2350e-12,  ..., 5.6666e-12, 6.7954e-12,\n",
       "             6.5406e-12],\n",
       "            ...,\n",
       "            [5.0788e-12, 1.2377e-11, 4.2708e-12,  ..., 6.8040e-12, 5.9042e-12,\n",
       "             5.7006e-12],\n",
       "            [5.8986e-12, 8.9424e-12, 6.7917e-12,  ..., 4.0911e-12, 6.2511e-12,\n",
       "             5.4093e-12],\n",
       "            [5.7045e-12, 1.0425e-11, 6.2793e-12,  ..., 5.3753e-12, 5.3635e-12,\n",
       "             5.5565e-12]])},\n",
       "   'model.layers.15.mlp.gate_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-5.6431e-07, -1.5544e-07,  3.3713e-07,  ..., -3.2200e-07,\n",
       "             -6.2239e-07,  1.8662e-07],\n",
       "            [-4.7819e-07,  1.6588e-07,  1.1056e-07,  ..., -1.0996e-07,\n",
       "             -2.7619e-07, -1.0716e-06],\n",
       "            [-1.7398e-07,  3.5877e-08,  1.7985e-07,  ..., -1.3363e-07,\n",
       "             -2.2548e-07,  3.2185e-07],\n",
       "            ...,\n",
       "            [ 4.1818e-07,  5.9222e-08,  5.4898e-07,  ...,  4.7640e-09,\n",
       "              7.2413e-07, -6.6859e-07],\n",
       "            [ 3.8031e-07, -1.1175e-06, -1.2780e-06,  ..., -7.2346e-07,\n",
       "             -2.8015e-07, -4.2875e-07],\n",
       "            [-1.1979e-07,  6.2846e-07, -1.2630e-07,  ...,  2.4513e-07,\n",
       "             -3.0387e-07,  3.3843e-07]]),\n",
       "    'exp_avg_sq': tensor([[4.1624e-12, 4.9957e-12, 7.5444e-12,  ..., 3.8652e-12, 5.0642e-12,\n",
       "             4.1940e-12],\n",
       "            [4.5744e-12, 4.2819e-12, 8.0268e-12,  ..., 5.7567e-12, 6.9256e-12,\n",
       "             6.6538e-12],\n",
       "            [4.7437e-12, 2.9739e-12, 3.8732e-12,  ..., 5.1432e-12, 4.2193e-12,\n",
       "             6.3493e-12],\n",
       "            ...,\n",
       "            [4.7119e-12, 3.9307e-12, 5.7132e-12,  ..., 3.0655e-12, 3.6444e-12,\n",
       "             6.4913e-12],\n",
       "            [5.3955e-12, 7.8301e-12, 6.3615e-12,  ..., 7.2348e-12, 4.0091e-12,\n",
       "             3.4578e-12],\n",
       "            [2.8231e-12, 4.5116e-12, 4.2163e-12,  ..., 4.6922e-12, 3.7358e-12,\n",
       "             4.6095e-12]])},\n",
       "   'model.layers.15.mlp.up_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 3.7644e-07,  1.0851e-06,  5.5312e-07,  ...,  1.0103e-06,\n",
       "              4.9670e-07,  8.9722e-07],\n",
       "            [ 4.2475e-07, -6.5254e-08,  4.5591e-07,  ..., -3.2543e-08,\n",
       "              7.2741e-07, -3.5711e-07],\n",
       "            [ 3.5005e-07,  5.9267e-07, -3.8408e-07,  ..., -7.3262e-07,\n",
       "             -2.3944e-07,  3.4247e-07],\n",
       "            ...,\n",
       "            [-6.4086e-07, -2.9801e-07,  3.1308e-07,  ...,  1.3412e-07,\n",
       "              3.5645e-07, -9.9443e-07],\n",
       "            [-1.2155e-07,  5.1214e-07, -6.7253e-07,  ...,  1.6662e-08,\n",
       "             -1.1371e-07, -2.3698e-07],\n",
       "            [-3.2575e-07, -5.1822e-07,  1.4926e-07,  ..., -8.9881e-08,\n",
       "              7.4827e-07,  2.3631e-07]]),\n",
       "    'exp_avg_sq': tensor([[3.2841e-12, 4.6898e-12, 4.1246e-12,  ..., 5.3430e-12, 4.1433e-12,\n",
       "             4.7478e-12],\n",
       "            [4.4698e-12, 3.9158e-12, 5.3670e-12,  ..., 4.2544e-12, 5.8134e-12,\n",
       "             4.8163e-12],\n",
       "            [4.1045e-12, 2.7344e-12, 5.7428e-12,  ..., 6.5663e-12, 5.0213e-12,\n",
       "             6.6932e-12],\n",
       "            ...,\n",
       "            [3.0056e-12, 3.1144e-12, 3.8044e-12,  ..., 3.9442e-12, 2.4575e-12,\n",
       "             4.0298e-12],\n",
       "            [2.3384e-12, 4.9112e-12, 4.7077e-12,  ..., 7.7179e-12, 4.6386e-12,\n",
       "             3.5715e-12],\n",
       "            [3.3524e-12, 2.6847e-12, 2.2665e-12,  ..., 3.7805e-12, 3.9027e-12,\n",
       "             2.7957e-12]])},\n",
       "   'model.layers.15.post_attention_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-3.9044e-06, -1.9577e-06, -1.6834e-06,  ...,  7.6678e-06,\n",
       "            -1.0065e-05,  2.4401e-06]),\n",
       "    'exp_avg_sq': tensor([6.5648e-10, 4.8957e-10, 6.8046e-10,  ..., 5.5088e-10, 8.0531e-10,\n",
       "            7.1183e-10])},\n",
       "   'model.layers.15.self_attn.k_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 1.5838e-06,  1.4979e-06,  1.8834e-06,  ...,  5.1819e-10,\n",
       "             3.6111e-10, -6.8801e-09]),\n",
       "    'exp_avg_sq': tensor([5.7557e-11, 3.4316e-11, 3.4933e-11,  ..., 3.9972e-16, 2.9892e-16,\n",
       "            4.4442e-16])},\n",
       "   'model.layers.15.self_attn.k_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-8.8692e-08, -1.0017e-07,  1.5611e-06,  ...,  3.4876e-08,\n",
       "             -6.4005e-07, -5.4016e-07],\n",
       "            [-1.2712e-07,  2.0153e-07,  1.5003e-07,  ..., -4.2957e-07,\n",
       "             -2.5321e-07, -6.1907e-07],\n",
       "            [-5.4589e-07, -1.0448e-07,  7.5256e-07,  ...,  1.7291e-07,\n",
       "             -4.7719e-07, -1.1556e-06],\n",
       "            ...,\n",
       "            [-1.2664e-07, -2.1535e-07, -4.0183e-07,  ...,  4.7723e-08,\n",
       "              3.3639e-07, -1.8604e-07],\n",
       "            [-6.9163e-07, -8.2804e-07,  1.4676e-07,  ..., -1.6877e-07,\n",
       "              6.1690e-08, -5.2780e-07],\n",
       "            [ 6.0633e-07,  1.9677e-06, -2.5241e-07,  ...,  2.7796e-07,\n",
       "              6.6863e-07,  7.3750e-07]]),\n",
       "    'exp_avg_sq': tensor([[8.4903e-12, 1.4149e-11, 1.3142e-11,  ..., 1.1666e-11, 1.3392e-11,\n",
       "             1.1291e-11],\n",
       "            [2.6790e-12, 3.7102e-12, 2.4648e-12,  ..., 2.4492e-12, 2.9955e-12,\n",
       "             2.8761e-12],\n",
       "            [5.4667e-12, 9.5329e-12, 1.0137e-11,  ..., 8.1693e-12, 9.9054e-12,\n",
       "             1.0092e-11],\n",
       "            ...,\n",
       "            [4.4120e-12, 6.2162e-12, 6.5270e-12,  ..., 3.1138e-12, 6.0617e-12,\n",
       "             4.1563e-12],\n",
       "            [3.7419e-12, 4.5965e-12, 4.0705e-12,  ..., 3.8839e-12, 4.8205e-12,\n",
       "             4.3420e-12],\n",
       "            [7.4842e-12, 9.9325e-12, 6.1985e-12,  ..., 6.8676e-12, 6.1104e-12,\n",
       "             7.1829e-12]])},\n",
       "   'model.layers.15.self_attn.o_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-1.2600e-06, -1.6316e-07, -9.3554e-07,  ..., -5.4514e-07,\n",
       "              1.9322e-07, -2.7887e-07],\n",
       "            [ 7.2496e-07,  4.0546e-07, -5.5250e-07,  ..., -4.1820e-07,\n",
       "             -2.1155e-07, -1.0764e-06],\n",
       "            [-2.5111e-07,  6.5885e-07,  4.3448e-07,  ..., -7.2722e-07,\n",
       "             -2.5249e-07, -3.3630e-07],\n",
       "            ...,\n",
       "            [-2.7975e-07, -2.4858e-07,  8.7482e-07,  ...,  3.9160e-07,\n",
       "             -1.2481e-06, -1.3289e-07],\n",
       "            [ 1.4045e-08,  8.0454e-07,  2.5299e-07,  ..., -3.5277e-08,\n",
       "             -6.1654e-07, -1.3318e-07],\n",
       "            [-7.2113e-07, -3.9063e-07,  1.4827e-06,  ..., -2.7058e-07,\n",
       "              7.6010e-08, -2.3376e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.0281e-11, 6.6847e-12, 1.6270e-11,  ..., 6.2767e-12, 5.3299e-12,\n",
       "             3.4384e-12],\n",
       "            [9.7805e-12, 1.2753e-11, 1.1929e-11,  ..., 5.3393e-12, 3.6627e-12,\n",
       "             5.6648e-12],\n",
       "            [1.0713e-11, 8.8831e-12, 1.4688e-11,  ..., 5.6194e-12, 4.4933e-12,\n",
       "             5.7491e-12],\n",
       "            ...,\n",
       "            [9.1281e-12, 9.8182e-12, 1.3284e-11,  ..., 5.8531e-12, 5.0056e-12,\n",
       "             5.7888e-12],\n",
       "            [7.7002e-12, 5.7177e-12, 1.0427e-11,  ..., 6.2155e-12, 3.2664e-12,\n",
       "             3.0747e-12],\n",
       "            [1.2979e-11, 1.0369e-11, 1.2000e-11,  ..., 5.0148e-12, 5.6544e-12,\n",
       "             4.6760e-12]])},\n",
       "   'model.layers.15.self_attn.q_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 2.1195e-06,  3.8611e-06,  2.4489e-06,  ...,  3.1493e-07,\n",
       "            -1.6653e-07, -2.1362e-06]),\n",
       "    'exp_avg_sq': tensor([1.8247e-10, 7.0596e-11, 5.8400e-11,  ..., 3.1636e-11, 2.4183e-11,\n",
       "            6.8136e-11])},\n",
       "   'model.layers.15.self_attn.q_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 6.0106e-07, -1.0262e-06, -4.5519e-09,  ..., -4.7948e-07,\n",
       "              1.7615e-07,  6.3888e-07],\n",
       "            [ 8.5702e-07,  8.6135e-08, -2.1213e-07,  ..., -7.7658e-07,\n",
       "             -7.0798e-07, -2.9553e-08],\n",
       "            [ 1.1325e-06, -4.7814e-07, -4.0182e-08,  ..., -3.0788e-07,\n",
       "             -4.3402e-07,  1.9870e-07],\n",
       "            ...,\n",
       "            [-1.1310e-07,  1.8205e-08,  9.6736e-07,  ...,  2.8238e-07,\n",
       "             -6.6767e-07,  2.4293e-07],\n",
       "            [ 6.2680e-08, -4.7173e-08, -3.3754e-07,  ..., -4.1519e-09,\n",
       "              1.1287e-07,  1.1029e-06],\n",
       "            [ 8.6021e-08,  1.5839e-06, -3.2090e-07,  ...,  4.7405e-07,\n",
       "              4.9935e-07, -1.0250e-06]]),\n",
       "    'exp_avg_sq': tensor([[1.4127e-11, 3.6987e-11, 1.6663e-11,  ..., 1.4525e-11, 1.2863e-11,\n",
       "             1.6346e-11],\n",
       "            [6.6133e-12, 9.9185e-12, 7.8853e-12,  ..., 7.5833e-12, 7.9214e-12,\n",
       "             9.7571e-12],\n",
       "            [6.8585e-12, 6.1198e-12, 6.4661e-12,  ..., 4.4488e-12, 4.6614e-12,\n",
       "             5.5114e-12],\n",
       "            ...,\n",
       "            [3.3679e-12, 5.0227e-12, 5.7659e-12,  ..., 4.8698e-12, 4.3987e-12,\n",
       "             3.6081e-12],\n",
       "            [3.6468e-12, 3.6921e-12, 3.3086e-12,  ..., 3.0633e-12, 4.1202e-12,\n",
       "             4.7792e-12],\n",
       "            [7.0145e-12, 1.0437e-11, 7.4387e-12,  ..., 5.8764e-12, 7.5293e-12,\n",
       "             8.9561e-12]])},\n",
       "   'model.layers.15.self_attn.v_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 8.7899e-06, -1.7235e-06,  5.3184e-07,  ..., -2.5850e-06,\n",
       "            -4.7208e-06,  2.0731e-06]),\n",
       "    'exp_avg_sq': tensor([8.8232e-10, 4.2506e-10, 5.9847e-10,  ..., 4.8243e-10, 6.8062e-10,\n",
       "            3.9290e-10])},\n",
       "   'model.layers.15.self_attn.v_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-1.3884e-06, -8.1764e-07, -1.2851e-07,  ..., -1.4651e-06,\n",
       "              3.7730e-08,  1.2493e-06],\n",
       "            [ 8.9604e-09,  5.9074e-07,  1.4266e-06,  ..., -2.4112e-07,\n",
       "             -9.1466e-08,  2.9516e-07],\n",
       "            [ 1.3097e-07,  2.4070e-06, -3.3382e-06,  ...,  3.2282e-07,\n",
       "             -1.8049e-07, -7.4248e-07],\n",
       "            ...,\n",
       "            [ 1.3898e-07,  4.9051e-07, -5.2493e-07,  ..., -8.2632e-07,\n",
       "             -6.6101e-07,  1.5509e-07],\n",
       "            [-2.4354e-07, -2.4664e-07, -2.7246e-07,  ..., -5.1250e-08,\n",
       "              2.1893e-07, -2.8325e-07],\n",
       "            [ 6.5728e-07,  6.3159e-07,  4.7372e-07,  ...,  5.2506e-07,\n",
       "              8.7143e-09,  2.8053e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.2682e-11, 9.7985e-12, 1.0639e-11,  ..., 1.2823e-11, 9.9451e-12,\n",
       "             1.0261e-11],\n",
       "            [7.0094e-12, 7.7870e-12, 6.7798e-12,  ..., 7.5790e-12, 7.3358e-12,\n",
       "             7.1849e-12],\n",
       "            [1.1342e-11, 1.6595e-11, 2.2982e-11,  ..., 1.6437e-11, 1.5168e-11,\n",
       "             1.4002e-11],\n",
       "            ...,\n",
       "            [2.9492e-12, 3.3110e-12, 3.9527e-12,  ..., 3.7496e-12, 1.8378e-12,\n",
       "             2.8911e-12],\n",
       "            [3.2851e-12, 4.5177e-12, 3.8268e-12,  ..., 2.1684e-12, 2.2963e-12,\n",
       "             3.6720e-12],\n",
       "            [3.4643e-12, 4.9477e-12, 2.7123e-12,  ..., 4.9002e-12, 3.1441e-12,\n",
       "             3.9735e-12]])},\n",
       "   'model.layers.16.input_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-7.2414e-07, -3.4900e-06,  1.6350e-06,  ..., -3.5141e-06,\n",
       "             1.0758e-06, -3.5218e-06]),\n",
       "    'exp_avg_sq': tensor([4.7728e-10, 3.9897e-10, 3.9441e-10,  ..., 3.6445e-10, 3.4619e-10,\n",
       "            3.6854e-10])},\n",
       "   'model.layers.16.mlp.down_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 2.6487e-07,  1.8502e-08,  4.7822e-07,  ..., -1.7107e-08,\n",
       "             -3.6236e-07, -3.5712e-07],\n",
       "            [ 4.9934e-07, -5.0397e-07,  1.0296e-07,  ...,  3.2329e-07,\n",
       "              4.4599e-07, -5.0625e-07],\n",
       "            [-1.3747e-07,  3.7115e-07,  3.4326e-07,  ...,  3.7320e-08,\n",
       "              8.5852e-07,  6.7511e-07],\n",
       "            ...,\n",
       "            [ 4.7962e-07, -3.6644e-07,  3.5562e-08,  ..., -6.6894e-07,\n",
       "              9.6871e-07,  4.4314e-07],\n",
       "            [-4.8610e-07,  8.8023e-09,  3.8593e-07,  ...,  4.9214e-07,\n",
       "             -3.2618e-07, -5.0384e-07],\n",
       "            [ 1.1559e-07, -7.4027e-07, -1.2692e-07,  ...,  2.2598e-07,\n",
       "              1.2492e-06,  2.0135e-07]]),\n",
       "    'exp_avg_sq': tensor([[7.8937e-12, 7.3043e-12, 4.7273e-12,  ..., 6.0728e-12, 7.9314e-12,\n",
       "             5.3317e-12],\n",
       "            [5.9432e-12, 6.9220e-12, 7.0210e-12,  ..., 6.4347e-12, 7.0101e-12,\n",
       "             4.6122e-12],\n",
       "            [6.2177e-12, 7.1222e-12, 5.8070e-12,  ..., 9.1180e-12, 6.6660e-12,\n",
       "             5.1329e-12],\n",
       "            ...,\n",
       "            [5.2196e-12, 4.6581e-12, 4.4881e-12,  ..., 9.6419e-12, 6.0053e-12,\n",
       "             4.3308e-12],\n",
       "            [7.6322e-12, 6.6559e-12, 4.0270e-12,  ..., 5.1372e-12, 6.7684e-12,\n",
       "             7.4364e-12],\n",
       "            [5.7893e-12, 4.4478e-12, 3.6740e-12,  ..., 5.9993e-12, 1.0712e-11,\n",
       "             5.1463e-12]])},\n",
       "   'model.layers.16.mlp.gate_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-3.4167e-07, -7.4911e-08, -1.6733e-07,  ...,  4.5578e-07,\n",
       "              3.2471e-07,  5.9145e-07],\n",
       "            [ 1.8083e-07,  6.0961e-07, -2.5937e-07,  ..., -5.4882e-08,\n",
       "              3.8550e-07,  1.9435e-07],\n",
       "            [-7.9998e-07,  1.4611e-07,  2.4999e-07,  ...,  1.8187e-07,\n",
       "             -7.4021e-07,  3.5635e-07],\n",
       "            ...,\n",
       "            [-4.6177e-07, -6.0956e-07, -6.6974e-07,  ...,  4.1838e-07,\n",
       "             -1.2737e-08,  4.3094e-07],\n",
       "            [-1.2079e-07, -1.0911e-07,  1.9479e-07,  ..., -1.3343e-07,\n",
       "             -1.5494e-08,  5.1215e-07],\n",
       "            [-8.0611e-07,  4.4033e-07, -5.2198e-07,  ...,  6.3783e-07,\n",
       "             -8.6074e-07,  5.5987e-07]]),\n",
       "    'exp_avg_sq': tensor([[7.3377e-12, 4.7153e-12, 7.7768e-12,  ..., 5.2718e-12, 6.9904e-12,\n",
       "             6.0736e-12],\n",
       "            [5.7021e-12, 4.8124e-12, 5.9558e-12,  ..., 6.0058e-12, 4.6041e-12,\n",
       "             4.3205e-12],\n",
       "            [5.0019e-12, 7.8384e-12, 5.1932e-12,  ..., 6.4834e-12, 5.0040e-12,\n",
       "             4.6573e-12],\n",
       "            ...,\n",
       "            [5.4569e-12, 3.6239e-12, 7.7677e-12,  ..., 6.0149e-12, 4.6246e-12,\n",
       "             4.3429e-12],\n",
       "            [4.6769e-12, 4.2180e-12, 3.7309e-12,  ..., 4.5339e-12, 4.3568e-12,\n",
       "             4.5485e-12],\n",
       "            [6.5948e-12, 4.5099e-12, 4.5432e-12,  ..., 5.0151e-12, 4.4895e-12,\n",
       "             6.0509e-12]])},\n",
       "   'model.layers.16.mlp.up_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-4.2866e-07, -9.9100e-07, -7.3166e-07,  ..., -1.1582e-06,\n",
       "              1.2165e-07, -1.6208e-07],\n",
       "            [-7.6611e-08,  5.7012e-08,  1.0176e-06,  ..., -3.2425e-07,\n",
       "              1.6478e-07, -2.9354e-07],\n",
       "            [-1.3200e-07, -1.2117e-07,  1.0134e-07,  ..., -5.1001e-09,\n",
       "              1.6562e-07, -1.8424e-07],\n",
       "            ...,\n",
       "            [ 4.0077e-07, -1.2681e-07, -1.9652e-07,  ...,  2.3966e-07,\n",
       "              1.7316e-07, -4.1201e-08],\n",
       "            [ 2.8049e-07, -4.7775e-07,  2.7372e-07,  ..., -7.9269e-08,\n",
       "              1.0899e-06, -4.8857e-07],\n",
       "            [ 7.8894e-07, -1.8578e-07,  8.8780e-08,  ...,  1.6589e-07,\n",
       "             -9.2007e-07,  2.1013e-07]]),\n",
       "    'exp_avg_sq': tensor([[7.0373e-12, 5.9754e-12, 6.0577e-12,  ..., 6.6046e-12, 4.4434e-12,\n",
       "             7.9261e-12],\n",
       "            [6.4630e-12, 3.4758e-12, 5.1335e-12,  ..., 3.7303e-12, 4.6346e-12,\n",
       "             4.0294e-12],\n",
       "            [3.0783e-12, 2.4260e-12, 2.5181e-12,  ..., 3.2494e-12, 3.5738e-12,\n",
       "             2.7501e-12],\n",
       "            ...,\n",
       "            [6.1698e-12, 6.6276e-12, 6.5625e-12,  ..., 5.4901e-12, 6.0769e-12,\n",
       "             5.3243e-12],\n",
       "            [5.8841e-12, 6.7259e-12, 5.8232e-12,  ..., 5.8188e-12, 5.4232e-12,\n",
       "             3.7747e-12],\n",
       "            [4.9386e-12, 3.3802e-12, 4.7492e-12,  ..., 4.0251e-12, 7.0561e-12,\n",
       "             5.4321e-12]])},\n",
       "   'model.layers.16.post_attention_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 5.7527e-06, -8.2342e-06,  4.6174e-07,  ...,  1.7093e-08,\n",
       "            -1.3843e-06,  1.3733e-05]),\n",
       "    'exp_avg_sq': tensor([7.3690e-10, 5.2398e-10, 7.7156e-10,  ..., 4.1184e-10, 8.1446e-10,\n",
       "            5.9366e-10])},\n",
       "   'model.layers.16.self_attn.k_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-2.8014e-08,  2.4943e-06, -4.9080e-07,  ...,  1.0215e-08,\n",
       "             5.8994e-09, -4.3284e-09]),\n",
       "    'exp_avg_sq': tensor([8.9884e-11, 6.3870e-11, 2.7069e-11,  ..., 6.7774e-16, 4.6112e-16,\n",
       "            5.1614e-16])},\n",
       "   'model.layers.16.self_attn.k_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-7.7484e-07, -1.1629e-06,  1.4194e-07,  ..., -9.1050e-07,\n",
       "              5.9037e-07, -8.0171e-07],\n",
       "            [ 4.0574e-07,  1.0125e-06, -2.1978e-07,  ...,  6.7730e-07,\n",
       "             -3.0509e-07,  1.7810e-07],\n",
       "            [-3.1479e-07, -7.2928e-07,  4.8045e-08,  ...,  1.9626e-08,\n",
       "             -8.6582e-08, -4.4723e-07],\n",
       "            ...,\n",
       "            [-9.3674e-07, -1.7764e-06,  7.8660e-07,  ..., -1.3211e-07,\n",
       "              4.5124e-08,  8.2005e-08],\n",
       "            [-1.7300e-07, -1.2543e-06,  5.1589e-07,  ..., -8.6288e-08,\n",
       "             -2.7986e-07,  1.3206e-06],\n",
       "            [-2.4583e-07,  1.3601e-07,  1.7253e-07,  ...,  1.4529e-06,\n",
       "              2.1708e-07, -9.3666e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.3870e-11, 1.6061e-11, 1.0972e-11,  ..., 1.2272e-11, 1.6503e-11,\n",
       "             1.4248e-11],\n",
       "            [8.6555e-12, 1.1093e-11, 5.3663e-12,  ..., 7.1407e-12, 1.0063e-11,\n",
       "             7.7672e-12],\n",
       "            [1.7976e-12, 3.8683e-12, 3.2989e-12,  ..., 2.4326e-12, 2.3959e-12,\n",
       "             3.0235e-12],\n",
       "            ...,\n",
       "            [6.1949e-12, 1.1178e-11, 8.0970e-12,  ..., 1.2169e-11, 7.4829e-12,\n",
       "             7.5267e-12],\n",
       "            [6.2818e-12, 7.3111e-12, 6.3193e-12,  ..., 9.1742e-12, 6.8441e-12,\n",
       "             8.2175e-12],\n",
       "            [4.2594e-12, 7.9695e-12, 5.1571e-12,  ..., 8.2602e-12, 6.1508e-12,\n",
       "             7.7346e-12]])},\n",
       "   'model.layers.16.self_attn.o_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-1.0511e-06, -1.7391e-07,  2.6441e-07,  ...,  2.5813e-07,\n",
       "             -1.1141e-06,  4.4252e-07],\n",
       "            [-7.9569e-07,  5.3950e-07, -1.0306e-06,  ...,  1.8291e-07,\n",
       "              1.3495e-06,  3.3344e-07],\n",
       "            [ 2.6304e-07, -5.3026e-07,  6.8802e-07,  ...,  7.8038e-07,\n",
       "              1.2164e-07, -8.4281e-07],\n",
       "            ...,\n",
       "            [-1.5470e-06, -3.3146e-07, -3.4026e-07,  ...,  7.5792e-09,\n",
       "              8.4379e-07,  2.0549e-06],\n",
       "            [-1.1878e-06,  4.0607e-07,  1.8229e-07,  ...,  5.7611e-07,\n",
       "             -7.6722e-08, -3.6913e-07],\n",
       "            [-2.3644e-07,  5.3889e-07, -2.9190e-07,  ..., -2.1568e-07,\n",
       "              6.8775e-07, -4.6886e-08]]),\n",
       "    'exp_avg_sq': tensor([[9.6029e-12, 1.1420e-11, 1.0531e-11,  ..., 6.2727e-12, 1.0317e-11,\n",
       "             9.5049e-12],\n",
       "            [9.9903e-12, 7.7883e-12, 1.1333e-11,  ..., 8.3961e-12, 1.1479e-11,\n",
       "             6.4259e-12],\n",
       "            [7.1089e-12, 9.3648e-12, 8.3337e-12,  ..., 8.6203e-12, 5.6570e-12,\n",
       "             6.5538e-12],\n",
       "            ...,\n",
       "            [9.9918e-12, 6.4255e-12, 7.5471e-12,  ..., 6.5693e-12, 9.5635e-12,\n",
       "             9.9632e-12],\n",
       "            [8.3340e-12, 6.4706e-12, 6.3248e-12,  ..., 5.3845e-12, 6.3495e-12,\n",
       "             7.0203e-12],\n",
       "            [1.0022e-11, 7.5975e-12, 5.7351e-12,  ..., 8.0440e-12, 5.7781e-12,\n",
       "             1.0460e-11]])},\n",
       "   'model.layers.16.self_attn.q_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 2.5347e-07,  1.4841e-06, -2.5546e-06,  ...,  1.4474e-06,\n",
       "             2.9656e-06, -2.8481e-06]),\n",
       "    'exp_avg_sq': tensor([1.0082e-10, 5.3309e-11, 6.8142e-11,  ..., 5.1335e-11, 6.9332e-11,\n",
       "            5.7728e-11])},\n",
       "   'model.layers.16.self_attn.q_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-7.0258e-07, -1.5183e-08,  2.8289e-07,  ...,  8.4103e-08,\n",
       "              3.1233e-07,  8.4552e-08],\n",
       "            [ 2.8608e-07, -1.1746e-07, -3.0950e-08,  ..., -1.2622e-07,\n",
       "              2.5276e-07, -8.5033e-08],\n",
       "            [-3.0887e-07, -4.8123e-08, -5.3972e-07,  ...,  2.7050e-07,\n",
       "              5.9972e-08, -1.8133e-07],\n",
       "            ...,\n",
       "            [ 1.1506e-06, -8.0407e-07,  2.3598e-07,  ...,  4.8448e-07,\n",
       "             -3.2449e-07, -2.7098e-07],\n",
       "            [ 1.3423e-06, -2.0682e-08,  1.3857e-07,  ...,  8.8279e-07,\n",
       "             -1.4199e-08, -7.5015e-07],\n",
       "            [ 1.3709e-08,  6.1589e-07, -3.3250e-07,  ...,  4.6687e-07,\n",
       "              9.2780e-08,  1.3516e-07]]),\n",
       "    'exp_avg_sq': tensor([[8.8863e-12, 2.0119e-11, 1.3155e-11,  ..., 1.3029e-11, 1.3487e-11,\n",
       "             1.4797e-11],\n",
       "            [2.9025e-12, 7.8180e-12, 5.8890e-12,  ..., 5.9291e-12, 6.3312e-12,\n",
       "             5.2582e-12],\n",
       "            [6.1607e-12, 5.0098e-12, 5.7049e-12,  ..., 4.3845e-12, 4.8936e-12,\n",
       "             6.5024e-12],\n",
       "            ...,\n",
       "            [9.4653e-12, 1.0759e-11, 6.9538e-12,  ..., 6.5630e-12, 5.5801e-12,\n",
       "             6.4670e-12],\n",
       "            [1.0928e-11, 7.6208e-12, 8.1482e-12,  ..., 9.4120e-12, 6.4979e-12,\n",
       "             3.8425e-12],\n",
       "            [3.9183e-12, 4.9724e-12, 4.7221e-12,  ..., 3.1217e-12, 3.6140e-12,\n",
       "             4.8229e-12]])},\n",
       "   'model.layers.16.self_attn.v_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-5.7095e-07, -8.9291e-06, -8.6156e-07,  ..., -1.4430e-06,\n",
       "            -1.7408e-06,  2.0904e-06]),\n",
       "    'exp_avg_sq': tensor([5.7142e-10, 7.0264e-10, 4.0302e-10,  ..., 3.1214e-10, 5.3813e-10,\n",
       "            1.8681e-10])},\n",
       "   'model.layers.16.self_attn.v_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-9.0468e-07, -2.6695e-07, -1.5540e-06,  ..., -1.6645e-07,\n",
       "             -4.3394e-07,  1.3373e-08],\n",
       "            [-1.7877e-06, -2.8517e-07, -3.3309e-07,  ..., -6.7581e-07,\n",
       "             -3.7986e-07, -8.5618e-07],\n",
       "            [-2.3721e-07,  1.3325e-07,  7.8184e-08,  ..., -6.2161e-07,\n",
       "             -6.2296e-08,  7.2174e-07],\n",
       "            ...,\n",
       "            [ 2.1445e-07, -2.2034e-07, -3.6086e-07,  ...,  8.8675e-08,\n",
       "             -6.1642e-07, -2.3698e-07],\n",
       "            [-5.2648e-07, -6.7813e-07,  1.3333e-07,  ...,  1.3075e-06,\n",
       "              3.3940e-07, -4.1360e-07],\n",
       "            [-2.6061e-07, -6.6070e-07,  3.0093e-07,  ...,  5.1131e-07,\n",
       "             -6.0929e-07,  5.6766e-08]]),\n",
       "    'exp_avg_sq': tensor([[7.9670e-12, 5.8293e-12, 1.2204e-11,  ..., 4.8020e-12, 9.0482e-12,\n",
       "             5.2469e-12],\n",
       "            [1.0037e-11, 1.4345e-11, 1.0877e-11,  ..., 6.1297e-12, 8.0720e-12,\n",
       "             6.3362e-12],\n",
       "            [9.1600e-12, 1.3475e-11, 5.6900e-12,  ..., 5.3792e-12, 6.9637e-12,\n",
       "             6.9671e-12],\n",
       "            ...,\n",
       "            [4.1203e-12, 3.3100e-12, 3.1466e-12,  ..., 4.3188e-12, 2.8591e-12,\n",
       "             2.9463e-12],\n",
       "            [4.5963e-12, 3.8640e-12, 2.9736e-12,  ..., 3.6197e-12, 3.9159e-12,\n",
       "             3.7656e-12],\n",
       "            [2.7517e-12, 4.9230e-12, 2.8477e-12,  ..., 2.6064e-12, 4.9041e-12,\n",
       "             5.0272e-12]])},\n",
       "   'model.layers.17.input_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-1.5009e-06,  6.9382e-07, -7.9598e-06,  ..., -1.5369e-06,\n",
       "             4.3933e-06,  1.8062e-06]),\n",
       "    'exp_avg_sq': tensor([4.0882e-10, 4.8525e-10, 3.4469e-10,  ..., 5.2150e-10, 3.8531e-10,\n",
       "            2.9069e-10])},\n",
       "   'model.layers.17.mlp.down_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-8.6542e-07, -4.7590e-07, -4.5894e-07,  ..., -1.2970e-07,\n",
       "             -4.1538e-08,  8.0195e-07],\n",
       "            [-6.1747e-07, -7.7436e-07, -1.4177e-06,  ...,  6.3161e-07,\n",
       "             -2.2129e-08,  8.5779e-07],\n",
       "            [-7.1927e-07,  2.5786e-07,  4.0608e-07,  ..., -7.4013e-07,\n",
       "             -4.5202e-07,  9.0208e-07],\n",
       "            ...,\n",
       "            [ 2.5916e-08,  5.7432e-07, -9.8110e-08,  ..., -1.2741e-06,\n",
       "             -4.2958e-07,  1.0806e-06],\n",
       "            [-1.6907e-07, -4.2376e-07,  5.6953e-08,  ...,  5.5235e-07,\n",
       "              6.0735e-07,  6.5418e-07],\n",
       "            [ 9.9417e-07,  1.1410e-06,  5.4315e-07,  ...,  2.5403e-07,\n",
       "              1.6840e-06, -3.8352e-07]]),\n",
       "    'exp_avg_sq': tensor([[4.0561e-12, 7.4290e-12, 8.5669e-12,  ..., 6.7246e-12, 6.8233e-12,\n",
       "             1.0239e-11],\n",
       "            [6.8544e-12, 7.2381e-12, 1.0148e-11,  ..., 1.0803e-11, 6.7938e-12,\n",
       "             7.4302e-12],\n",
       "            [8.8128e-12, 9.7631e-12, 9.4690e-12,  ..., 1.1073e-11, 6.9133e-12,\n",
       "             1.0331e-11],\n",
       "            ...,\n",
       "            [1.0489e-11, 7.3833e-12, 9.0592e-12,  ..., 6.0866e-12, 7.1501e-12,\n",
       "             8.0732e-12],\n",
       "            [7.1673e-12, 7.4546e-12, 5.3448e-12,  ..., 1.0027e-11, 6.8007e-12,\n",
       "             1.1040e-11],\n",
       "            [9.1288e-12, 1.0005e-11, 6.9172e-12,  ..., 6.7519e-12, 1.0268e-11,\n",
       "             8.6136e-12]])},\n",
       "   'model.layers.17.mlp.gate_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 2.2605e-07,  2.3445e-07,  8.4303e-07,  ..., -2.7425e-07,\n",
       "              9.8664e-07,  9.4738e-07],\n",
       "            [ 4.7493e-07, -5.1492e-07, -5.7508e-07,  ...,  1.3028e-07,\n",
       "              3.2731e-07,  1.8534e-07],\n",
       "            [-2.4052e-07, -4.5373e-07, -7.5855e-07,  ...,  1.9955e-07,\n",
       "              6.6547e-07, -1.0379e-06],\n",
       "            ...,\n",
       "            [ 6.7851e-07,  5.4609e-07,  2.0051e-07,  ..., -4.7974e-07,\n",
       "             -6.0684e-07, -3.2875e-07],\n",
       "            [ 2.8106e-07,  2.6076e-07,  4.0745e-07,  ...,  7.4863e-07,\n",
       "             -2.6597e-08,  1.1582e-07],\n",
       "            [-4.5636e-07,  7.3060e-07,  1.6048e-07,  ..., -8.9397e-07,\n",
       "              4.2123e-07,  7.5317e-08]]),\n",
       "    'exp_avg_sq': tensor([[4.9555e-12, 5.1420e-12, 1.0269e-11,  ..., 8.4741e-12, 7.3450e-12,\n",
       "             5.6509e-12],\n",
       "            [5.9265e-12, 5.5922e-12, 6.4145e-12,  ..., 4.7259e-12, 7.4402e-12,\n",
       "             6.7768e-12],\n",
       "            [4.6571e-12, 7.2961e-12, 7.5369e-12,  ..., 5.8804e-12, 8.9019e-12,\n",
       "             1.1573e-11],\n",
       "            ...,\n",
       "            [6.8717e-12, 1.3237e-11, 1.0700e-11,  ..., 5.4391e-12, 7.2822e-12,\n",
       "             7.7745e-12],\n",
       "            [6.0284e-12, 5.9729e-12, 6.4929e-12,  ..., 5.7153e-12, 4.4000e-12,\n",
       "             6.1571e-12],\n",
       "            [1.2550e-11, 9.0409e-12, 5.8493e-12,  ..., 6.8640e-12, 9.5647e-12,\n",
       "             7.7236e-12]])},\n",
       "   'model.layers.17.mlp.up_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 1.8746e-07,  1.8448e-07,  5.5337e-07,  ...,  8.2225e-09,\n",
       "             -3.3813e-08, -8.2684e-07],\n",
       "            [ 1.9497e-08,  5.3675e-07,  1.1902e-07,  ...,  8.4016e-08,\n",
       "              3.6186e-07,  2.0720e-07],\n",
       "            [-3.3887e-07,  1.1214e-06,  2.2614e-07,  ...,  2.8382e-07,\n",
       "             -4.9478e-07,  1.9661e-06],\n",
       "            ...,\n",
       "            [ 4.0136e-07, -2.0648e-08,  7.5591e-08,  ..., -7.9341e-08,\n",
       "              7.2401e-07,  4.1193e-07],\n",
       "            [ 1.7749e-07,  2.1925e-07, -6.4328e-07,  ...,  2.8437e-07,\n",
       "             -9.5022e-08, -5.0024e-07],\n",
       "            [-3.5749e-07,  4.5369e-07,  4.7502e-07,  ...,  3.1175e-07,\n",
       "              1.0280e-06, -1.1267e-07]]),\n",
       "    'exp_avg_sq': tensor([[4.7934e-12, 5.9020e-12, 6.5694e-12,  ..., 3.8708e-12, 4.5736e-12,\n",
       "             8.0014e-12],\n",
       "            [5.4748e-12, 7.7008e-12, 5.0059e-12,  ..., 8.0961e-12, 6.2147e-12,\n",
       "             7.6391e-12],\n",
       "            [7.3451e-12, 6.8926e-12, 6.5392e-12,  ..., 5.2590e-12, 7.7408e-12,\n",
       "             1.2594e-11],\n",
       "            ...,\n",
       "            [4.8296e-12, 3.8650e-12, 8.1092e-12,  ..., 4.7583e-12, 4.3157e-12,\n",
       "             5.2116e-12],\n",
       "            [6.3304e-12, 3.9107e-12, 3.8993e-12,  ..., 3.8522e-12, 6.2204e-12,\n",
       "             5.9581e-12],\n",
       "            [8.6554e-12, 7.5080e-12, 6.0352e-12,  ..., 5.2498e-12, 7.9787e-12,\n",
       "             7.7713e-12]])},\n",
       "   'model.layers.17.post_attention_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-1.8208e-06,  1.4180e-06, -1.4793e-05,  ...,  1.9820e-06,\n",
       "            -2.8974e-08,  5.0022e-06]),\n",
       "    'exp_avg_sq': tensor([3.8059e-10, 6.3465e-10, 7.4682e-10,  ..., 4.7540e-10, 5.6607e-10,\n",
       "            8.1507e-10])},\n",
       "   'model.layers.17.self_attn.k_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 3.5072e-07, -3.8385e-07,  6.0022e-07,  ..., -9.6427e-10,\n",
       "            -4.3377e-10,  2.4877e-10]),\n",
       "    'exp_avg_sq': tensor([2.3672e-11, 2.1222e-11, 4.6362e-11,  ..., 1.8763e-16, 9.6064e-17,\n",
       "            8.7566e-17])},\n",
       "   'model.layers.17.self_attn.k_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 4.0862e-08,  2.0033e-07, -2.2543e-07,  ...,  4.4430e-07,\n",
       "              2.7623e-08, -3.9201e-07],\n",
       "            [-1.8391e-07,  1.3243e-06, -3.6128e-07,  ...,  1.5484e-07,\n",
       "              1.2502e-06, -4.9103e-07],\n",
       "            [ 3.2444e-07,  3.5206e-07,  7.6837e-07,  ..., -1.0057e-06,\n",
       "              1.9573e-07, -1.0063e-07],\n",
       "            ...,\n",
       "            [-1.0530e-07, -4.0282e-07, -3.7827e-07,  ..., -5.3031e-07,\n",
       "              7.8839e-07,  1.9918e-07],\n",
       "            [ 1.5037e-07, -2.7654e-08, -1.9010e-07,  ..., -2.4463e-07,\n",
       "              5.5592e-07,  5.7871e-07],\n",
       "            [-1.9951e-07, -3.8175e-07,  2.0091e-07,  ..., -7.6056e-11,\n",
       "              6.4450e-07,  6.9786e-09]]),\n",
       "    'exp_avg_sq': tensor([[2.7047e-12, 2.9414e-12, 3.6469e-12,  ..., 2.8577e-12, 3.8274e-12,\n",
       "             4.2486e-12],\n",
       "            [3.1562e-12, 5.2738e-12, 6.9600e-12,  ..., 9.4496e-12, 5.5254e-12,\n",
       "             5.1711e-12],\n",
       "            [2.5639e-12, 4.5586e-12, 4.1140e-12,  ..., 3.6644e-12, 6.4052e-12,\n",
       "             4.7803e-12],\n",
       "            ...,\n",
       "            [2.2006e-12, 2.8700e-12, 1.5286e-12,  ..., 2.8274e-12, 2.2504e-12,\n",
       "             1.5928e-12],\n",
       "            [1.4591e-12, 1.4184e-12, 1.7849e-12,  ..., 2.3946e-12, 2.7501e-12,\n",
       "             1.6316e-12],\n",
       "            [9.9903e-13, 2.1377e-12, 1.4113e-12,  ..., 1.9895e-12, 1.6998e-12,\n",
       "             1.0328e-12]])},\n",
       "   'model.layers.17.self_attn.o_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 6.4635e-07, -2.1478e-07,  1.0161e-06,  ...,  2.6588e-07,\n",
       "              4.2939e-07, -5.6358e-07],\n",
       "            [ 1.5563e-07,  6.7760e-07,  6.1530e-07,  ..., -1.7527e-07,\n",
       "              3.1362e-07,  3.5748e-07],\n",
       "            [ 3.2868e-07, -1.5202e-07,  1.0190e-07,  ...,  4.8791e-07,\n",
       "              7.6592e-07, -3.1197e-07],\n",
       "            ...,\n",
       "            [-1.8728e-07, -4.3786e-07,  1.9176e-07,  ..., -2.5342e-08,\n",
       "             -4.2556e-09, -3.9327e-07],\n",
       "            [ 9.0195e-07, -7.0546e-07, -8.5749e-07,  ...,  2.9635e-07,\n",
       "              3.4789e-07,  2.7134e-08],\n",
       "            [-2.9226e-07,  1.9136e-07, -1.0344e-07,  ...,  3.7328e-07,\n",
       "              2.1001e-08, -2.9613e-07]]),\n",
       "    'exp_avg_sq': tensor([[9.5767e-12, 7.9348e-12, 1.1454e-11,  ..., 5.7009e-12, 7.5970e-12,\n",
       "             7.0590e-12],\n",
       "            [6.2893e-12, 9.2081e-12, 8.5952e-12,  ..., 5.4235e-12, 6.3959e-12,\n",
       "             4.9498e-12],\n",
       "            [7.4894e-12, 7.2070e-12, 7.3554e-12,  ..., 5.1334e-12, 7.7494e-12,\n",
       "             6.2700e-12],\n",
       "            ...,\n",
       "            [9.9550e-12, 4.9322e-12, 8.4936e-12,  ..., 6.8646e-12, 5.9649e-12,\n",
       "             9.2384e-12],\n",
       "            [8.4231e-12, 6.1785e-12, 1.1054e-11,  ..., 9.1583e-12, 5.4153e-12,\n",
       "             6.0812e-12],\n",
       "            [7.4387e-12, 1.0569e-11, 1.1985e-11,  ..., 6.9545e-12, 6.4342e-12,\n",
       "             5.2138e-12]])},\n",
       "   'model.layers.17.self_attn.q_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-2.4250e-06, -1.3760e-06, -1.9166e-07,  ...,  5.0328e-07,\n",
       "             1.2430e-07, -8.1881e-07]),\n",
       "    'exp_avg_sq': tensor([4.9122e-11, 2.4125e-11, 8.6802e-11,  ..., 2.3271e-11, 1.4712e-11,\n",
       "            1.8960e-11])},\n",
       "   'model.layers.17.self_attn.q_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 6.1048e-07, -6.3310e-07,  9.3751e-08,  ..., -9.9726e-07,\n",
       "             -3.6038e-07,  1.1820e-07],\n",
       "            [ 4.4394e-07, -9.6677e-07,  1.0026e-06,  ...,  8.7372e-08,\n",
       "              1.2631e-07,  3.8414e-07],\n",
       "            [ 1.2178e-06, -3.1335e-07,  2.8904e-07,  ...,  2.0430e-07,\n",
       "              1.8993e-07, -1.1922e-07],\n",
       "            ...,\n",
       "            [ 6.1689e-07,  9.4807e-08, -3.9977e-07,  ..., -1.3919e-07,\n",
       "              9.5615e-07, -4.1049e-08],\n",
       "            [-1.2252e-06,  2.2459e-07, -5.6982e-08,  ...,  1.5320e-09,\n",
       "             -1.4595e-07, -3.3579e-07],\n",
       "            [ 2.1949e-07,  4.0461e-07, -1.9512e-07,  ...,  8.3755e-07,\n",
       "              1.1728e-07, -7.3976e-08]]),\n",
       "    'exp_avg_sq': tensor([[5.9760e-12, 5.5237e-12, 5.5035e-12,  ..., 7.3183e-12, 4.4185e-12,\n",
       "             5.2222e-12],\n",
       "            [3.9134e-12, 4.9354e-12, 6.4347e-12,  ..., 3.5992e-12, 3.8838e-12,\n",
       "             2.8329e-12],\n",
       "            [7.1481e-12, 6.9893e-12, 1.0756e-11,  ..., 6.9642e-12, 8.2415e-12,\n",
       "             8.0029e-12],\n",
       "            ...,\n",
       "            [2.6279e-12, 1.5406e-12, 2.5353e-12,  ..., 2.3534e-12, 4.1822e-12,\n",
       "             2.6282e-12],\n",
       "            [3.1500e-12, 2.0303e-12, 1.6813e-12,  ..., 2.1970e-12, 2.5900e-12,\n",
       "             2.1491e-12],\n",
       "            [1.8784e-12, 2.1543e-12, 2.1318e-12,  ..., 2.1383e-12, 1.4703e-12,\n",
       "             2.0335e-12]])},\n",
       "   'model.layers.17.self_attn.v_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 4.2857e-06, -9.5104e-06,  1.0746e-06,  ...,  3.8673e-06,\n",
       "            -2.9704e-06,  3.1773e-06]),\n",
       "    'exp_avg_sq': tensor([7.9440e-10, 8.8775e-10, 1.0629e-09,  ..., 1.9906e-10, 2.1061e-10,\n",
       "            2.2438e-10])},\n",
       "   'model.layers.17.self_attn.v_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 3.1408e-07,  5.3169e-07, -2.4298e-08,  ...,  3.5414e-07,\n",
       "             -1.2594e-07,  5.0989e-07],\n",
       "            [-3.1440e-08, -4.1149e-07, -1.9063e-07,  ...,  1.0238e-06,\n",
       "              9.9502e-07,  1.7521e-07],\n",
       "            [ 1.2275e-06,  6.1271e-07, -1.0004e-06,  ..., -4.4820e-07,\n",
       "             -2.6440e-07, -4.0480e-07],\n",
       "            ...,\n",
       "            [-1.3341e-07,  6.1055e-08,  1.0927e-07,  ...,  5.6386e-07,\n",
       "              3.0985e-07,  7.1363e-07],\n",
       "            [ 2.7894e-07, -1.1371e-07,  5.1402e-07,  ..., -5.3678e-08,\n",
       "             -2.3240e-07, -8.0231e-07],\n",
       "            [ 3.7462e-07, -3.4934e-07,  8.0958e-08,  ..., -7.9719e-07,\n",
       "              4.8894e-07,  3.5571e-07]]),\n",
       "    'exp_avg_sq': tensor([[7.5819e-12, 5.5112e-12, 9.5365e-12,  ..., 6.5840e-12, 6.9613e-12,\n",
       "             6.3557e-12],\n",
       "            [6.5168e-12, 6.3405e-12, 1.3713e-11,  ..., 7.5130e-12, 1.0303e-11,\n",
       "             5.4514e-12],\n",
       "            [5.8278e-12, 6.8817e-12, 8.3624e-12,  ..., 6.1649e-12, 8.2007e-12,\n",
       "             6.2517e-12],\n",
       "            ...,\n",
       "            [2.9475e-12, 3.9265e-12, 4.8900e-12,  ..., 4.2049e-12, 4.9976e-12,\n",
       "             4.8087e-12],\n",
       "            [3.0991e-12, 3.4930e-12, 3.8845e-12,  ..., 3.0502e-12, 5.7571e-12,\n",
       "             5.0210e-12],\n",
       "            [4.2419e-12, 4.6073e-12, 4.8050e-12,  ..., 5.6471e-12, 3.3628e-12,\n",
       "             2.8910e-12]])},\n",
       "   'model.layers.18.input_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 1.8537e-06,  3.2279e-06,  1.1002e-06,  ...,  6.8859e-06,\n",
       "             4.4183e-06, -3.7841e-06]),\n",
       "    'exp_avg_sq': tensor([2.2451e-10, 3.1797e-10, 3.1495e-10,  ..., 2.2592e-10, 2.3707e-10,\n",
       "            2.1326e-10])},\n",
       "   'model.layers.18.mlp.down_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 5.1962e-08,  8.8018e-07,  1.5029e-07,  ...,  1.0691e-07,\n",
       "             -5.9159e-08,  9.7492e-07],\n",
       "            [ 1.0470e-07,  3.5084e-07, -4.1502e-07,  ..., -7.7644e-07,\n",
       "             -1.3741e-06, -5.2565e-07],\n",
       "            [-3.8459e-07, -1.5866e-07, -2.7159e-07,  ...,  1.5123e-08,\n",
       "             -1.8528e-07,  3.8821e-07],\n",
       "            ...,\n",
       "            [ 2.5405e-07, -6.0199e-08, -5.9398e-07,  ...,  4.9429e-07,\n",
       "             -1.7513e-06,  1.6243e-06],\n",
       "            [-2.7890e-07, -8.0305e-07, -2.2393e-07,  ..., -3.0743e-07,\n",
       "              3.9881e-07, -1.2123e-06],\n",
       "            [ 8.3892e-07, -8.4873e-07,  8.8374e-07,  ..., -7.0879e-07,\n",
       "              5.3951e-07, -8.7409e-07]]),\n",
       "    'exp_avg_sq': tensor([[8.5148e-12, 7.5108e-12, 6.9932e-12,  ..., 9.0146e-12, 8.8985e-12,\n",
       "             8.8564e-12],\n",
       "            [4.6029e-12, 8.1388e-12, 8.5354e-12,  ..., 9.5964e-12, 1.2083e-11,\n",
       "             6.7133e-12],\n",
       "            [9.2027e-12, 8.7762e-12, 8.6094e-12,  ..., 4.6048e-12, 1.5319e-11,\n",
       "             8.0245e-12],\n",
       "            ...,\n",
       "            [1.0124e-11, 1.0537e-11, 7.8874e-12,  ..., 8.1894e-12, 9.9087e-12,\n",
       "             9.8795e-12],\n",
       "            [1.1655e-11, 6.9044e-12, 9.4749e-12,  ..., 5.6228e-12, 1.1392e-11,\n",
       "             8.4369e-12],\n",
       "            [7.5282e-12, 8.5684e-12, 1.0138e-11,  ..., 7.1617e-12, 7.0680e-12,\n",
       "             8.7708e-12]])},\n",
       "   'model.layers.18.mlp.gate_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 1.2133e-06, -5.1246e-07, -1.2654e-06,  ..., -2.8458e-07,\n",
       "             -9.4030e-07, -2.9243e-07],\n",
       "            [ 1.3993e-06, -4.0085e-07,  8.1049e-07,  ...,  4.8332e-07,\n",
       "              4.9579e-07,  2.1959e-07],\n",
       "            [-2.9993e-07,  2.7604e-07, -1.1168e-07,  ...,  3.7419e-08,\n",
       "              4.9007e-07,  7.1998e-07],\n",
       "            ...,\n",
       "            [-1.0276e-07,  9.3018e-07, -7.7377e-07,  ...,  5.5491e-07,\n",
       "              7.5960e-08, -1.0163e-06],\n",
       "            [ 1.8128e-07,  3.0709e-08,  6.9006e-07,  ..., -1.5058e-06,\n",
       "              1.0739e-06,  9.0077e-08],\n",
       "            [ 5.0427e-07, -8.7370e-09,  8.6675e-07,  ...,  9.6380e-07,\n",
       "              4.5640e-07, -4.0231e-07]]),\n",
       "    'exp_avg_sq': tensor([[9.7194e-12, 5.8096e-12, 7.6633e-12,  ..., 7.5716e-12, 5.3584e-12,\n",
       "             6.8027e-12],\n",
       "            [7.2541e-12, 4.4838e-12, 8.6617e-12,  ..., 6.7145e-12, 1.0277e-11,\n",
       "             8.5360e-12],\n",
       "            [6.5997e-12, 7.4396e-12, 6.2520e-12,  ..., 4.3181e-12, 9.7038e-12,\n",
       "             6.9340e-12],\n",
       "            ...,\n",
       "            [7.5547e-12, 6.6730e-12, 8.3091e-12,  ..., 4.0687e-12, 4.8794e-12,\n",
       "             6.8138e-12],\n",
       "            [5.8793e-12, 5.1950e-12, 6.6750e-12,  ..., 1.3931e-11, 7.2337e-12,\n",
       "             7.5421e-12],\n",
       "            [6.9749e-12, 5.3571e-12, 7.6216e-12,  ..., 4.6164e-12, 8.3658e-12,\n",
       "             7.3764e-12]])},\n",
       "   'model.layers.18.mlp.up_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-8.3914e-07, -4.9799e-07, -6.7196e-07,  ..., -5.3650e-07,\n",
       "             -9.4659e-07,  5.5792e-07],\n",
       "            [ 1.9198e-07, -3.2809e-07,  1.5133e-07,  ..., -2.8711e-07,\n",
       "             -1.8209e-07,  5.9336e-07],\n",
       "            [-3.0001e-08,  4.6144e-07,  3.9895e-07,  ...,  2.4225e-07,\n",
       "              1.1600e-07,  8.6705e-08],\n",
       "            ...,\n",
       "            [-1.9226e-07,  4.1711e-07,  5.3471e-07,  ...,  5.3145e-07,\n",
       "             -7.7265e-07, -2.6225e-07],\n",
       "            [-6.1465e-08, -5.4775e-08,  1.5983e-07,  ...,  1.4923e-07,\n",
       "              4.4253e-07, -1.2255e-07],\n",
       "            [-9.7592e-07,  1.9816e-08,  1.5962e-07,  ..., -3.9650e-07,\n",
       "             -7.2903e-07, -8.2231e-07]]),\n",
       "    'exp_avg_sq': tensor([[5.1852e-12, 5.4394e-12, 7.7131e-12,  ..., 6.9623e-12, 8.1643e-12,\n",
       "             4.8712e-12],\n",
       "            [6.8883e-12, 6.0018e-12, 5.8769e-12,  ..., 5.5234e-12, 6.7599e-12,\n",
       "             7.2079e-12],\n",
       "            [6.8978e-12, 5.3268e-12, 6.0923e-12,  ..., 4.2103e-12, 4.8304e-12,\n",
       "             2.5477e-12],\n",
       "            ...,\n",
       "            [6.5514e-12, 6.0920e-12, 7.9995e-12,  ..., 4.1751e-12, 5.0040e-12,\n",
       "             6.5959e-12],\n",
       "            [6.7753e-12, 5.3714e-12, 5.0832e-12,  ..., 3.3374e-12, 5.7703e-12,\n",
       "             5.3093e-12],\n",
       "            [5.0912e-12, 5.5131e-12, 9.2252e-12,  ..., 6.3277e-12, 6.0221e-12,\n",
       "             6.2386e-12]])},\n",
       "   'model.layers.18.post_attention_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-4.8453e-06,  1.9102e-06,  9.7650e-06,  ...,  3.6578e-06,\n",
       "            -4.8088e-06, -5.2482e-06]),\n",
       "    'exp_avg_sq': tensor([5.0473e-10, 8.5654e-10, 6.0408e-10,  ..., 3.4352e-10, 5.3970e-10,\n",
       "            5.8014e-10])},\n",
       "   'model.layers.18.self_attn.k_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-2.8529e-08, -2.6098e-08, -4.7518e-07,  ...,  4.4269e-09,\n",
       "             4.0444e-09,  5.6849e-09]),\n",
       "    'exp_avg_sq': tensor([5.9520e-12, 5.5541e-12, 6.3871e-12,  ..., 1.5750e-16, 1.4057e-16,\n",
       "            1.0620e-16])},\n",
       "   'model.layers.18.self_attn.k_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 1.1419e-07,  7.7881e-08, -1.0440e-07,  ..., -3.2809e-08,\n",
       "             -1.3263e-07,  1.4968e-07],\n",
       "            [ 1.0201e-07,  4.8884e-07,  1.2536e-07,  ...,  2.3158e-07,\n",
       "             -7.0703e-08, -3.2281e-08],\n",
       "            [-1.0203e-07,  7.9998e-08,  1.4589e-07,  ..., -4.4890e-08,\n",
       "              6.1340e-08, -1.1875e-07],\n",
       "            ...,\n",
       "            [ 5.3951e-07, -4.6398e-07,  4.4672e-07,  ..., -3.5445e-07,\n",
       "              7.5440e-08,  4.9975e-07],\n",
       "            [-1.8380e-07, -1.7561e-07,  8.9010e-08,  ...,  1.6893e-07,\n",
       "             -9.6469e-08, -1.4445e-07],\n",
       "            [-3.6876e-07, -2.4548e-07,  2.5214e-07,  ...,  3.4606e-07,\n",
       "             -3.5888e-07, -4.6164e-07]]),\n",
       "    'exp_avg_sq': tensor([[8.7172e-13, 8.0014e-13, 6.1847e-13,  ..., 5.6446e-13, 9.0389e-13,\n",
       "             9.7580e-13],\n",
       "            [7.8094e-13, 1.0168e-12, 1.2214e-12,  ..., 6.4488e-13, 9.8847e-13,\n",
       "             8.9486e-13],\n",
       "            [5.6232e-13, 8.6996e-13, 6.5297e-13,  ..., 6.6876e-13, 7.4843e-13,\n",
       "             1.0708e-12],\n",
       "            ...,\n",
       "            [1.5209e-12, 2.4069e-12, 1.7035e-12,  ..., 1.2660e-12, 8.9962e-13,\n",
       "             1.4305e-12],\n",
       "            [1.6160e-12, 1.4157e-12, 1.5988e-12,  ..., 1.1352e-12, 1.0542e-12,\n",
       "             2.2128e-12],\n",
       "            [1.4980e-12, 2.1837e-12, 1.1367e-12,  ..., 1.6500e-12, 1.0346e-12,\n",
       "             1.9916e-12]])},\n",
       "   'model.layers.18.self_attn.o_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-8.9565e-07, -1.9260e-07, -2.2816e-07,  ..., -3.6978e-07,\n",
       "              7.0127e-08,  5.7345e-07],\n",
       "            [-7.0414e-07, -7.9229e-07,  8.4359e-07,  ...,  1.8807e-07,\n",
       "              6.5207e-07, -2.9943e-07],\n",
       "            [-4.2513e-07,  3.6186e-07,  6.9230e-07,  ..., -7.4926e-07,\n",
       "             -9.6381e-07, -5.8159e-07],\n",
       "            ...,\n",
       "            [ 2.6922e-07,  6.6858e-07,  1.1319e-06,  ..., -1.3232e-06,\n",
       "              2.5486e-08,  2.1383e-07],\n",
       "            [ 7.5646e-07,  4.5256e-07, -3.7866e-07,  ...,  5.2889e-07,\n",
       "             -9.1977e-07, -4.6335e-07],\n",
       "            [-6.6915e-08, -4.2261e-07,  9.5555e-07,  ...,  2.7339e-07,\n",
       "              8.2240e-07,  1.4787e-07]]),\n",
       "    'exp_avg_sq': tensor([[4.6934e-12, 6.7520e-12, 6.4286e-12,  ..., 3.3133e-12, 3.1434e-12,\n",
       "             4.1988e-12],\n",
       "            [4.2391e-12, 6.8624e-12, 6.2112e-12,  ..., 3.3092e-12, 2.9698e-12,\n",
       "             6.9527e-12],\n",
       "            [3.9575e-12, 2.9009e-12, 5.0695e-12,  ..., 5.8743e-12, 4.0475e-12,\n",
       "             4.2046e-12],\n",
       "            ...,\n",
       "            [5.1537e-12, 5.6680e-12, 8.7479e-12,  ..., 8.5132e-12, 3.7537e-12,\n",
       "             3.2896e-12],\n",
       "            [6.5574e-12, 4.5932e-12, 5.8642e-12,  ..., 4.3773e-12, 3.8897e-12,\n",
       "             3.3064e-12],\n",
       "            [4.5844e-12, 4.4728e-12, 6.5045e-12,  ..., 3.9023e-12, 4.7103e-12,\n",
       "             3.9945e-12]])},\n",
       "   'model.layers.18.self_attn.q_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-6.4525e-07,  9.9113e-07, -2.6012e-07,  ...,  1.6196e-07,\n",
       "            -2.3468e-07, -4.6934e-07]),\n",
       "    'exp_avg_sq': tensor([3.8972e-12, 6.9125e-12, 4.1823e-12,  ..., 1.5526e-11, 1.4663e-11,\n",
       "            2.4638e-11])},\n",
       "   'model.layers.18.self_attn.q_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 1.2859e-07, -1.0260e-07,  2.1536e-07,  ..., -3.2685e-07,\n",
       "              1.0820e-07, -2.1316e-08],\n",
       "            [-1.9522e-07, -6.7826e-08,  2.0672e-07,  ..., -2.3872e-07,\n",
       "             -1.6498e-08, -1.6856e-07],\n",
       "            [-7.7126e-08,  3.0990e-08,  8.9891e-08,  ..., -1.1628e-07,\n",
       "              2.2964e-07, -1.3039e-07],\n",
       "            ...,\n",
       "            [-1.5273e-07,  8.1700e-08, -1.6774e-07,  ..., -3.5626e-07,\n",
       "              1.8291e-07,  1.8747e-07],\n",
       "            [-1.8069e-07,  4.1195e-07, -4.8052e-07,  ...,  2.2778e-07,\n",
       "              2.8436e-07, -1.0086e-07],\n",
       "            [-1.1674e-07,  9.5896e-08,  3.3259e-07,  ..., -1.8834e-07,\n",
       "              6.2133e-08, -3.5157e-07]]),\n",
       "    'exp_avg_sq': tensor([[7.4180e-13, 8.0919e-13, 7.8220e-13,  ..., 1.8258e-12, 6.6776e-13,\n",
       "             9.8011e-13],\n",
       "            [8.2710e-13, 9.7048e-13, 1.2859e-12,  ..., 9.8755e-13, 6.9482e-13,\n",
       "             1.1585e-12],\n",
       "            [6.4608e-13, 8.0022e-13, 9.3518e-13,  ..., 8.7534e-13, 1.1420e-12,\n",
       "             1.1812e-12],\n",
       "            ...,\n",
       "            [1.6701e-12, 2.2829e-12, 1.8741e-12,  ..., 1.0238e-12, 2.7554e-12,\n",
       "             1.7599e-12],\n",
       "            [2.4931e-12, 1.7304e-12, 1.9750e-12,  ..., 1.6054e-12, 1.9444e-12,\n",
       "             2.2757e-12],\n",
       "            [2.3256e-12, 1.3297e-12, 2.8595e-12,  ..., 2.8125e-12, 1.8687e-12,\n",
       "             1.2882e-12]])},\n",
       "   'model.layers.18.self_attn.v_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 1.2865e-06, -2.4923e-06, -2.4563e-06,  ..., -1.5527e-06,\n",
       "             3.4580e-06, -9.8215e-07]),\n",
       "    'exp_avg_sq': tensor([1.9419e-10, 1.5501e-10, 2.2338e-10,  ..., 1.6292e-10, 1.9863e-10,\n",
       "            1.2413e-10])},\n",
       "   'model.layers.18.self_attn.v_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 7.7970e-08, -1.8226e-07, -1.7623e-07,  ...,  3.1782e-07,\n",
       "             -8.3784e-07, -8.1835e-08],\n",
       "            [ 3.9650e-07,  2.2920e-07, -4.2766e-08,  ..., -3.7818e-07,\n",
       "             -4.6016e-07, -4.3250e-07],\n",
       "            [ 2.3360e-07, -3.9207e-07,  9.4887e-07,  ...,  4.2787e-08,\n",
       "              1.9133e-07, -1.5814e-07],\n",
       "            ...,\n",
       "            [-1.7059e-07,  1.3975e-07, -1.4817e-08,  ..., -1.6673e-08,\n",
       "             -7.3094e-08, -9.9226e-08],\n",
       "            [ 1.4106e-07,  3.4068e-07,  1.6280e-07,  ..., -1.7705e-07,\n",
       "             -4.5265e-07, -1.9900e-07],\n",
       "            [ 3.0415e-07,  3.3737e-08,  2.8227e-07,  ..., -8.4093e-07,\n",
       "              3.6233e-08,  5.5288e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.6638e-12, 2.1940e-12, 2.3756e-12,  ..., 2.6095e-12, 2.8334e-12,\n",
       "             2.4443e-12],\n",
       "            [2.2599e-12, 4.3693e-12, 3.2637e-12,  ..., 2.5566e-12, 2.7001e-12,\n",
       "             2.4466e-12],\n",
       "            [3.2482e-12, 3.2076e-12, 3.1513e-12,  ..., 2.4307e-12, 2.8564e-12,\n",
       "             3.2844e-12],\n",
       "            ...,\n",
       "            [2.4477e-12, 1.9223e-12, 2.3665e-12,  ..., 1.7579e-12, 2.2480e-12,\n",
       "             2.7101e-12],\n",
       "            [2.2542e-12, 3.1740e-12, 2.5630e-12,  ..., 2.3959e-12, 2.7818e-12,\n",
       "             1.8059e-12],\n",
       "            [2.3458e-12, 2.5115e-12, 2.2073e-12,  ..., 2.8251e-12, 1.4851e-12,\n",
       "             1.7757e-12]])},\n",
       "   'model.layers.19.input_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-1.6934e-06,  1.2651e-06,  7.7659e-08,  ...,  1.8432e-06,\n",
       "            -1.5958e-06, -4.5798e-06]),\n",
       "    'exp_avg_sq': tensor([2.9354e-10, 1.8670e-10, 2.3999e-10,  ..., 1.9691e-10, 2.3868e-10,\n",
       "            1.9587e-10])},\n",
       "   'model.layers.19.mlp.down_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 4.8430e-07,  8.9718e-07,  1.0612e-07,  ..., -1.5065e-07,\n",
       "             -1.3939e-07,  8.9624e-07],\n",
       "            [-1.0751e-06,  6.0889e-07,  2.9806e-07,  ..., -1.4432e-07,\n",
       "              7.9702e-07, -1.5360e-07],\n",
       "            [-1.2938e-07, -5.7642e-07,  1.1033e-06,  ...,  4.8215e-07,\n",
       "             -7.8735e-08,  5.5274e-07],\n",
       "            ...,\n",
       "            [ 2.1614e-07,  1.7138e-07, -4.3126e-07,  ..., -3.3347e-07,\n",
       "              4.2735e-07, -2.8225e-07],\n",
       "            [ 1.0767e-06,  9.4464e-07, -1.0378e-06,  ...,  1.1614e-06,\n",
       "              4.7427e-07,  4.4527e-07],\n",
       "            [-1.0057e-06,  3.7888e-07, -9.7043e-09,  ...,  6.0585e-07,\n",
       "             -1.6803e-07,  3.3453e-07]]),\n",
       "    'exp_avg_sq': tensor([[6.4282e-12, 9.7647e-12, 1.0729e-11,  ..., 1.1095e-11, 9.5162e-12,\n",
       "             9.2795e-12],\n",
       "            [8.1933e-12, 1.4608e-11, 1.0982e-11,  ..., 1.0862e-11, 1.2736e-11,\n",
       "             5.9892e-12],\n",
       "            [7.2404e-12, 1.2813e-11, 7.5320e-12,  ..., 1.0762e-11, 5.6748e-12,\n",
       "             6.0099e-12],\n",
       "            ...,\n",
       "            [9.9854e-12, 1.6882e-11, 6.5058e-12,  ..., 7.4517e-12, 9.3698e-12,\n",
       "             5.4038e-12],\n",
       "            [9.5971e-12, 1.0488e-11, 8.1692e-12,  ..., 7.6432e-12, 8.6788e-12,\n",
       "             8.6070e-12],\n",
       "            [1.0836e-11, 1.6281e-11, 8.2241e-12,  ..., 6.6969e-12, 9.4189e-12,\n",
       "             8.1117e-12]])},\n",
       "   'model.layers.19.mlp.gate_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-2.1860e-07,  1.0487e-06, -1.4804e-07,  ...,  7.7816e-07,\n",
       "             -4.1457e-07,  1.1876e-06],\n",
       "            [-1.2496e-06, -1.1149e-06,  4.6381e-08,  ...,  3.0299e-07,\n",
       "              4.3953e-07, -1.9132e-07],\n",
       "            [ 6.2551e-07, -3.5332e-08, -8.1660e-08,  ...,  6.0994e-07,\n",
       "             -9.0052e-07,  5.6208e-07],\n",
       "            ...,\n",
       "            [-3.8779e-07, -4.5564e-07, -1.8911e-07,  ...,  3.5893e-07,\n",
       "             -5.2237e-08,  4.1182e-07],\n",
       "            [ 3.3313e-07,  7.1113e-07,  8.6724e-07,  ...,  1.1982e-06,\n",
       "             -5.1674e-07, -1.0663e-06],\n",
       "            [-1.0288e-06, -1.2604e-07, -5.9646e-08,  ..., -1.5405e-06,\n",
       "              1.0895e-06,  7.8393e-07]]),\n",
       "    'exp_avg_sq': tensor([[4.2798e-12, 8.3114e-12, 8.0891e-12,  ..., 7.8314e-12, 7.0859e-12,\n",
       "             8.9536e-12],\n",
       "            [7.7481e-12, 7.8693e-12, 8.5850e-12,  ..., 8.9774e-12, 1.3354e-11,\n",
       "             1.3640e-11],\n",
       "            [1.1934e-11, 5.4570e-12, 1.0560e-11,  ..., 1.0934e-11, 7.6100e-12,\n",
       "             7.0221e-12],\n",
       "            ...,\n",
       "            [5.4436e-12, 5.5795e-12, 4.1672e-12,  ..., 5.3817e-12, 6.4378e-12,\n",
       "             7.8527e-12],\n",
       "            [8.9382e-12, 9.8591e-12, 1.0031e-11,  ..., 8.3579e-12, 7.7798e-12,\n",
       "             7.5862e-12],\n",
       "            [6.5896e-12, 6.1633e-12, 7.8573e-12,  ..., 7.6445e-12, 7.3325e-12,\n",
       "             5.9825e-12]])},\n",
       "   'model.layers.19.mlp.up_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 1.8144e-07, -4.6875e-08,  3.5542e-08,  ...,  4.7234e-07,\n",
       "              1.2990e-06,  7.9271e-07],\n",
       "            [ 5.9288e-07, -5.8545e-07,  2.8699e-07,  ...,  7.2172e-07,\n",
       "              3.8478e-07,  9.9142e-08],\n",
       "            [ 2.3998e-07, -1.0347e-06,  2.5037e-07,  ..., -1.6762e-08,\n",
       "             -7.1538e-07, -8.4635e-07],\n",
       "            ...,\n",
       "            [-2.7008e-07,  1.2908e-06, -2.8942e-08,  ..., -1.3645e-07,\n",
       "             -5.7438e-07,  4.9093e-07],\n",
       "            [-5.0340e-07, -4.6628e-07, -8.8618e-07,  ..., -7.9877e-07,\n",
       "              8.7575e-08, -1.2876e-06],\n",
       "            [ 3.6035e-07, -7.6776e-07, -2.2497e-07,  ..., -1.4741e-06,\n",
       "             -1.8559e-07,  3.6390e-07]]),\n",
       "    'exp_avg_sq': tensor([[5.3491e-12, 4.4379e-12, 6.6976e-12,  ..., 4.0846e-12, 7.3555e-12,\n",
       "             4.2968e-12],\n",
       "            [7.6011e-12, 6.8615e-12, 8.6890e-12,  ..., 7.6612e-12, 9.2842e-12,\n",
       "             8.5927e-12],\n",
       "            [4.0782e-12, 4.7293e-12, 5.9084e-12,  ..., 4.8233e-12, 4.4341e-12,\n",
       "             4.8884e-12],\n",
       "            ...,\n",
       "            [4.1269e-12, 6.8245e-12, 4.6635e-12,  ..., 3.9220e-12, 4.9249e-12,\n",
       "             3.7351e-12],\n",
       "            [8.9488e-12, 7.4884e-12, 8.0617e-12,  ..., 9.0011e-12, 6.4916e-12,\n",
       "             9.8993e-12],\n",
       "            [6.7115e-12, 6.9700e-12, 5.9358e-12,  ..., 6.9435e-12, 4.0174e-12,\n",
       "             5.9694e-12]])},\n",
       "   'model.layers.19.post_attention_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-9.5601e-07, -2.8111e-06, -2.1406e-06,  ..., -4.7813e-06,\n",
       "            -1.2472e-05, -1.1990e-06]),\n",
       "    'exp_avg_sq': tensor([5.6863e-10, 3.0711e-10, 5.4202e-10,  ..., 3.6483e-10, 5.3475e-10,\n",
       "            4.2848e-10])},\n",
       "   'model.layers.19.self_attn.k_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-8.5207e-08, -3.4903e-07,  1.2874e-07,  ...,  2.8955e-09,\n",
       "             3.1080e-09, -3.9166e-10]),\n",
       "    'exp_avg_sq': tensor([2.4616e-12, 4.3082e-12, 4.6995e-12,  ..., 2.9871e-16, 1.9750e-16,\n",
       "            1.7578e-16])},\n",
       "   'model.layers.19.self_attn.k_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 7.1569e-08, -1.5766e-07, -1.2226e-07,  ...,  7.7778e-08,\n",
       "             -2.2322e-07,  2.8172e-07],\n",
       "            [-1.2899e-07,  7.9366e-08, -2.2714e-07,  ..., -3.2809e-07,\n",
       "             -1.3912e-07,  1.7556e-07],\n",
       "            [-2.4367e-07, -2.0964e-07, -7.9374e-08,  ..., -7.2671e-08,\n",
       "             -2.4164e-07, -2.0480e-08],\n",
       "            ...,\n",
       "            [-6.3497e-07, -3.8036e-07,  1.1117e-07,  ..., -5.8973e-08,\n",
       "             -7.0825e-08,  3.4291e-08],\n",
       "            [ 3.7878e-07, -1.6101e-07,  2.5503e-07,  ..., -3.3726e-07,\n",
       "             -1.9525e-08,  2.2549e-07],\n",
       "            [-6.0840e-07, -2.8874e-08,  1.4956e-07,  ..., -1.9040e-07,\n",
       "             -2.0703e-07,  6.9189e-08]]),\n",
       "    'exp_avg_sq': tensor([[5.5765e-13, 6.3701e-13, 6.2232e-13,  ..., 7.1984e-13, 8.9885e-13,\n",
       "             8.7250e-13],\n",
       "            [4.7378e-13, 4.0618e-13, 8.4484e-13,  ..., 6.4095e-13, 5.1072e-13,\n",
       "             4.4990e-13],\n",
       "            [5.9735e-13, 6.7019e-13, 5.4762e-13,  ..., 4.1256e-13, 6.7630e-13,\n",
       "             6.1207e-13],\n",
       "            ...,\n",
       "            [3.1158e-12, 2.9587e-12, 2.2846e-12,  ..., 2.2655e-12, 2.5158e-12,\n",
       "             1.9999e-12],\n",
       "            [1.5681e-12, 1.6620e-12, 2.4783e-12,  ..., 1.7428e-12, 2.2757e-12,\n",
       "             3.0020e-12],\n",
       "            [2.6535e-12, 4.0433e-12, 4.1641e-12,  ..., 1.7269e-12, 2.1039e-12,\n",
       "             2.2767e-12]])},\n",
       "   'model.layers.19.self_attn.o_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-4.6771e-07, -3.5569e-07, -7.6593e-07,  ...,  6.5929e-07,\n",
       "             -1.8225e-07,  2.2821e-08],\n",
       "            [ 2.7177e-07,  1.5989e-07,  4.4403e-07,  ...,  4.6307e-07,\n",
       "             -5.4172e-08,  7.5659e-07],\n",
       "            [ 7.9186e-08,  3.4327e-07,  4.1958e-08,  ..., -4.4189e-07,\n",
       "              9.1189e-08,  1.2880e-07],\n",
       "            ...,\n",
       "            [-5.5383e-08, -4.1524e-07, -7.7517e-07,  ...,  8.5894e-08,\n",
       "              4.3481e-07,  9.3871e-07],\n",
       "            [-3.8644e-07,  4.7981e-07, -9.9093e-08,  ..., -8.7023e-07,\n",
       "              4.5557e-07,  1.9006e-08],\n",
       "            [ 9.5742e-07, -6.8683e-08, -4.0574e-07,  ..., -4.0945e-07,\n",
       "             -7.6010e-07, -5.6121e-08]]),\n",
       "    'exp_avg_sq': tensor([[3.1004e-12, 2.8859e-12, 4.8403e-12,  ..., 3.7698e-12, 3.1872e-12,\n",
       "             3.1123e-12],\n",
       "            [2.4940e-12, 2.8970e-12, 2.9016e-12,  ..., 3.1343e-12, 4.7073e-12,\n",
       "             3.1445e-12],\n",
       "            [4.4934e-12, 4.0687e-12, 3.8669e-12,  ..., 3.8299e-12, 3.8196e-12,\n",
       "             3.6138e-12],\n",
       "            ...,\n",
       "            [3.2162e-12, 4.5645e-12, 3.9017e-12,  ..., 4.6538e-12, 3.6363e-12,\n",
       "             6.4706e-12],\n",
       "            [4.2560e-12, 3.6885e-12, 5.0234e-12,  ..., 3.7723e-12, 2.7481e-12,\n",
       "             4.3693e-12],\n",
       "            [5.9173e-12, 2.7637e-12, 4.0849e-12,  ..., 4.5834e-12, 5.1561e-12,\n",
       "             5.2089e-12]])},\n",
       "   'model.layers.19.self_attn.q_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-5.5306e-07,  3.0556e-07, -8.3300e-07,  ...,  6.3493e-07,\n",
       "            -8.1163e-07, -1.0256e-06]),\n",
       "    'exp_avg_sq': tensor([8.7176e-12, 5.2095e-12, 8.0341e-12,  ..., 1.1602e-11, 2.1310e-11,\n",
       "            2.0589e-11])},\n",
       "   'model.layers.19.self_attn.q_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-2.8788e-07, -6.1056e-08,  5.1900e-07,  ..., -6.3272e-09,\n",
       "             -2.5219e-07,  1.0027e-07],\n",
       "            [ 3.2982e-08, -1.2150e-07,  1.5699e-07,  ...,  1.7052e-07,\n",
       "             -2.9202e-07,  4.4151e-07],\n",
       "            [ 3.2530e-07, -2.5539e-08,  1.6426e-07,  ..., -6.8994e-08,\n",
       "              3.8390e-07,  1.1238e-08],\n",
       "            ...,\n",
       "            [-2.6096e-10, -6.1357e-07, -2.8881e-07,  ..., -9.9687e-09,\n",
       "             -2.7815e-07,  4.7134e-07],\n",
       "            [ 5.7846e-07, -1.8334e-07,  4.0165e-08,  ...,  2.4217e-07,\n",
       "             -3.3222e-07,  3.1695e-07],\n",
       "            [ 6.1149e-07,  5.8040e-07,  1.9476e-07,  ...,  8.2148e-08,\n",
       "             -2.7953e-07,  7.2609e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.0410e-12, 1.1970e-12, 1.2943e-12,  ..., 9.5174e-13, 1.1434e-12,\n",
       "             9.9201e-13],\n",
       "            [9.8469e-13, 8.2526e-13, 1.2374e-12,  ..., 1.3692e-12, 8.3413e-13,\n",
       "             1.1518e-12],\n",
       "            [9.5728e-13, 1.3106e-12, 1.2613e-12,  ..., 1.1396e-12, 1.6455e-12,\n",
       "             9.7950e-13],\n",
       "            ...,\n",
       "            [2.8367e-12, 4.2275e-12, 1.5696e-12,  ..., 2.3490e-12, 2.6970e-12,\n",
       "             2.1650e-12],\n",
       "            [2.1039e-12, 2.5146e-12, 1.1762e-12,  ..., 2.5295e-12, 3.5719e-12,\n",
       "             2.2414e-12],\n",
       "            [2.9649e-12, 3.2275e-12, 2.0636e-12,  ..., 2.8087e-12, 2.1288e-12,\n",
       "             2.6778e-12]])},\n",
       "   'model.layers.19.self_attn.v_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-4.4343e-06,  1.0223e-06,  3.2624e-07,  ...,  4.3943e-06,\n",
       "            -2.2831e-06, -3.3939e-07]),\n",
       "    'exp_avg_sq': tensor([2.1516e-10, 1.3929e-10, 1.0202e-10,  ..., 2.2224e-10, 1.7803e-10,\n",
       "            1.6731e-10])},\n",
       "   'model.layers.19.self_attn.v_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-6.7723e-07, -2.7603e-07,  5.9635e-07,  ...,  4.4469e-07,\n",
       "              5.5614e-08, -6.7250e-07],\n",
       "            [-3.3246e-08, -4.1704e-07, -1.6282e-07,  ...,  2.3497e-07,\n",
       "             -2.2430e-07,  1.9117e-07],\n",
       "            [ 2.9927e-07, -3.3642e-07, -2.1236e-07,  ..., -2.8887e-07,\n",
       "             -1.1355e-07, -7.0307e-07],\n",
       "            ...,\n",
       "            [ 2.6003e-07,  2.7697e-07,  2.6045e-07,  ..., -8.7548e-08,\n",
       "             -7.1877e-07,  4.1660e-07],\n",
       "            [-1.6674e-07, -4.8436e-07,  3.7177e-07,  ...,  1.3954e-07,\n",
       "              1.6156e-07, -2.1887e-07],\n",
       "            [ 1.2706e-08,  2.1064e-07, -3.2310e-07,  ...,  2.1143e-07,\n",
       "             -2.2638e-07, -1.4541e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.7245e-12, 2.3243e-12, 1.5429e-12,  ..., 2.3719e-12, 1.9082e-12,\n",
       "             2.1464e-12],\n",
       "            [1.3067e-12, 2.2503e-12, 1.7480e-12,  ..., 1.1252e-12, 1.4749e-12,\n",
       "             1.2321e-12],\n",
       "            [1.3053e-12, 1.8123e-12, 1.8510e-12,  ..., 2.3093e-12, 1.8092e-12,\n",
       "             2.2382e-12],\n",
       "            ...,\n",
       "            [3.0309e-12, 2.0959e-12, 3.3210e-12,  ..., 1.6678e-12, 3.5509e-12,\n",
       "             2.1414e-12],\n",
       "            [2.0684e-12, 3.0100e-12, 2.1946e-12,  ..., 1.3999e-12, 2.1222e-12,\n",
       "             2.1875e-12],\n",
       "            [1.6197e-12, 1.5144e-12, 3.0444e-12,  ..., 1.7947e-12, 2.0943e-12,\n",
       "             1.3741e-12]])},\n",
       "   'model.layers.2.input_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-3.6599e-07, -1.2359e-07,  9.2375e-06,  ..., -5.6848e-06,\n",
       "            -2.4141e-06, -1.9791e-06]),\n",
       "    'exp_avg_sq': tensor([1.9880e-10, 2.0995e-10, 2.2883e-10,  ..., 1.7130e-10, 1.7433e-10,\n",
       "            1.5778e-10])},\n",
       "   'model.layers.2.mlp.down_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-2.0234e-07, -7.3903e-07, -1.7170e-07,  ...,  1.0448e-06,\n",
       "              4.4438e-07,  4.2059e-07],\n",
       "            [-2.8441e-07,  9.3275e-07,  8.0329e-07,  ..., -1.2471e-07,\n",
       "             -8.1346e-08, -2.5786e-07],\n",
       "            [ 5.5609e-08, -5.8270e-08, -1.8627e-07,  ..., -5.5414e-07,\n",
       "             -2.1884e-07,  2.6340e-07],\n",
       "            ...,\n",
       "            [-1.0766e-07,  3.0821e-07, -2.4646e-07,  ...,  9.5593e-07,\n",
       "              2.1124e-07, -3.0007e-07],\n",
       "            [ 2.9907e-07, -4.1900e-07,  5.9551e-07,  ...,  9.5182e-07,\n",
       "             -3.7414e-07,  7.9901e-08],\n",
       "            [-2.1387e-07, -2.7105e-07,  5.1562e-07,  ..., -2.9612e-07,\n",
       "              1.6711e-07,  6.9042e-08]]),\n",
       "    'exp_avg_sq': tensor([[2.6237e-12, 3.0635e-12, 3.4943e-12,  ..., 5.8138e-12, 3.9800e-12,\n",
       "             4.8638e-12],\n",
       "            [2.4868e-12, 3.9732e-12, 4.6212e-12,  ..., 5.8508e-12, 2.4959e-12,\n",
       "             2.8367e-12],\n",
       "            [2.8243e-12, 3.6857e-12, 2.9344e-12,  ..., 6.1570e-12, 2.0804e-12,\n",
       "             2.2022e-12],\n",
       "            ...,\n",
       "            [2.3475e-12, 4.5871e-12, 4.9887e-12,  ..., 4.9482e-12, 3.9877e-12,\n",
       "             3.3194e-12],\n",
       "            [2.9872e-12, 4.1789e-12, 5.2814e-12,  ..., 6.4946e-12, 3.6543e-12,\n",
       "             4.0737e-12],\n",
       "            [3.4199e-12, 5.3916e-12, 6.1085e-12,  ..., 9.9177e-12, 2.9205e-12,\n",
       "             3.6413e-12]])},\n",
       "   'model.layers.2.mlp.gate_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-3.9441e-07, -5.6250e-08,  2.0739e-07,  ...,  2.6977e-07,\n",
       "             -2.7688e-07, -9.8442e-09],\n",
       "            [-1.2478e-07, -5.6389e-08,  6.7072e-08,  ..., -3.5969e-08,\n",
       "             -3.2511e-07,  2.5561e-07],\n",
       "            [ 5.4221e-07, -2.0434e-07,  1.1768e-07,  ...,  1.2908e-07,\n",
       "             -3.0480e-07,  1.4369e-07],\n",
       "            ...,\n",
       "            [ 4.1943e-07, -2.2678e-07,  2.3802e-07,  ..., -1.4365e-07,\n",
       "              9.5367e-08,  1.1668e-07],\n",
       "            [ 1.5695e-07, -5.0393e-07,  2.0555e-08,  ..., -3.9238e-07,\n",
       "             -6.9361e-07,  2.2135e-07],\n",
       "            [ 5.9224e-08,  1.2940e-08, -9.5197e-08,  ..., -2.1391e-07,\n",
       "             -2.4872e-07,  5.1563e-07]]),\n",
       "    'exp_avg_sq': tensor([[9.6548e-13, 5.9886e-13, 8.7043e-13,  ..., 1.0777e-12, 1.1846e-12,\n",
       "             1.1349e-12],\n",
       "            [7.9021e-13, 1.5360e-12, 6.1766e-13,  ..., 6.4029e-13, 1.1328e-12,\n",
       "             8.9104e-13],\n",
       "            [2.9305e-12, 1.2029e-12, 1.5268e-12,  ..., 1.3437e-12, 1.4313e-12,\n",
       "             1.2076e-12],\n",
       "            ...,\n",
       "            [2.4614e-12, 1.6267e-12, 1.2382e-12,  ..., 1.2519e-12, 1.6240e-12,\n",
       "             1.9510e-12],\n",
       "            [1.3795e-12, 8.8280e-13, 1.0130e-12,  ..., 1.0886e-12, 1.3026e-12,\n",
       "             1.1784e-12],\n",
       "            [1.0294e-12, 9.1417e-13, 9.4068e-13,  ..., 1.5143e-12, 9.6898e-13,\n",
       "             1.0983e-12]])},\n",
       "   'model.layers.2.mlp.up_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 2.8859e-07,  3.0995e-07, -2.2979e-07,  ...,  3.0185e-07,\n",
       "              3.6660e-07,  2.4820e-07],\n",
       "            [-2.2917e-09,  3.3756e-07,  3.3907e-07,  ...,  1.4549e-07,\n",
       "             -2.3335e-07, -2.5917e-07],\n",
       "            [-3.1723e-07,  1.1358e-07, -4.6062e-08,  ..., -2.7192e-07,\n",
       "              4.2438e-07,  3.8761e-07],\n",
       "            ...,\n",
       "            [-7.4469e-09, -5.5748e-08,  4.1341e-07,  ..., -9.3065e-10,\n",
       "              3.7823e-07, -1.2199e-07],\n",
       "            [ 6.9703e-08, -1.6710e-07,  3.3574e-07,  ..., -5.9916e-07,\n",
       "              1.1918e-07,  2.1360e-08],\n",
       "            [-3.1427e-08, -2.2229e-07,  5.6082e-08,  ..., -1.4390e-07,\n",
       "              2.0027e-07,  5.1033e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.2405e-12, 9.6306e-13, 8.0003e-13,  ..., 1.5128e-12, 1.8109e-12,\n",
       "             9.7238e-13],\n",
       "            [1.1788e-12, 1.1376e-12, 8.7176e-13,  ..., 9.4143e-13, 1.3394e-12,\n",
       "             1.0734e-12],\n",
       "            [1.7552e-12, 1.9542e-12, 1.1552e-12,  ..., 2.1028e-12, 1.3893e-12,\n",
       "             3.6891e-12],\n",
       "            ...,\n",
       "            [2.3217e-12, 8.5110e-13, 1.3097e-12,  ..., 1.3311e-12, 2.3252e-12,\n",
       "             1.4700e-12],\n",
       "            [7.5548e-13, 1.0635e-12, 1.0910e-12,  ..., 1.4650e-12, 1.3101e-12,\n",
       "             1.2652e-12],\n",
       "            [8.6787e-13, 1.6038e-12, 6.4770e-13,  ..., 1.2310e-12, 8.3931e-13,\n",
       "             1.4067e-12]])},\n",
       "   'model.layers.2.post_attention_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 1.4253e-06,  6.6730e-07,  8.8984e-06,  ...,  3.4312e-06,\n",
       "             2.7851e-06, -2.7918e-06]),\n",
       "    'exp_avg_sq': tensor([3.4996e-10, 2.0824e-10, 4.1449e-10,  ..., 2.2577e-10, 2.3817e-10,\n",
       "            2.8800e-10])},\n",
       "   'model.layers.2.self_attn.k_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-5.8409e-07,  2.1951e-07,  5.8860e-07,  ...,  2.1365e-10,\n",
       "             4.3707e-10,  2.6808e-10]),\n",
       "    'exp_avg_sq': tensor([6.1467e-12, 4.7084e-12, 4.4336e-12,  ..., 2.7323e-17, 5.8072e-18,\n",
       "            6.0344e-18])},\n",
       "   'model.layers.2.self_attn.k_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 1.2053e-08,  1.6614e-08,  6.7207e-08,  ..., -9.3923e-08,\n",
       "             -1.4503e-07,  9.4613e-08],\n",
       "            [ 8.0450e-08, -8.3574e-09,  7.3946e-08,  ..., -7.1146e-09,\n",
       "              9.6571e-09, -1.8166e-08],\n",
       "            [-9.3604e-08, -2.3861e-10, -3.3901e-08,  ..., -4.4091e-09,\n",
       "             -4.7096e-08,  1.5520e-08],\n",
       "            ...,\n",
       "            [ 2.0613e-08, -3.0883e-11,  2.5229e-08,  ...,  6.5206e-09,\n",
       "              3.4334e-08, -3.2065e-08],\n",
       "            [-4.1703e-08,  2.9079e-08, -3.1454e-08,  ..., -3.8155e-08,\n",
       "              8.2285e-09,  8.0686e-09],\n",
       "            [ 1.5405e-08,  1.6915e-08, -1.4737e-08,  ..., -3.2709e-09,\n",
       "             -4.2237e-08, -1.9786e-08]]),\n",
       "    'exp_avg_sq': tensor([[5.3563e-14, 8.1645e-14, 7.8626e-14,  ..., 7.4189e-14, 9.0784e-14,\n",
       "             6.4211e-14],\n",
       "            [7.4007e-14, 6.3070e-14, 1.0467e-13,  ..., 1.3163e-13, 7.3504e-14,\n",
       "             9.3609e-14],\n",
       "            [6.0369e-14, 4.6753e-14, 7.0926e-14,  ..., 9.0435e-14, 8.2335e-14,\n",
       "             7.1372e-14],\n",
       "            ...,\n",
       "            [2.2541e-14, 9.6346e-15, 2.5986e-14,  ..., 2.7216e-14, 3.3262e-14,\n",
       "             1.1948e-14],\n",
       "            [1.7040e-14, 4.6972e-15, 7.2038e-15,  ..., 1.3578e-14, 2.2896e-14,\n",
       "             8.4864e-15],\n",
       "            [1.1029e-14, 6.3263e-15, 1.5086e-14,  ..., 7.3853e-15, 1.6602e-14,\n",
       "             1.1172e-14]])},\n",
       "   'model.layers.2.self_attn.o_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 2.4311e-07, -2.8684e-08,  1.2620e-07,  ..., -3.7343e-08,\n",
       "             -1.9860e-07, -9.5260e-08],\n",
       "            [-7.3268e-08,  7.6421e-08,  4.4613e-07,  ...,  1.4073e-07,\n",
       "              3.3021e-08, -1.1660e-07],\n",
       "            [-3.8126e-08, -8.4574e-08, -6.1056e-07,  ...,  1.3572e-08,\n",
       "             -4.0323e-08, -5.6360e-08],\n",
       "            ...,\n",
       "            [-3.5073e-07,  4.4285e-07,  7.1614e-07,  ...,  3.5506e-08,\n",
       "             -1.6675e-07,  7.6499e-08],\n",
       "            [ 1.9625e-07, -3.7543e-07,  4.2949e-07,  ..., -7.0657e-08,\n",
       "              4.3537e-08,  2.9610e-08],\n",
       "            [-3.8323e-07, -4.7806e-07, -2.1294e-07,  ...,  5.9708e-08,\n",
       "              8.1303e-08,  2.3140e-07]]),\n",
       "    'exp_avg_sq': tensor([[2.0199e-12, 1.9326e-12, 2.2700e-12,  ..., 4.4036e-13, 5.9210e-13,\n",
       "             9.4826e-13],\n",
       "            [2.2717e-12, 2.3451e-12, 2.5438e-12,  ..., 5.8646e-13, 5.5709e-13,\n",
       "             4.9948e-13],\n",
       "            [2.3889e-12, 1.5517e-12, 2.2072e-12,  ..., 2.1533e-13, 6.0003e-13,\n",
       "             4.8981e-13],\n",
       "            ...,\n",
       "            [2.1338e-12, 2.0052e-12, 2.5171e-12,  ..., 3.5399e-13, 5.2144e-13,\n",
       "             8.1486e-13],\n",
       "            [3.1711e-12, 1.8836e-12, 3.4161e-12,  ..., 2.7288e-13, 4.7810e-13,\n",
       "             6.1525e-13],\n",
       "            [3.5496e-12, 2.6622e-12, 2.2838e-12,  ..., 2.9703e-13, 5.8281e-13,\n",
       "             6.0072e-13]])},\n",
       "   'model.layers.2.self_attn.q_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-7.8958e-07,  3.0811e-07,  1.1278e-06,  ...,  5.2393e-07,\n",
       "            -3.8083e-08, -3.5881e-07]),\n",
       "    'exp_avg_sq': tensor([5.9492e-12, 5.6057e-12, 1.2591e-11,  ..., 2.6327e-11, 1.9579e-12,\n",
       "            3.7476e-12])},\n",
       "   'model.layers.2.self_attn.q_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-7.3108e-08, -7.3140e-08,  4.2945e-08,  ..., -1.3696e-07,\n",
       "              1.0995e-07,  6.9360e-08],\n",
       "            [-2.7553e-08, -1.9664e-08, -4.3500e-08,  ...,  8.4386e-08,\n",
       "              6.4642e-08,  5.3391e-08],\n",
       "            [-1.9301e-08,  1.1962e-07,  2.6854e-08,  ..., -7.4989e-08,\n",
       "             -2.3942e-08,  8.8239e-08],\n",
       "            ...,\n",
       "            [ 5.1727e-08, -2.6245e-09, -3.3276e-09,  ..., -4.7406e-08,\n",
       "             -2.5127e-08,  6.1017e-08],\n",
       "            [-5.3215e-08, -1.1206e-08,  2.9589e-08,  ...,  3.8434e-08,\n",
       "             -1.6087e-08, -3.8061e-08],\n",
       "            [-1.6025e-08, -1.7034e-08, -3.2349e-08,  ...,  5.5535e-09,\n",
       "             -2.2979e-08,  8.2479e-09]]),\n",
       "    'exp_avg_sq': tensor([[1.2509e-13, 5.7896e-14, 1.4142e-13,  ..., 1.2552e-13, 1.5324e-13,\n",
       "             1.3599e-13],\n",
       "            [8.2804e-14, 9.4998e-14, 1.0600e-13,  ..., 9.3716e-14, 7.8974e-14,\n",
       "             8.4750e-14],\n",
       "            [1.6837e-13, 1.3224e-13, 1.6284e-13,  ..., 1.5529e-13, 1.1209e-13,\n",
       "             1.5932e-13],\n",
       "            ...,\n",
       "            [8.6381e-14, 4.8338e-14, 9.2861e-14,  ..., 7.5073e-14, 9.0898e-14,\n",
       "             6.6358e-14],\n",
       "            [1.2353e-14, 9.8507e-15, 1.3152e-14,  ..., 1.2978e-14, 1.1509e-14,\n",
       "             9.4132e-15],\n",
       "            [1.3805e-14, 2.0632e-14, 3.3045e-14,  ..., 1.5905e-14, 2.0524e-14,\n",
       "             1.4776e-14]])},\n",
       "   'model.layers.2.self_attn.v_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 3.9116e-06,  1.4291e-05,  1.1147e-06,  ..., -3.5120e-06,\n",
       "            -2.0959e-06,  3.4942e-06]),\n",
       "    'exp_avg_sq': tensor([1.3872e-09, 1.6407e-09, 1.4005e-09,  ..., 1.2731e-09, 1.1077e-09,\n",
       "            8.9255e-10])},\n",
       "   'model.layers.2.self_attn.v_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-8.5285e-08,  1.7743e-07, -2.0474e-07,  ...,  2.0555e-07,\n",
       "             -3.3728e-07, -3.5339e-08],\n",
       "            [-3.3709e-07, -3.8569e-08,  2.4547e-07,  ...,  2.3104e-07,\n",
       "             -3.5604e-07, -4.9885e-07],\n",
       "            [ 1.8067e-07, -1.9340e-07, -1.8649e-08,  ...,  4.7558e-07,\n",
       "             -2.7524e-07, -7.7376e-08],\n",
       "            ...,\n",
       "            [ 1.3797e-07,  5.9393e-08, -1.6773e-07,  ...,  7.9399e-08,\n",
       "             -3.1835e-08, -8.2341e-08],\n",
       "            [ 1.3164e-07,  4.1464e-08, -9.3340e-08,  ..., -2.0805e-07,\n",
       "              2.1653e-09, -2.6175e-08],\n",
       "            [ 5.2069e-08, -1.1494e-07, -1.6899e-08,  ..., -1.1178e-07,\n",
       "             -2.7823e-08,  1.7600e-08]]),\n",
       "    'exp_avg_sq': tensor([[1.2690e-12, 9.9178e-13, 1.2251e-12,  ..., 1.0417e-12, 1.2825e-12,\n",
       "             1.0291e-12],\n",
       "            [1.7506e-12, 1.4618e-12, 2.3600e-12,  ..., 9.3475e-13, 1.1809e-12,\n",
       "             1.4252e-12],\n",
       "            [7.4060e-13, 9.6268e-13, 1.3094e-12,  ..., 9.9106e-13, 8.8528e-13,\n",
       "             6.4024e-13],\n",
       "            ...,\n",
       "            [3.9296e-13, 1.9984e-13, 9.0804e-13,  ..., 3.5554e-13, 2.4457e-13,\n",
       "             2.1732e-13],\n",
       "            [4.6784e-13, 2.2873e-13, 4.1483e-13,  ..., 2.3958e-13, 4.0155e-13,\n",
       "             2.1574e-13],\n",
       "            [2.8266e-13, 1.8556e-13, 4.0355e-13,  ..., 2.2580e-13, 2.2735e-13,\n",
       "             1.5305e-13]])},\n",
       "   'model.layers.20.input_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-1.7713e-06, -6.9643e-06, -6.7833e-08,  ...,  2.3300e-06,\n",
       "             4.9732e-06, -4.6977e-06]),\n",
       "    'exp_avg_sq': tensor([1.9647e-10, 2.5777e-10, 1.5714e-10,  ..., 1.6996e-10, 1.7136e-10,\n",
       "            1.4432e-10])},\n",
       "   'model.layers.20.mlp.down_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-2.1322e-07, -8.2408e-07, -6.5572e-07,  ...,  5.3707e-07,\n",
       "             -5.4272e-07, -8.3963e-07],\n",
       "            [-1.1923e-06, -1.1195e-07, -6.9087e-07,  ...,  8.6888e-07,\n",
       "             -4.8510e-07,  5.4127e-07],\n",
       "            [ 3.3116e-07, -2.0506e-07, -1.0374e-06,  ..., -3.2849e-07,\n",
       "              2.0268e-07,  1.4866e-08],\n",
       "            ...,\n",
       "            [ 4.4832e-07, -1.7073e-07,  8.2229e-07,  ..., -1.2208e-06,\n",
       "              9.3007e-08,  5.1797e-07],\n",
       "            [-9.4500e-07,  8.7397e-09,  7.1579e-07,  ...,  7.5996e-08,\n",
       "              2.6757e-07,  9.4213e-07],\n",
       "            [-3.1155e-07, -6.9723e-08,  7.7919e-07,  ...,  1.0301e-06,\n",
       "             -1.0495e-07,  6.3763e-08]]),\n",
       "    'exp_avg_sq': tensor([[7.0256e-12, 1.0024e-11, 1.5055e-11,  ..., 1.1763e-11, 9.3427e-12,\n",
       "             1.2139e-11],\n",
       "            [1.0222e-11, 7.1843e-12, 1.0072e-11,  ..., 9.5381e-12, 7.1044e-12,\n",
       "             1.3245e-11],\n",
       "            [9.2573e-12, 8.0864e-12, 8.6108e-12,  ..., 9.2945e-12, 1.2624e-11,\n",
       "             1.1950e-11],\n",
       "            ...,\n",
       "            [7.2207e-12, 1.1985e-11, 1.1738e-11,  ..., 1.0358e-11, 1.1169e-11,\n",
       "             1.1876e-11],\n",
       "            [8.3837e-12, 6.1931e-12, 1.0436e-11,  ..., 8.3753e-12, 1.1111e-11,\n",
       "             1.2778e-11],\n",
       "            [8.0424e-12, 7.2301e-12, 9.0738e-12,  ..., 9.7604e-12, 1.2301e-11,\n",
       "             1.0535e-11]])},\n",
       "   'model.layers.20.mlp.gate_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 3.1239e-07,  1.1616e-06,  6.5817e-07,  ...,  7.2856e-07,\n",
       "              1.2203e-06, -1.4483e-06],\n",
       "            [-2.6686e-07, -1.1966e-07, -8.9495e-08,  ..., -6.8086e-07,\n",
       "              4.4859e-07, -1.1658e-06],\n",
       "            [ 1.3597e-07,  2.3853e-07, -1.2532e-07,  ..., -1.9593e-07,\n",
       "              1.1749e-07, -1.0999e-06],\n",
       "            ...,\n",
       "            [-5.8821e-08, -1.1211e-07, -7.8209e-07,  ...,  6.4502e-07,\n",
       "              5.0225e-08,  2.9793e-07],\n",
       "            [ 1.2998e-06,  4.5823e-08, -3.6122e-07,  ..., -1.7518e-07,\n",
       "              4.4559e-07, -6.3865e-07],\n",
       "            [-1.5608e-06,  4.6098e-07, -6.1839e-07,  ..., -6.2021e-07,\n",
       "             -2.9104e-07,  8.4361e-07]]),\n",
       "    'exp_avg_sq': tensor([[7.4903e-12, 8.4429e-12, 8.4864e-12,  ..., 8.8504e-12, 8.7590e-12,\n",
       "             7.8180e-12],\n",
       "            [1.0645e-11, 1.1888e-11, 6.7777e-12,  ..., 7.5288e-12, 9.3642e-12,\n",
       "             1.0903e-11],\n",
       "            [5.7180e-12, 6.7482e-12, 6.6043e-12,  ..., 8.1148e-12, 6.8060e-12,\n",
       "             7.2566e-12],\n",
       "            ...,\n",
       "            [1.0245e-11, 6.7760e-12, 9.0750e-12,  ..., 7.6807e-12, 6.3146e-12,\n",
       "             6.8261e-12],\n",
       "            [9.0443e-12, 8.5141e-12, 1.4073e-11,  ..., 1.0384e-11, 8.1974e-12,\n",
       "             7.8967e-12],\n",
       "            [1.1078e-11, 6.3419e-12, 1.3003e-11,  ..., 9.7394e-12, 7.5581e-12,\n",
       "             9.0682e-12]])},\n",
       "   'model.layers.20.mlp.up_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-4.4210e-07,  6.7047e-07,  8.8087e-07,  ...,  5.3888e-08,\n",
       "             -5.1514e-07, -5.9275e-07],\n",
       "            [ 5.0848e-07,  7.2575e-07,  3.2228e-07,  ...,  7.9334e-08,\n",
       "             -7.1673e-07,  1.4455e-07],\n",
       "            [-1.6682e-07, -9.0182e-07,  6.1242e-07,  ..., -4.6123e-07,\n",
       "             -3.2890e-08,  1.0110e-06],\n",
       "            ...,\n",
       "            [ 5.4624e-08,  9.2963e-08,  4.1357e-07,  ...,  1.2142e-06,\n",
       "             -5.0359e-07,  1.9439e-08],\n",
       "            [-1.6534e-07,  1.1445e-06, -1.1284e-06,  ...,  4.6615e-07,\n",
       "              4.7303e-07, -6.1350e-07],\n",
       "            [ 3.9812e-07,  2.9066e-07,  6.3881e-07,  ...,  1.5246e-07,\n",
       "              4.9426e-07, -4.3936e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.0345e-11, 5.5421e-12, 6.6806e-12,  ..., 4.7817e-12, 7.1239e-12,\n",
       "             5.2862e-12],\n",
       "            [5.9636e-12, 4.2026e-12, 4.2026e-12,  ..., 5.3478e-12, 5.7467e-12,\n",
       "             4.6917e-12],\n",
       "            [6.5916e-12, 7.1069e-12, 6.5579e-12,  ..., 6.8767e-12, 5.8436e-12,\n",
       "             4.5173e-12],\n",
       "            ...,\n",
       "            [8.1251e-12, 6.3764e-12, 5.6389e-12,  ..., 8.5590e-12, 4.7984e-12,\n",
       "             5.3510e-12],\n",
       "            [8.3083e-12, 5.8294e-12, 5.8874e-12,  ..., 3.9997e-12, 5.1256e-12,\n",
       "             5.3649e-12],\n",
       "            [4.3355e-12, 3.0299e-12, 8.1886e-12,  ..., 9.3019e-12, 6.7009e-12,\n",
       "             3.5481e-12]])},\n",
       "   'model.layers.20.post_attention_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-3.2357e-06, -3.6866e-06, -3.1032e-06,  ..., -1.4941e-06,\n",
       "             1.0586e-06,  4.0338e-07]),\n",
       "    'exp_avg_sq': tensor([3.4643e-10, 4.8303e-10, 4.5990e-10,  ..., 4.7350e-10, 4.4825e-10,\n",
       "            4.6706e-10])},\n",
       "   'model.layers.20.self_attn.k_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-1.5199e-07, -1.0020e-06,  3.2808e-07,  ..., -5.1671e-09,\n",
       "             3.6571e-09, -8.6689e-11]),\n",
       "    'exp_avg_sq': tensor([1.6793e-12, 4.7500e-12, 1.9232e-12,  ..., 1.4716e-16, 8.8828e-17,\n",
       "            1.3609e-16])},\n",
       "   'model.layers.20.self_attn.k_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 1.9325e-07, -3.1057e-07,  2.5703e-08,  ...,  7.3065e-08,\n",
       "              4.7385e-08,  1.2653e-07],\n",
       "            [ 2.1007e-07,  1.1551e-07,  2.8110e-07,  ...,  2.6161e-07,\n",
       "              6.3400e-08,  2.0759e-07],\n",
       "            [-8.5822e-08, -1.6605e-07,  1.2378e-07,  ...,  9.4240e-09,\n",
       "              6.6185e-08, -5.3849e-08],\n",
       "            ...,\n",
       "            [-1.7255e-07,  1.7513e-09, -6.5804e-08,  ..., -3.2404e-08,\n",
       "             -1.4217e-07, -2.7792e-07],\n",
       "            [ 2.2306e-07,  1.5295e-07, -1.5647e-07,  ...,  3.3921e-07,\n",
       "              3.0877e-08,  8.9865e-08],\n",
       "            [-2.3215e-07, -4.1246e-08,  2.7086e-07,  ..., -8.5305e-07,\n",
       "              3.6286e-08, -1.7503e-08]]),\n",
       "    'exp_avg_sq': tensor([[2.6445e-13, 8.0603e-13, 3.2495e-13,  ..., 4.5020e-13, 5.1214e-13,\n",
       "             2.4090e-13],\n",
       "            [4.7251e-13, 6.8852e-13, 3.9359e-13,  ..., 5.9491e-13, 4.2169e-13,\n",
       "             2.9627e-13],\n",
       "            [4.9989e-13, 5.1666e-13, 4.8312e-13,  ..., 3.7451e-13, 4.8797e-13,\n",
       "             4.1069e-13],\n",
       "            ...,\n",
       "            [1.0798e-12, 1.6269e-12, 1.8088e-12,  ..., 1.0734e-12, 1.3866e-12,\n",
       "             1.6299e-12],\n",
       "            [1.3348e-12, 7.0461e-13, 1.4333e-12,  ..., 5.9013e-13, 2.1162e-12,\n",
       "             7.8040e-13],\n",
       "            [1.3801e-12, 8.7592e-13, 1.1578e-12,  ..., 2.6000e-12, 3.5474e-12,\n",
       "             1.4650e-12]])},\n",
       "   'model.layers.20.self_attn.o_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 3.9364e-07, -1.9273e-07,  1.5557e-07,  ...,  6.5025e-07,\n",
       "              2.5593e-07,  1.2189e-07],\n",
       "            [ 7.7080e-07, -1.5616e-07,  4.7584e-07,  ...,  6.4921e-07,\n",
       "              6.0000e-07,  2.0789e-06],\n",
       "            [ 2.2405e-07,  4.8895e-07,  7.7417e-07,  ...,  4.0994e-07,\n",
       "             -2.1286e-07, -5.1358e-07],\n",
       "            ...,\n",
       "            [-6.1609e-07,  8.2003e-07,  7.8301e-07,  ..., -3.7801e-07,\n",
       "             -4.5286e-07, -1.0545e-06],\n",
       "            [ 3.1827e-08,  2.2385e-07,  5.8306e-07,  ...,  1.4698e-06,\n",
       "              4.5755e-08, -2.4303e-08],\n",
       "            [-6.5138e-07, -2.2617e-07, -7.5341e-08,  ...,  3.9414e-07,\n",
       "             -6.8953e-07, -6.2235e-07]]),\n",
       "    'exp_avg_sq': tensor([[5.0705e-12, 3.8518e-12, 3.3668e-12,  ..., 4.4694e-12, 4.9456e-12,\n",
       "             3.7080e-12],\n",
       "            [7.3644e-12, 4.2506e-12, 3.4103e-12,  ..., 3.3945e-12, 9.8946e-12,\n",
       "             6.4336e-12],\n",
       "            [5.5887e-12, 3.4337e-12, 5.3667e-12,  ..., 4.6090e-12, 4.5711e-12,\n",
       "             3.6518e-12],\n",
       "            ...,\n",
       "            [5.5188e-12, 6.0191e-12, 5.4936e-12,  ..., 3.8889e-12, 3.7444e-12,\n",
       "             5.2133e-12],\n",
       "            [4.0456e-12, 4.5239e-12, 4.6775e-12,  ..., 7.1113e-12, 4.9601e-12,\n",
       "             4.7894e-12],\n",
       "            [4.3728e-12, 3.2326e-12, 3.3136e-12,  ..., 5.1770e-12, 5.3383e-12,\n",
       "             4.3624e-12]])},\n",
       "   'model.layers.20.self_attn.q_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-5.0308e-07,  3.7848e-08,  2.5814e-08,  ..., -7.6572e-07,\n",
       "             3.5321e-07,  3.1140e-08]),\n",
       "    'exp_avg_sq': tensor([3.8514e-12, 2.3426e-12, 2.3760e-12,  ..., 1.2835e-11, 1.7190e-11,\n",
       "            1.5112e-11])},\n",
       "   'model.layers.20.self_attn.q_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-9.1405e-08,  2.4736e-08,  1.9145e-07,  ..., -1.8327e-08,\n",
       "              3.0600e-07,  1.3621e-07],\n",
       "            [ 1.4796e-07, -1.9353e-07,  1.6075e-07,  ...,  2.0256e-07,\n",
       "             -2.4916e-07, -1.9209e-07],\n",
       "            [-3.3660e-07, -4.7332e-07, -1.6867e-07,  ...,  1.8734e-07,\n",
       "             -1.4360e-07,  1.3740e-07],\n",
       "            ...,\n",
       "            [ 1.3121e-07, -3.6208e-07,  4.0554e-07,  ..., -2.2400e-07,\n",
       "              3.9565e-07, -1.6233e-07],\n",
       "            [ 2.8366e-08, -5.1526e-07,  5.8732e-08,  ...,  2.9354e-07,\n",
       "              4.2966e-07,  2.8831e-07],\n",
       "            [ 6.9719e-08,  5.1036e-08, -5.3770e-08,  ..., -3.0642e-07,\n",
       "              5.9841e-09, -3.0121e-07]]),\n",
       "    'exp_avg_sq': tensor([[6.5456e-13, 3.9545e-13, 6.0573e-13,  ..., 3.7394e-13, 6.2142e-13,\n",
       "             4.4293e-13],\n",
       "            [5.9140e-13, 5.8370e-13, 3.2723e-13,  ..., 3.5817e-13, 5.9240e-13,\n",
       "             6.4989e-13],\n",
       "            [6.7546e-13, 7.1194e-13, 5.6958e-13,  ..., 4.9173e-13, 7.6484e-13,\n",
       "             4.2115e-13],\n",
       "            ...,\n",
       "            [1.7168e-12, 1.7998e-12, 1.7209e-12,  ..., 2.2514e-12, 2.5164e-12,\n",
       "             1.6190e-12],\n",
       "            [1.3642e-12, 2.5231e-12, 1.5326e-12,  ..., 1.5084e-12, 2.6942e-12,\n",
       "             1.4550e-12],\n",
       "            [1.6183e-12, 1.2883e-12, 1.8101e-12,  ..., 1.8620e-12, 1.1357e-12,\n",
       "             1.6898e-12]])},\n",
       "   'model.layers.20.self_attn.v_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 4.3380e-07,  1.8839e-06,  8.2179e-07,  ..., -7.0006e-07,\n",
       "             3.4652e-06,  2.4958e-06]),\n",
       "    'exp_avg_sq': tensor([2.3836e-10, 1.3851e-10, 1.1831e-10,  ..., 9.6136e-11, 1.2171e-10,\n",
       "            9.2974e-11])},\n",
       "   'model.layers.20.self_attn.v_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 2.0700e-07,  1.0511e-07,  7.4157e-08,  ..., -4.1777e-07,\n",
       "             -4.8117e-07, -7.1363e-08],\n",
       "            [ 6.0432e-08,  4.1416e-08, -3.9086e-08,  ...,  1.1540e-07,\n",
       "             -2.8193e-07, -8.5197e-08],\n",
       "            [-1.8771e-08, -1.3119e-07,  2.7706e-07,  ..., -3.4446e-07,\n",
       "             -3.0646e-08, -2.9636e-07],\n",
       "            ...,\n",
       "            [ 1.2658e-07,  7.4340e-07, -9.7777e-08,  ...,  2.1077e-08,\n",
       "             -4.1058e-07,  2.5815e-09],\n",
       "            [ 2.1628e-08, -5.4625e-08,  9.8323e-08,  ..., -5.9277e-08,\n",
       "              1.0106e-07,  5.5023e-07],\n",
       "            [ 1.4540e-07,  5.3394e-08,  1.3433e-07,  ...,  1.3911e-07,\n",
       "              9.9628e-08, -2.1104e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.1975e-12, 2.3377e-12, 2.7006e-12,  ..., 1.7771e-12, 3.1481e-12,\n",
       "             1.8721e-12],\n",
       "            [1.4925e-12, 2.7415e-12, 2.1116e-12,  ..., 1.2867e-12, 1.9855e-12,\n",
       "             2.1071e-12],\n",
       "            [2.0500e-12, 1.7995e-12, 1.8520e-12,  ..., 1.9188e-12, 1.7266e-12,\n",
       "             1.7269e-12],\n",
       "            ...,\n",
       "            [2.0862e-12, 1.3346e-12, 2.9132e-12,  ..., 2.4197e-12, 2.3924e-12,\n",
       "             2.3843e-12],\n",
       "            [1.7378e-12, 2.2002e-12, 2.5460e-12,  ..., 1.4627e-12, 1.5139e-12,\n",
       "             2.8379e-12],\n",
       "            [1.5005e-12, 2.1054e-12, 1.3514e-12,  ..., 2.2070e-12, 1.7399e-12,\n",
       "             2.5179e-12]])},\n",
       "   'model.layers.21.input_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 5.1860e-07,  6.5107e-07, -6.5370e-07,  ..., -2.8731e-06,\n",
       "             8.8743e-07,  2.7363e-06]),\n",
       "    'exp_avg_sq': tensor([1.8394e-10, 1.4489e-10, 2.3867e-10,  ..., 1.6682e-10, 1.5494e-10,\n",
       "            2.3229e-10])},\n",
       "   'model.layers.21.mlp.down_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-2.1099e-07,  5.7917e-07, -9.2855e-07,  ...,  6.2608e-07,\n",
       "              7.6851e-08, -1.1375e-06],\n",
       "            [-7.5487e-07,  8.2035e-07,  4.0282e-07,  ...,  4.7409e-07,\n",
       "              2.8718e-07,  1.6756e-06],\n",
       "            [ 1.8282e-07,  8.9586e-07, -1.2349e-06,  ..., -7.3895e-08,\n",
       "             -1.2935e-06, -2.7424e-07],\n",
       "            ...,\n",
       "            [-1.5719e-07, -1.0079e-07, -5.6987e-07,  ...,  9.4408e-08,\n",
       "              3.2793e-07, -4.8020e-07],\n",
       "            [ 5.8803e-07,  8.4439e-07, -1.6173e-06,  ...,  3.2542e-07,\n",
       "             -3.2354e-07,  1.0114e-06],\n",
       "            [-1.5272e-06,  4.3970e-07,  3.7617e-07,  ..., -6.6489e-07,\n",
       "             -1.2325e-07,  1.2309e-06]]),\n",
       "    'exp_avg_sq': tensor([[1.0408e-11, 5.4350e-12, 1.1864e-11,  ..., 8.6534e-12, 6.4578e-12,\n",
       "             9.6652e-12],\n",
       "            [2.1326e-11, 8.6512e-12, 1.3877e-11,  ..., 6.7246e-12, 7.3986e-12,\n",
       "             1.0723e-11],\n",
       "            [1.4585e-11, 8.2728e-12, 9.5510e-12,  ..., 8.4221e-12, 8.6088e-12,\n",
       "             9.5570e-12],\n",
       "            ...,\n",
       "            [1.2447e-11, 1.1208e-11, 1.0257e-11,  ..., 1.0054e-11, 1.0947e-11,\n",
       "             8.3193e-12],\n",
       "            [1.2536e-11, 9.7561e-12, 1.4801e-11,  ..., 1.4176e-11, 9.7835e-12,\n",
       "             1.2724e-11],\n",
       "            [2.0203e-11, 1.0262e-11, 1.2105e-11,  ..., 1.1829e-11, 7.2728e-12,\n",
       "             8.2010e-12]])},\n",
       "   'model.layers.21.mlp.gate_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 4.3698e-07,  3.5522e-07, -1.2617e-06,  ...,  6.6636e-07,\n",
       "             -1.8060e-07, -1.2216e-07],\n",
       "            [-8.2246e-07,  4.7869e-07, -3.9230e-07,  ...,  1.0626e-06,\n",
       "             -1.3097e-07,  4.1149e-07],\n",
       "            [ 4.4197e-07, -3.4202e-07,  1.9949e-08,  ..., -2.2340e-07,\n",
       "              2.7148e-07,  7.1300e-07],\n",
       "            ...,\n",
       "            [-2.4347e-07,  9.2675e-08, -2.1515e-07,  ..., -1.4382e-08,\n",
       "              3.1601e-07,  1.7495e-08],\n",
       "            [-3.3088e-07,  3.3773e-07, -1.4527e-06,  ...,  2.5253e-07,\n",
       "             -1.7357e-07, -3.6700e-07],\n",
       "            [ 7.0804e-08,  4.8852e-07,  5.6156e-08,  ...,  1.5398e-06,\n",
       "              1.6333e-07,  3.8719e-07]]),\n",
       "    'exp_avg_sq': tensor([[8.2040e-12, 1.2691e-11, 1.1562e-11,  ..., 7.7896e-12, 8.2802e-12,\n",
       "             9.2935e-12],\n",
       "            [5.0180e-12, 8.6980e-12, 1.0536e-11,  ..., 1.2576e-11, 6.2136e-12,\n",
       "             1.5695e-11],\n",
       "            [9.0278e-12, 5.9714e-12, 6.1964e-12,  ..., 7.8037e-12, 9.8574e-12,\n",
       "             7.4845e-12],\n",
       "            ...,\n",
       "            [9.5785e-12, 7.1512e-12, 1.0198e-11,  ..., 8.6678e-12, 6.9776e-12,\n",
       "             1.1710e-11],\n",
       "            [6.7278e-12, 5.9895e-12, 8.0786e-12,  ..., 7.9250e-12, 7.3317e-12,\n",
       "             8.0765e-12],\n",
       "            [1.3385e-11, 8.1872e-12, 1.0429e-11,  ..., 8.9109e-12, 9.2557e-12,\n",
       "             9.1669e-12]])},\n",
       "   'model.layers.21.mlp.up_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-3.2816e-07, -2.2927e-07,  5.7661e-07,  ..., -1.9123e-07,\n",
       "             -1.1193e-06, -4.3948e-07],\n",
       "            [-7.8719e-07,  8.2716e-07,  5.8839e-07,  ..., -1.4684e-07,\n",
       "             -3.7560e-08, -4.1033e-07],\n",
       "            [-2.6156e-07, -2.2406e-07,  1.2650e-06,  ..., -8.2987e-07,\n",
       "              7.6439e-07,  5.0893e-08],\n",
       "            ...,\n",
       "            [-5.8126e-07, -6.2595e-07,  4.9406e-07,  ...,  4.9418e-07,\n",
       "             -3.3228e-07, -2.3393e-07],\n",
       "            [-1.0197e-07,  4.4945e-07,  3.1166e-07,  ...,  4.6595e-07,\n",
       "              5.8120e-07,  3.7156e-07],\n",
       "            [-1.2272e-07,  4.7404e-07, -3.7432e-07,  ...,  3.3305e-07,\n",
       "             -4.4836e-07, -4.1200e-07]]),\n",
       "    'exp_avg_sq': tensor([[7.1673e-12, 7.0670e-12, 1.0171e-11,  ..., 5.9076e-12, 8.8863e-12,\n",
       "             9.1026e-12],\n",
       "            [7.6369e-12, 5.1453e-12, 5.6894e-12,  ..., 5.9926e-12, 5.0253e-12,\n",
       "             6.0419e-12],\n",
       "            [8.8981e-12, 7.2963e-12, 1.0122e-11,  ..., 6.6624e-12, 6.0785e-12,\n",
       "             6.4831e-12],\n",
       "            ...,\n",
       "            [5.0416e-12, 6.3883e-12, 7.3312e-12,  ..., 9.4301e-12, 5.5656e-12,\n",
       "             5.8490e-12],\n",
       "            [6.6751e-12, 1.0478e-11, 5.5823e-12,  ..., 6.6265e-12, 5.3017e-12,\n",
       "             6.8489e-12],\n",
       "            [8.2015e-12, 6.4615e-12, 9.0751e-12,  ..., 6.5639e-12, 4.3525e-12,\n",
       "             7.1454e-12]])},\n",
       "   'model.layers.21.post_attention_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-9.3505e-06,  2.5186e-06,  8.1185e-06,  ..., -6.1519e-07,\n",
       "             6.6742e-07, -6.9293e-06]),\n",
       "    'exp_avg_sq': tensor([3.4372e-10, 2.9916e-10, 5.1205e-10,  ..., 4.5969e-10, 4.2615e-10,\n",
       "            3.5057e-10])},\n",
       "   'model.layers.21.self_attn.k_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 6.2637e-07, -7.2918e-07, -2.0757e-07,  ..., -3.0404e-09,\n",
       "             8.5043e-10, -4.0698e-09]),\n",
       "    'exp_avg_sq': tensor([3.4592e-12, 4.5435e-12, 2.5031e-12,  ..., 9.9527e-17, 1.1521e-16,\n",
       "            1.6438e-16])},\n",
       "   'model.layers.21.self_attn.k_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 2.0130e-07,  2.2667e-07, -2.5671e-07,  ...,  3.0517e-08,\n",
       "             -2.7918e-07,  2.3968e-07],\n",
       "            [-3.6211e-07, -3.4050e-07, -4.9489e-08,  ...,  4.3336e-08,\n",
       "              7.0715e-08,  3.7987e-08],\n",
       "            [-1.5355e-07, -1.0554e-07,  3.2964e-08,  ..., -2.3623e-07,\n",
       "             -9.7621e-08,  1.1823e-07],\n",
       "            ...,\n",
       "            [-2.3621e-08,  7.1849e-08, -6.1551e-08,  ..., -3.7502e-07,\n",
       "              4.1678e-07, -4.1432e-08],\n",
       "            [ 2.7486e-07,  2.1905e-07, -3.0242e-07,  ..., -4.8280e-07,\n",
       "              6.8107e-07,  2.7811e-07],\n",
       "            [ 1.7424e-07, -1.7732e-07, -4.4737e-07,  ...,  3.9247e-07,\n",
       "             -6.1767e-07, -2.3074e-07]]),\n",
       "    'exp_avg_sq': tensor([[3.8787e-13, 6.0628e-13, 4.9209e-13,  ..., 4.7177e-13, 4.7994e-13,\n",
       "             4.8153e-13],\n",
       "            [4.3947e-13, 9.3367e-13, 6.2116e-13,  ..., 5.1439e-13, 7.0802e-13,\n",
       "             5.6639e-13],\n",
       "            [4.8949e-13, 6.6625e-13, 5.1940e-13,  ..., 4.0718e-13, 6.1197e-13,\n",
       "             4.5282e-13],\n",
       "            ...,\n",
       "            [9.4054e-13, 1.6745e-12, 2.1219e-12,  ..., 2.0459e-12, 1.6528e-12,\n",
       "             2.0206e-12],\n",
       "            [3.8684e-12, 2.5190e-12, 2.6255e-12,  ..., 2.2728e-12, 1.9520e-12,\n",
       "             1.7787e-12],\n",
       "            [1.9826e-12, 2.3131e-12, 2.0692e-12,  ..., 1.6039e-12, 2.7324e-12,\n",
       "             1.2132e-12]])},\n",
       "   'model.layers.21.self_attn.o_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 1.3802e-07,  4.2648e-07, -3.1456e-07,  ...,  4.8194e-07,\n",
       "             -5.3259e-08, -5.3905e-07],\n",
       "            [-5.9127e-08, -2.2781e-07, -2.6330e-07,  ..., -3.4867e-07,\n",
       "              6.2992e-07,  4.1534e-07],\n",
       "            [ 1.2056e-06,  2.4536e-07, -3.0146e-07,  ..., -5.3891e-07,\n",
       "             -9.4507e-07, -2.0834e-07],\n",
       "            ...,\n",
       "            [ 8.7543e-07,  5.1956e-07,  2.3168e-07,  ...,  4.9396e-07,\n",
       "              6.1235e-07,  3.2057e-08],\n",
       "            [-5.2728e-07, -6.9692e-07, -1.6210e-07,  ...,  1.6774e-07,\n",
       "             -1.2931e-07, -4.4477e-08],\n",
       "            [ 7.6375e-07,  4.2641e-07, -4.0058e-07,  ..., -1.0838e-06,\n",
       "              3.4907e-08,  6.6678e-07]]),\n",
       "    'exp_avg_sq': tensor([[2.6053e-12, 3.1709e-12, 3.3614e-12,  ..., 3.3466e-12, 3.0315e-12,\n",
       "             3.4888e-12],\n",
       "            [2.9012e-12, 5.3651e-12, 3.3982e-12,  ..., 3.7529e-12, 4.3932e-12,\n",
       "             3.0808e-12],\n",
       "            [4.2879e-12, 2.8881e-12, 2.6366e-12,  ..., 4.0679e-12, 3.6595e-12,\n",
       "             3.1048e-12],\n",
       "            ...,\n",
       "            [5.2410e-12, 5.6129e-12, 4.4159e-12,  ..., 2.3617e-12, 3.1044e-12,\n",
       "             3.5414e-12],\n",
       "            [2.8363e-12, 4.6576e-12, 4.5959e-12,  ..., 2.5906e-12, 3.1800e-12,\n",
       "             3.2588e-12],\n",
       "            [2.4184e-12, 3.3628e-12, 4.0557e-12,  ..., 3.5144e-12, 2.8393e-12,\n",
       "             3.2396e-12]])},\n",
       "   'model.layers.21.self_attn.q_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-1.0833e-06, -7.9256e-07,  2.3691e-07,  ..., -4.4198e-07,\n",
       "            -1.3159e-07, -1.0578e-06]),\n",
       "    'exp_avg_sq': tensor([6.9525e-12, 7.7330e-12, 5.5643e-12,  ..., 1.9284e-11, 3.2325e-11,\n",
       "            2.5827e-11])},\n",
       "   'model.layers.21.self_attn.q_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 1.2901e-07, -3.1608e-08, -4.1565e-07,  ...,  5.8036e-08,\n",
       "              3.3954e-09, -3.2026e-07],\n",
       "            [ 7.9976e-08,  3.6239e-07,  3.4787e-07,  ..., -2.5524e-07,\n",
       "              4.1100e-07,  3.1197e-08],\n",
       "            [-7.0460e-09,  1.8397e-07,  1.5556e-08,  ...,  9.5114e-08,\n",
       "              1.1401e-07,  1.9536e-07],\n",
       "            ...,\n",
       "            [-2.9694e-08,  2.9601e-07,  8.3781e-07,  ...,  2.6814e-07,\n",
       "              7.0172e-07, -8.2996e-07],\n",
       "            [-2.4057e-07, -4.6338e-07, -3.9656e-07,  ...,  1.0754e-06,\n",
       "              4.5386e-07, -3.5170e-07],\n",
       "            [ 2.8724e-07, -2.3844e-07,  2.4745e-07,  ...,  1.7912e-07,\n",
       "              7.2542e-07, -8.4575e-07]]),\n",
       "    'exp_avg_sq': tensor([[5.2891e-13, 9.4700e-13, 9.3316e-13,  ..., 4.7913e-13, 9.0462e-13,\n",
       "             7.6170e-13],\n",
       "            [6.0329e-13, 9.8486e-13, 1.0108e-12,  ..., 6.4241e-13, 1.5748e-12,\n",
       "             8.6725e-13],\n",
       "            [3.6918e-13, 7.4072e-13, 8.1379e-13,  ..., 4.1364e-13, 5.5472e-13,\n",
       "             6.1206e-13],\n",
       "            ...,\n",
       "            [2.0339e-12, 2.8728e-12, 3.1739e-12,  ..., 2.5936e-12, 3.7255e-12,\n",
       "             2.7850e-12],\n",
       "            [3.0618e-12, 5.9369e-12, 4.4465e-12,  ..., 4.2101e-12, 5.1566e-12,\n",
       "             3.8053e-12],\n",
       "            [2.6663e-12, 2.2207e-12, 1.8999e-12,  ..., 1.6878e-12, 2.0347e-12,\n",
       "             2.3691e-12]])},\n",
       "   'model.layers.21.self_attn.v_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-4.1651e-06,  6.5585e-07, -2.4987e-07,  ...,  5.4883e-07,\n",
       "             3.1186e-06, -5.9480e-07]),\n",
       "    'exp_avg_sq': tensor([9.4443e-11, 7.7747e-11, 6.7685e-11,  ..., 6.8658e-11, 1.0058e-10,\n",
       "            9.2198e-11])},\n",
       "   'model.layers.21.self_attn.v_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-1.3350e-07, -3.1681e-07,  3.8342e-07,  ..., -2.0881e-07,\n",
       "              2.1423e-07,  1.5980e-07],\n",
       "            [ 2.7027e-07,  3.5391e-07, -2.1448e-08,  ..., -1.7885e-07,\n",
       "             -3.0464e-07, -2.2533e-07],\n",
       "            [ 1.8044e-07, -1.0492e-07,  5.2148e-07,  ..., -1.8988e-08,\n",
       "              7.2053e-08,  2.3961e-07],\n",
       "            ...,\n",
       "            [ 9.8068e-08,  1.1185e-07, -5.4175e-07,  ..., -1.0908e-07,\n",
       "             -4.0926e-08, -1.0388e-07],\n",
       "            [ 1.1972e-07, -3.2463e-07, -1.9134e-07,  ...,  3.8411e-07,\n",
       "             -5.1521e-07, -3.0761e-08],\n",
       "            [ 3.5344e-07, -1.4406e-07,  2.9467e-07,  ...,  1.8327e-07,\n",
       "              1.1685e-07, -1.3690e-07]]),\n",
       "    'exp_avg_sq': tensor([[8.3538e-13, 1.7722e-12, 2.0978e-12,  ..., 1.9211e-12, 1.7609e-12,\n",
       "             1.5182e-12],\n",
       "            [1.3693e-12, 2.7076e-12, 1.6388e-12,  ..., 1.2989e-12, 1.9777e-12,\n",
       "             1.4383e-12],\n",
       "            [1.6700e-12, 1.4567e-12, 2.4769e-12,  ..., 1.4596e-12, 1.7847e-12,\n",
       "             1.6206e-12],\n",
       "            ...,\n",
       "            [8.9466e-13, 2.4964e-12, 3.0096e-12,  ..., 1.3719e-12, 1.3712e-12,\n",
       "             1.1884e-12],\n",
       "            [1.7398e-12, 1.4908e-12, 2.6723e-12,  ..., 1.8082e-12, 1.8336e-12,\n",
       "             1.1632e-12],\n",
       "            [1.1198e-12, 1.8212e-12, 2.0052e-12,  ..., 6.6787e-13, 1.8367e-12,\n",
       "             1.1248e-12]])},\n",
       "   'model.layers.22.input_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-5.2664e-07, -1.7103e-06, -6.1314e-07,  ...,  3.6651e-06,\n",
       "             2.8917e-06, -4.3317e-06]),\n",
       "    'exp_avg_sq': tensor([1.5804e-10, 1.3611e-10, 2.0977e-10,  ..., 1.2164e-10, 1.2447e-10,\n",
       "            1.5410e-10])},\n",
       "   'model.layers.22.mlp.down_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 3.0271e-07, -2.5942e-07,  2.0794e-07,  ..., -2.0713e-07,\n",
       "             -6.7783e-07,  1.5447e-06],\n",
       "            [ 1.1497e-06,  1.6440e-07,  6.2466e-07,  ...,  8.0044e-07,\n",
       "              7.3536e-07, -1.1684e-06],\n",
       "            [ 4.7709e-08,  1.1858e-06,  3.0522e-08,  ..., -1.3633e-06,\n",
       "              4.1459e-07,  1.2614e-06],\n",
       "            ...,\n",
       "            [ 4.8253e-08, -1.5324e-08, -3.7289e-07,  ..., -2.8178e-07,\n",
       "             -8.6886e-07,  5.9969e-07],\n",
       "            [ 3.5086e-08,  3.7517e-07,  1.0531e-06,  ..., -9.1429e-07,\n",
       "             -1.6846e-07, -5.0562e-07],\n",
       "            [ 3.3653e-07, -1.5626e-06, -3.9103e-07,  ..., -5.5997e-07,\n",
       "             -1.3506e-06, -5.8761e-07]]),\n",
       "    'exp_avg_sq': tensor([[9.0031e-12, 7.0339e-12, 1.0882e-11,  ..., 9.2215e-12, 1.1412e-11,\n",
       "             9.5149e-12],\n",
       "            [1.2355e-11, 1.2250e-11, 9.0323e-12,  ..., 1.4665e-11, 1.3637e-11,\n",
       "             1.4818e-11],\n",
       "            [2.3006e-11, 8.1179e-12, 1.5333e-11,  ..., 1.0386e-11, 1.0425e-11,\n",
       "             1.1879e-11],\n",
       "            ...,\n",
       "            [1.6629e-11, 5.8571e-12, 1.1706e-11,  ..., 1.8847e-11, 1.2243e-11,\n",
       "             1.6863e-11],\n",
       "            [9.4608e-12, 7.9522e-12, 8.9621e-12,  ..., 8.1333e-12, 1.0739e-11,\n",
       "             1.5071e-11],\n",
       "            [1.6313e-11, 1.1505e-11, 9.2507e-12,  ..., 1.6884e-11, 1.9158e-11,\n",
       "             1.1881e-11]])},\n",
       "   'model.layers.22.mlp.gate_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-6.0760e-08, -1.5614e-06, -3.9803e-08,  ..., -7.6736e-07,\n",
       "              1.0388e-06,  8.6554e-07],\n",
       "            [-6.3321e-07, -1.2504e-06, -7.6237e-08,  ..., -3.0859e-07,\n",
       "             -1.9092e-07,  5.5428e-07],\n",
       "            [-4.5693e-07,  7.3938e-07, -1.4495e-06,  ...,  1.7437e-07,\n",
       "              1.8213e-06,  5.3944e-07],\n",
       "            ...,\n",
       "            [-3.8508e-07, -9.8025e-07,  1.3281e-06,  ..., -4.4294e-07,\n",
       "             -9.4195e-07, -1.9161e-06],\n",
       "            [ 9.8859e-08,  1.4034e-07,  1.5814e-07,  ..., -1.1779e-06,\n",
       "             -5.7160e-07,  6.1724e-07],\n",
       "            [ 1.1978e-07, -8.3306e-07,  3.3124e-07,  ..., -3.4351e-07,\n",
       "             -9.5134e-07, -6.0484e-08]]),\n",
       "    'exp_avg_sq': tensor([[9.7971e-12, 1.0780e-11, 1.4546e-11,  ..., 1.1399e-11, 1.3513e-11,\n",
       "             8.6139e-12],\n",
       "            [8.7011e-12, 8.0913e-12, 1.2047e-11,  ..., 6.4832e-12, 1.1008e-11,\n",
       "             1.0812e-11],\n",
       "            [1.2615e-11, 7.7456e-12, 1.3440e-11,  ..., 7.1439e-12, 1.0975e-11,\n",
       "             6.2649e-12],\n",
       "            ...,\n",
       "            [9.1858e-12, 1.6194e-11, 1.1067e-11,  ..., 9.5082e-12, 1.4613e-11,\n",
       "             1.4719e-11],\n",
       "            [5.6067e-12, 1.1290e-11, 7.8529e-12,  ..., 8.6835e-12, 1.4003e-11,\n",
       "             8.0372e-12],\n",
       "            [1.3638e-11, 1.3798e-11, 1.0316e-11,  ..., 7.4565e-12, 7.6553e-12,\n",
       "             1.0934e-11]])},\n",
       "   'model.layers.22.mlp.up_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 1.6297e-07,  5.5792e-07, -1.0979e-06,  ..., -2.7353e-07,\n",
       "             -3.0076e-07, -7.8414e-07],\n",
       "            [-5.0816e-07,  1.2691e-06, -7.3615e-07,  ..., -7.3687e-07,\n",
       "              4.7373e-07,  9.0529e-07],\n",
       "            [ 5.2775e-08,  7.4831e-07,  7.2072e-08,  ...,  1.4007e-06,\n",
       "             -3.9564e-08, -7.2641e-08],\n",
       "            ...,\n",
       "            [ 1.9438e-06, -6.4074e-07, -1.6704e-07,  ...,  2.5733e-07,\n",
       "              3.2782e-07,  8.3249e-07],\n",
       "            [-5.1902e-07,  3.2191e-07,  5.0927e-07,  ...,  3.5731e-07,\n",
       "             -2.8358e-07,  6.1826e-07],\n",
       "            [-1.1774e-06, -1.0401e-06,  1.3180e-06,  ...,  6.6737e-07,\n",
       "             -3.8166e-07, -2.2341e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.2547e-11, 9.3209e-12, 1.3349e-11,  ..., 1.9730e-11, 9.4650e-12,\n",
       "             9.7976e-12],\n",
       "            [6.2391e-12, 8.7390e-12, 1.0840e-11,  ..., 6.1313e-12, 4.8605e-12,\n",
       "             1.1602e-11],\n",
       "            [6.9780e-12, 7.1671e-12, 6.4576e-12,  ..., 1.3560e-11, 1.1784e-11,\n",
       "             7.0840e-12],\n",
       "            ...,\n",
       "            [1.8705e-11, 1.3972e-11, 1.9925e-11,  ..., 9.2543e-12, 1.1258e-11,\n",
       "             9.5700e-12],\n",
       "            [6.3606e-12, 9.1222e-12, 7.7202e-12,  ..., 8.2017e-12, 7.5848e-12,\n",
       "             8.3755e-12],\n",
       "            [1.4780e-11, 9.8180e-12, 1.2647e-11,  ..., 8.7716e-12, 1.0159e-11,\n",
       "             9.6955e-12]])},\n",
       "   'model.layers.22.post_attention_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-2.1694e-07,  5.9702e-07, -7.0730e-06,  ..., -1.7918e-06,\n",
       "            -9.1334e-06,  1.0882e-05]),\n",
       "    'exp_avg_sq': tensor([4.2108e-10, 3.2927e-10, 4.2865e-10,  ..., 5.1288e-10, 5.0794e-10,\n",
       "            4.9428e-10])},\n",
       "   'model.layers.22.self_attn.k_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 1.7468e-06, -1.4716e-06, -1.0202e-06,  ..., -2.2530e-09,\n",
       "            -9.7621e-10,  4.8538e-09]),\n",
       "    'exp_avg_sq': tensor([3.6705e-11, 2.7194e-11, 9.2495e-12,  ..., 1.3380e-16, 1.3944e-16,\n",
       "            1.3146e-16])},\n",
       "   'model.layers.22.self_attn.k_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-2.1307e-08,  8.6457e-07,  4.5584e-07,  ..., -2.3752e-07,\n",
       "             -5.8324e-07,  3.1349e-07],\n",
       "            [ 1.5170e-07, -5.9361e-07, -3.9821e-07,  ..., -4.3737e-08,\n",
       "              3.3796e-07, -3.7890e-07],\n",
       "            [-1.1654e-07, -5.0393e-07, -3.9653e-07,  ...,  4.3739e-07,\n",
       "             -6.5502e-08, -4.4762e-07],\n",
       "            ...,\n",
       "            [-1.8553e-07, -1.4496e-07, -1.2738e-07,  ..., -1.6192e-07,\n",
       "             -2.4893e-08, -1.7806e-07],\n",
       "            [ 7.0025e-08,  6.3941e-08,  6.3650e-08,  ..., -1.9700e-07,\n",
       "             -1.6437e-07, -2.1527e-08],\n",
       "            [-7.4430e-08, -8.1690e-09,  7.3773e-08,  ..., -9.8945e-08,\n",
       "             -1.3997e-07,  2.6047e-07]]),\n",
       "    'exp_avg_sq': tensor([[3.6183e-12, 5.5144e-12, 5.3702e-12,  ..., 2.7706e-12, 3.8106e-12,\n",
       "             3.6014e-12],\n",
       "            [1.2278e-12, 1.7347e-12, 2.7482e-12,  ..., 1.6035e-12, 1.6601e-12,\n",
       "             1.1529e-12],\n",
       "            [1.2835e-12, 1.5327e-12, 1.1589e-12,  ..., 1.4742e-12, 9.0305e-13,\n",
       "             1.0518e-12],\n",
       "            ...,\n",
       "            [1.0055e-12, 1.0528e-12, 1.2353e-12,  ..., 1.0088e-12, 1.2808e-12,\n",
       "             9.1795e-13],\n",
       "            [1.6561e-12, 1.6246e-12, 2.2039e-12,  ..., 1.4744e-12, 1.2759e-12,\n",
       "             2.5398e-12],\n",
       "            [1.2330e-12, 2.0039e-12, 2.4899e-12,  ..., 1.5269e-12, 1.5725e-12,\n",
       "             1.7504e-12]])},\n",
       "   'model.layers.22.self_attn.o_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-2.4051e-07, -2.9837e-07,  2.9543e-07,  ...,  1.2826e-07,\n",
       "             -1.6941e-08,  2.5274e-09],\n",
       "            [-2.1969e-07, -2.7174e-08,  3.2870e-07,  ...,  1.0195e-06,\n",
       "              2.9440e-07,  1.1871e-06],\n",
       "            [-1.7506e-08, -1.3344e-07, -8.4327e-07,  ..., -6.2918e-07,\n",
       "             -5.9092e-07,  1.5952e-07],\n",
       "            ...,\n",
       "            [-3.6694e-07, -4.2552e-07, -2.8168e-07,  ...,  5.4899e-07,\n",
       "              7.5216e-07,  5.2580e-07],\n",
       "            [ 9.5872e-07, -1.1746e-07, -6.9413e-07,  ...,  1.0636e-07,\n",
       "             -4.3640e-07, -2.7181e-09],\n",
       "            [-5.2152e-07,  1.4707e-08, -3.2311e-07,  ..., -4.5930e-07,\n",
       "             -1.6352e-07,  6.8905e-07]]),\n",
       "    'exp_avg_sq': tensor([[3.1524e-12, 3.1855e-12, 2.4271e-12,  ..., 7.3946e-12, 3.7244e-12,\n",
       "             3.7226e-12],\n",
       "            [4.2245e-12, 2.3688e-12, 2.8573e-12,  ..., 6.5332e-12, 3.9493e-12,\n",
       "             3.4085e-12],\n",
       "            [2.7120e-12, 2.1039e-12, 2.9482e-12,  ..., 4.8714e-12, 4.3343e-12,\n",
       "             3.3315e-12],\n",
       "            ...,\n",
       "            [3.4854e-12, 2.3351e-12, 4.5589e-12,  ..., 9.7304e-12, 4.9903e-12,\n",
       "             5.3200e-12],\n",
       "            [4.1159e-12, 3.0685e-12, 2.6540e-12,  ..., 1.5606e-11, 4.5699e-12,\n",
       "             4.2435e-12],\n",
       "            [3.3145e-12, 4.4249e-12, 2.7727e-12,  ..., 5.1728e-12, 2.9053e-12,\n",
       "             3.2164e-12]])},\n",
       "   'model.layers.22.self_attn.q_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 1.7020e-06,  1.2228e-06, -5.8752e-07,  ..., -1.0491e-06,\n",
       "             1.7153e-08,  5.1294e-07]),\n",
       "    'exp_avg_sq': tensor([4.5083e-11, 2.1345e-11, 1.4938e-11,  ..., 4.1050e-11, 3.2494e-11,\n",
       "            3.7088e-11])},\n",
       "   'model.layers.22.self_attn.q_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-6.0766e-07,  1.2415e-06, -2.0524e-07,  ..., -9.3248e-07,\n",
       "              1.7408e-07, -1.0993e-07],\n",
       "            [-4.2143e-07,  3.2837e-07, -8.0071e-08,  ...,  3.2868e-07,\n",
       "              9.0143e-08,  5.1112e-07],\n",
       "            [-1.6210e-07,  9.1831e-07, -2.4576e-07,  ...,  4.4655e-08,\n",
       "              2.7610e-07,  3.6669e-07],\n",
       "            ...,\n",
       "            [-1.0048e-08, -2.2133e-07, -5.6557e-07,  ...,  1.9711e-08,\n",
       "             -1.1588e-07, -1.9367e-07],\n",
       "            [-4.5606e-08,  3.9890e-07,  2.3876e-07,  ...,  5.4763e-07,\n",
       "             -7.7375e-08, -1.7301e-07],\n",
       "            [ 3.0269e-07,  6.9984e-08, -1.7958e-07,  ..., -2.3642e-07,\n",
       "             -1.7444e-07, -9.0775e-10]]),\n",
       "    'exp_avg_sq': tensor([[3.1338e-12, 5.2331e-12, 6.2280e-12,  ..., 6.1521e-12, 4.3938e-12,\n",
       "             5.5770e-12],\n",
       "            [1.7423e-12, 4.4867e-12, 3.5261e-12,  ..., 1.6767e-12, 4.6477e-12,\n",
       "             2.1492e-12],\n",
       "            [1.0007e-12, 3.0968e-12, 2.1835e-12,  ..., 1.6063e-12, 1.7005e-12,\n",
       "             2.6892e-12],\n",
       "            ...,\n",
       "            [2.9066e-12, 3.2668e-12, 5.7300e-12,  ..., 2.7815e-12, 2.8387e-12,\n",
       "             2.3830e-12],\n",
       "            [2.1995e-12, 3.4607e-12, 2.9068e-12,  ..., 2.6770e-12, 2.7063e-12,\n",
       "             2.3566e-12],\n",
       "            [1.3575e-12, 3.8627e-12, 3.0855e-12,  ..., 1.6089e-12, 2.6046e-12,\n",
       "             1.4284e-12]])},\n",
       "   'model.layers.22.self_attn.v_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 1.4714e-06, -3.1864e-06,  3.4228e-06,  ...,  6.0093e-07,\n",
       "             3.1376e-07,  3.0904e-06]),\n",
       "    'exp_avg_sq': tensor([8.1360e-11, 7.1313e-11, 9.5235e-11,  ..., 9.3381e-11, 1.1528e-10,\n",
       "            1.4901e-10])},\n",
       "   'model.layers.22.self_attn.v_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 8.3555e-07,  1.5574e-07,  2.2464e-07,  ...,  2.0777e-07,\n",
       "             -4.7244e-07,  7.5939e-08],\n",
       "            [ 2.9325e-07, -5.4716e-07, -2.6262e-07,  ...,  4.0222e-07,\n",
       "             -3.1323e-07, -4.9206e-07],\n",
       "            [-4.3565e-07,  4.0988e-07,  1.2648e-07,  ..., -2.6729e-07,\n",
       "             -3.2567e-07,  2.4142e-07],\n",
       "            ...,\n",
       "            [ 2.4811e-07,  5.2745e-07,  3.9279e-07,  ..., -5.6673e-08,\n",
       "              1.0544e-07, -2.6239e-08],\n",
       "            [ 4.0366e-07, -3.8281e-07, -2.6902e-08,  ...,  2.9804e-07,\n",
       "              7.7087e-08,  3.3845e-07],\n",
       "            [-5.8643e-07,  4.2455e-07, -1.8425e-07,  ...,  2.2613e-07,\n",
       "             -3.4820e-07,  2.3427e-08]]),\n",
       "    'exp_avg_sq': tensor([[2.9958e-12, 4.5906e-12, 3.9568e-12,  ..., 3.6070e-12, 2.3632e-12,\n",
       "             2.6986e-12],\n",
       "            [2.2063e-12, 2.5988e-12, 2.7709e-12,  ..., 4.4754e-12, 2.1922e-12,\n",
       "             3.7349e-12],\n",
       "            [4.1788e-12, 5.2132e-12, 3.6864e-12,  ..., 3.9841e-12, 4.8098e-12,\n",
       "             5.0089e-12],\n",
       "            ...,\n",
       "            [1.6609e-12, 2.4440e-12, 1.7545e-12,  ..., 2.1108e-12, 1.7455e-12,\n",
       "             1.4313e-12],\n",
       "            [1.7531e-12, 3.0343e-12, 1.8985e-12,  ..., 2.0681e-12, 1.7286e-12,\n",
       "             1.6552e-12],\n",
       "            [1.7702e-12, 2.0340e-12, 1.6818e-12,  ..., 1.9185e-12, 2.1847e-12,\n",
       "             1.2795e-12]])},\n",
       "   'model.layers.23.input_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-6.7428e-07,  4.2318e-06,  2.0588e-07,  ..., -6.4942e-07,\n",
       "            -7.7092e-09, -4.9138e-06]),\n",
       "    'exp_avg_sq': tensor([1.1837e-10, 2.0073e-10, 1.5203e-10,  ..., 1.7036e-10, 1.1773e-10,\n",
       "            2.2919e-10])},\n",
       "   'model.layers.23.mlp.down_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 4.8267e-08, -1.2535e-07, -1.8674e-07,  ..., -6.2723e-07,\n",
       "              2.6155e-07, -7.9258e-08],\n",
       "            [ 4.8214e-07, -1.9129e-07,  9.0775e-07,  ...,  2.6664e-07,\n",
       "              4.6164e-09,  4.1839e-07],\n",
       "            [ 1.2473e-06, -1.4317e-07, -2.6483e-07,  ...,  6.4004e-07,\n",
       "              2.1764e-07, -1.1943e-07],\n",
       "            ...,\n",
       "            [ 1.0201e-06, -2.2749e-07,  3.2122e-07,  ..., -5.2290e-07,\n",
       "             -2.3010e-07, -1.2404e-06],\n",
       "            [-3.8246e-07,  1.0453e-06,  3.0850e-07,  ..., -1.3456e-06,\n",
       "              9.4893e-07, -1.3376e-06],\n",
       "            [ 1.2598e-06,  1.9390e-07, -6.2992e-07,  ...,  1.0447e-07,\n",
       "             -1.2872e-06, -1.8570e-08]]),\n",
       "    'exp_avg_sq': tensor([[9.2354e-12, 9.7041e-12, 8.5316e-12,  ..., 1.8611e-11, 1.0999e-11,\n",
       "             1.0594e-11],\n",
       "            [1.2401e-11, 1.1006e-11, 1.3724e-11,  ..., 1.1630e-11, 7.4806e-12,\n",
       "             9.3477e-12],\n",
       "            [8.8325e-12, 7.6462e-12, 8.4567e-12,  ..., 9.2211e-12, 1.0777e-11,\n",
       "             7.9694e-12],\n",
       "            ...,\n",
       "            [1.5968e-11, 1.1601e-11, 1.1221e-11,  ..., 1.3830e-11, 1.3507e-11,\n",
       "             1.1350e-11],\n",
       "            [1.0658e-11, 1.3920e-11, 9.8781e-12,  ..., 1.5460e-11, 1.2451e-11,\n",
       "             1.1245e-11],\n",
       "            [1.1823e-11, 7.7282e-12, 8.3746e-12,  ..., 1.6225e-11, 1.0254e-11,\n",
       "             9.5356e-12]])},\n",
       "   'model.layers.23.mlp.gate_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 4.0765e-07, -5.5905e-07,  1.8958e-07,  ...,  7.3868e-07,\n",
       "             -1.5202e-06,  9.9331e-08],\n",
       "            [-2.2673e-08, -7.8869e-08, -5.2579e-07,  ..., -6.4842e-07,\n",
       "             -2.8950e-07, -1.5762e-07],\n",
       "            [-4.3069e-07, -1.0557e-06, -1.6606e-06,  ...,  5.3715e-07,\n",
       "              1.2685e-06,  1.2516e-06],\n",
       "            ...,\n",
       "            [ 4.1905e-08, -1.1504e-08, -5.9422e-07,  ...,  5.4596e-07,\n",
       "              2.9361e-08,  6.9038e-07],\n",
       "            [-1.0919e-06, -1.4902e-06, -4.0704e-08,  ...,  2.5773e-08,\n",
       "             -6.5149e-08, -3.0862e-07],\n",
       "            [ 3.6314e-07,  2.6262e-08, -7.4335e-07,  ...,  4.5068e-08,\n",
       "              7.2168e-07,  4.1929e-07]]),\n",
       "    'exp_avg_sq': tensor([[8.1041e-12, 6.7119e-12, 9.1390e-12,  ..., 7.3978e-12, 9.8653e-12,\n",
       "             7.8047e-12],\n",
       "            [9.9261e-12, 1.2185e-11, 1.2026e-11,  ..., 9.0609e-12, 1.0851e-11,\n",
       "             9.3715e-12],\n",
       "            [1.4628e-11, 1.5881e-11, 1.9203e-11,  ..., 1.3202e-11, 2.1945e-11,\n",
       "             1.2891e-11],\n",
       "            ...,\n",
       "            [4.8280e-12, 8.6506e-12, 1.1617e-11,  ..., 7.7252e-12, 5.1574e-12,\n",
       "             9.2685e-12],\n",
       "            [7.3580e-12, 5.0737e-12, 7.5560e-12,  ..., 5.4529e-12, 8.3061e-12,\n",
       "             7.2285e-12],\n",
       "            [6.5159e-12, 5.2628e-12, 7.5150e-12,  ..., 9.0193e-12, 8.2968e-12,\n",
       "             9.7959e-12]])},\n",
       "   'model.layers.23.mlp.up_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-8.8192e-08, -5.1185e-07, -1.5378e-07,  ...,  1.7185e-07,\n",
       "              2.7195e-07, -1.5954e-07],\n",
       "            [-2.9889e-07, -6.5217e-07,  5.9688e-07,  ...,  3.9313e-07,\n",
       "              9.4443e-07, -6.8352e-07],\n",
       "            [-5.5722e-07, -1.6922e-07,  6.4445e-07,  ..., -2.9082e-07,\n",
       "             -4.8980e-07, -3.7894e-07],\n",
       "            ...,\n",
       "            [-4.6063e-07,  1.3507e-07, -5.9156e-07,  ..., -6.3586e-07,\n",
       "             -1.0017e-06, -1.4380e-07],\n",
       "            [-8.9779e-07,  7.9646e-07, -2.2995e-07,  ..., -3.0357e-07,\n",
       "              3.2408e-08, -3.2414e-07],\n",
       "            [-2.1832e-07, -5.6968e-07, -2.2922e-07,  ..., -8.7033e-07,\n",
       "             -2.7313e-07, -4.8977e-07]]),\n",
       "    'exp_avg_sq': tensor([[4.4395e-12, 6.3844e-12, 7.5618e-12,  ..., 5.9505e-12, 9.9536e-12,\n",
       "             4.6112e-12],\n",
       "            [3.4056e-12, 8.5929e-12, 8.9782e-12,  ..., 6.3196e-12, 9.9091e-12,\n",
       "             5.9040e-12],\n",
       "            [7.0757e-12, 1.0389e-11, 8.8843e-12,  ..., 5.8279e-12, 1.2109e-11,\n",
       "             1.0203e-11],\n",
       "            ...,\n",
       "            [5.1969e-12, 6.9622e-12, 9.8626e-12,  ..., 6.6672e-12, 6.7263e-12,\n",
       "             5.3880e-12],\n",
       "            [6.3851e-12, 6.1871e-12, 7.5458e-12,  ..., 5.0015e-12, 5.1446e-12,\n",
       "             5.1969e-12],\n",
       "            [3.9707e-12, 7.3315e-12, 4.9091e-12,  ..., 8.3157e-12, 5.1728e-12,\n",
       "             7.7034e-12]])},\n",
       "   'model.layers.23.post_attention_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 7.4947e-06, -6.9545e-07,  7.6661e-06,  ..., -1.8181e-07,\n",
       "            -1.1125e-07, -2.9366e-06]),\n",
       "    'exp_avg_sq': tensor([6.9533e-10, 1.1341e-09, 4.2169e-10,  ..., 5.7697e-10, 7.6346e-10,\n",
       "            6.2963e-10])},\n",
       "   'model.layers.23.self_attn.k_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-5.9073e-07, -5.0064e-07,  7.3183e-07,  ..., -1.1176e-09,\n",
       "            -4.4200e-10,  1.1529e-09]),\n",
       "    'exp_avg_sq': tensor([3.0726e-12, 2.4136e-12, 3.4507e-12,  ..., 4.9869e-17, 5.4684e-17,\n",
       "            9.2581e-17])},\n",
       "   'model.layers.23.self_attn.k_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 4.4021e-08, -6.7141e-08, -2.2764e-07,  ...,  1.9818e-08,\n",
       "              1.6848e-07,  1.4105e-07],\n",
       "            [ 5.7214e-08, -2.0197e-07,  1.5433e-08,  ...,  7.1491e-08,\n",
       "              1.5645e-07, -9.5702e-08],\n",
       "            [ 9.1068e-10, -9.0160e-08, -2.0665e-07,  ..., -2.0538e-07,\n",
       "             -6.2011e-08,  1.6118e-07],\n",
       "            ...,\n",
       "            [ 2.2955e-07, -1.1271e-07, -8.7884e-10,  ..., -9.2528e-08,\n",
       "             -2.4845e-07, -1.3113e-07],\n",
       "            [-1.8080e-07, -5.2699e-07, -2.1237e-07,  ..., -4.1207e-07,\n",
       "             -9.7141e-08,  1.2525e-07],\n",
       "            [ 7.3233e-08, -1.8016e-07,  1.7512e-07,  ...,  2.1561e-07,\n",
       "              3.3366e-08, -3.0050e-07]]),\n",
       "    'exp_avg_sq': tensor([[3.8414e-13, 5.0575e-13, 5.2730e-13,  ..., 5.7094e-13, 3.8662e-13,\n",
       "             4.4343e-13],\n",
       "            [3.8092e-13, 4.8966e-13, 4.0785e-13,  ..., 5.4703e-13, 5.4011e-13,\n",
       "             3.7114e-13],\n",
       "            [2.3250e-13, 4.4704e-13, 6.6090e-13,  ..., 4.9992e-13, 4.4160e-13,\n",
       "             5.9870e-13],\n",
       "            ...,\n",
       "            [4.9687e-13, 1.0334e-12, 1.0196e-12,  ..., 8.8189e-13, 1.0470e-12,\n",
       "             6.7016e-13],\n",
       "            [7.4124e-13, 1.3343e-12, 1.3104e-12,  ..., 1.2708e-12, 1.1551e-12,\n",
       "             1.0246e-12],\n",
       "            [9.9184e-13, 1.2044e-12, 1.4595e-12,  ..., 1.2934e-12, 1.3682e-12,\n",
       "             1.5593e-12]])},\n",
       "   'model.layers.23.self_attn.o_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-6.3814e-08,  7.0231e-08, -2.2561e-07,  ...,  1.5317e-08,\n",
       "              1.9864e-08, -2.2913e-07],\n",
       "            [ 5.0108e-08, -6.4536e-07,  3.7071e-07,  ..., -3.6385e-08,\n",
       "             -2.7547e-07, -1.7273e-07],\n",
       "            [-1.9782e-07, -1.1649e-07, -3.3546e-07,  ...,  2.7290e-07,\n",
       "             -2.0547e-07,  2.4071e-07],\n",
       "            ...,\n",
       "            [-4.9937e-07, -1.3138e-06,  2.1727e-08,  ...,  1.6243e-07,\n",
       "              3.4424e-07, -3.5643e-07],\n",
       "            [ 4.2909e-08, -6.4725e-07,  2.8903e-07,  ...,  3.1329e-07,\n",
       "              1.5084e-07,  1.8939e-07],\n",
       "            [-2.9581e-07, -9.9072e-08,  1.9570e-07,  ...,  8.7723e-08,\n",
       "              9.6097e-08, -3.0855e-07]]),\n",
       "    'exp_avg_sq': tensor([[2.8499e-12, 4.5460e-12, 2.6062e-12,  ..., 2.3187e-12, 2.1361e-12,\n",
       "             2.0257e-12],\n",
       "            [3.3012e-12, 5.6302e-12, 3.5740e-12,  ..., 2.8340e-12, 2.6564e-12,\n",
       "             3.2424e-12],\n",
       "            [3.3959e-12, 4.3600e-12, 3.9233e-12,  ..., 2.3623e-12, 2.1844e-12,\n",
       "             2.4195e-12],\n",
       "            ...,\n",
       "            [4.2604e-12, 7.1823e-12, 4.6447e-12,  ..., 1.4501e-12, 1.8238e-12,\n",
       "             2.8707e-12],\n",
       "            [4.2670e-12, 3.1287e-12, 2.6620e-12,  ..., 2.6822e-12, 1.8947e-12,\n",
       "             2.6933e-12],\n",
       "            [4.3419e-12, 3.2905e-12, 3.5407e-12,  ..., 3.5267e-12, 2.5480e-12,\n",
       "             1.9156e-12]])},\n",
       "   'model.layers.23.self_attn.q_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-3.3552e-07, -8.2047e-07, -2.0357e-07,  ..., -8.8173e-08,\n",
       "             2.1257e-06,  1.3816e-07]),\n",
       "    'exp_avg_sq': tensor([5.1553e-12, 5.4077e-12, 4.7657e-12,  ..., 1.3908e-11, 1.5168e-11,\n",
       "            1.4376e-11])},\n",
       "   'model.layers.23.self_attn.q_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-9.6026e-08, -1.5530e-07, -1.6827e-07,  ..., -4.7364e-07,\n",
       "             -3.2566e-07, -6.6461e-08],\n",
       "            [-1.9161e-07, -9.4567e-08, -2.9256e-07,  ..., -2.0816e-07,\n",
       "             -2.5202e-07, -3.1051e-07],\n",
       "            [-1.4792e-08,  8.6566e-08, -1.0877e-07,  ..., -5.9358e-08,\n",
       "              2.2620e-08,  6.5255e-08],\n",
       "            ...,\n",
       "            [ 1.2103e-07, -3.4875e-09, -2.1658e-09,  ...,  1.6925e-07,\n",
       "             -1.5638e-08,  1.0190e-07],\n",
       "            [-1.5720e-07, -1.5531e-07, -2.5255e-07,  ..., -4.5057e-07,\n",
       "              1.7983e-07,  2.6647e-07],\n",
       "            [-7.0960e-09,  2.8906e-07, -4.2670e-07,  ..., -2.6114e-07,\n",
       "             -9.1620e-08,  3.8565e-07]]),\n",
       "    'exp_avg_sq': tensor([[6.2905e-13, 8.9797e-13, 1.1401e-12,  ..., 1.3829e-12, 6.3359e-13,\n",
       "             7.9099e-13],\n",
       "            [5.6543e-13, 4.3173e-13, 8.0556e-13,  ..., 6.8728e-13, 6.1631e-13,\n",
       "             6.3225e-13],\n",
       "            [2.9193e-13, 4.6049e-13, 9.5176e-13,  ..., 6.4561e-13, 4.0349e-13,\n",
       "             3.2911e-13],\n",
       "            ...,\n",
       "            [7.7068e-13, 1.4681e-12, 1.1294e-12,  ..., 1.4084e-12, 9.4086e-13,\n",
       "             7.2612e-13],\n",
       "            [9.2404e-13, 1.7231e-12, 1.4680e-12,  ..., 1.6868e-12, 1.8943e-12,\n",
       "             1.2785e-12],\n",
       "            [1.0264e-12, 1.5467e-12, 1.2568e-12,  ..., 1.5318e-12, 1.4068e-12,\n",
       "             1.3667e-12]])},\n",
       "   'model.layers.23.self_attn.v_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 2.4600e-07,  3.0013e-06, -2.5792e-06,  ...,  2.6541e-06,\n",
       "             3.2338e-07, -3.1282e-06]),\n",
       "    'exp_avg_sq': tensor([7.0745e-11, 1.4472e-10, 7.2394e-11,  ..., 1.1527e-10, 4.5244e-11,\n",
       "            9.5683e-11])},\n",
       "   'model.layers.23.self_attn.v_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-2.0586e-07, -5.9436e-07,  1.8396e-07,  ..., -1.1927e-07,\n",
       "             -1.0953e-07,  8.5124e-07],\n",
       "            [-3.4464e-07,  6.7657e-08,  1.5932e-07,  ...,  4.6576e-07,\n",
       "             -1.1872e-07,  5.8629e-07],\n",
       "            [-3.7349e-07, -4.5259e-07, -5.0157e-07,  ..., -2.4422e-07,\n",
       "             -2.9980e-07, -7.7353e-08],\n",
       "            ...,\n",
       "            [-1.9416e-07,  1.5807e-07,  2.3854e-07,  ..., -1.0915e-07,\n",
       "              4.8566e-08,  1.2272e-07],\n",
       "            [-3.5436e-08,  2.9870e-07,  2.4163e-07,  ..., -5.2820e-07,\n",
       "              1.6018e-07, -1.5941e-07],\n",
       "            [-2.5634e-07,  1.1595e-07,  1.1602e-07,  ..., -1.4533e-07,\n",
       "              7.7678e-07, -2.9839e-07]]),\n",
       "    'exp_avg_sq': tensor([[2.2253e-12, 3.3382e-12, 1.8767e-12,  ..., 2.7857e-12, 2.5864e-12,\n",
       "             3.2458e-12],\n",
       "            [3.4918e-12, 2.2309e-12, 3.4048e-12,  ..., 4.4835e-12, 2.9742e-12,\n",
       "             2.9011e-12],\n",
       "            [2.1894e-12, 2.8214e-12, 2.6331e-12,  ..., 2.3637e-12, 1.7469e-12,\n",
       "             1.7249e-12],\n",
       "            ...,\n",
       "            [1.4510e-12, 1.3845e-12, 1.4034e-12,  ..., 1.9695e-12, 1.8526e-12,\n",
       "             1.7808e-12],\n",
       "            [9.3845e-13, 1.5853e-12, 2.1113e-12,  ..., 1.3788e-12, 1.5253e-12,\n",
       "             1.0272e-12],\n",
       "            [1.1845e-12, 1.8370e-12, 1.3672e-12,  ..., 1.4507e-12, 2.3176e-12,\n",
       "             1.4436e-12]])},\n",
       "   'model.layers.3.input_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-5.6222e-06,  1.0004e-06,  1.0892e-06,  ..., -2.1061e-06,\n",
       "            -2.0804e-06,  3.1909e-06]),\n",
       "    'exp_avg_sq': tensor([1.9754e-10, 4.0314e-10, 2.4338e-10,  ..., 2.3076e-10, 4.5101e-10,\n",
       "            4.3573e-10])},\n",
       "   'model.layers.3.mlp.down_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 1.4899e-06,  1.0305e-08,  3.5802e-07,  ...,  1.8152e-08,\n",
       "              4.5827e-08, -3.0870e-07],\n",
       "            [ 1.5108e-07, -8.2198e-07,  2.0896e-07,  ..., -9.7127e-08,\n",
       "             -3.8100e-07, -8.1869e-07],\n",
       "            [-1.3745e-07,  5.0958e-07, -2.4619e-07,  ...,  4.5797e-07,\n",
       "             -4.3802e-07, -2.8307e-07],\n",
       "            ...,\n",
       "            [-2.4988e-07,  2.5835e-08,  3.4726e-08,  ..., -6.5344e-07,\n",
       "              2.8290e-07,  3.0468e-07],\n",
       "            [ 2.7964e-07, -6.2475e-07,  3.2101e-07,  ...,  3.3686e-07,\n",
       "             -2.9078e-07,  3.1806e-07],\n",
       "            [-4.3484e-07,  2.8131e-07,  1.4019e-07,  ..., -2.1859e-08,\n",
       "             -9.7191e-08, -7.6062e-07]]),\n",
       "    'exp_avg_sq': tensor([[4.5938e-12, 3.2400e-12, 2.9716e-12,  ..., 5.5430e-12, 4.4487e-12,\n",
       "             3.2215e-12],\n",
       "            [3.8060e-12, 4.8646e-12, 2.9147e-12,  ..., 6.3300e-12, 4.8000e-12,\n",
       "             3.2485e-12],\n",
       "            [4.4297e-12, 5.5604e-12, 2.8234e-12,  ..., 5.7869e-12, 5.7967e-12,\n",
       "             3.8663e-12],\n",
       "            ...,\n",
       "            [3.6315e-12, 2.9383e-12, 3.6618e-12,  ..., 5.0300e-12, 4.7992e-12,\n",
       "             3.2482e-12],\n",
       "            [4.1942e-12, 3.0940e-12, 4.7404e-12,  ..., 6.1407e-12, 5.7137e-12,\n",
       "             3.9786e-12],\n",
       "            [4.2069e-12, 4.9289e-12, 3.9318e-12,  ..., 5.3632e-12, 4.8193e-12,\n",
       "             4.7353e-12]])},\n",
       "   'model.layers.3.mlp.gate_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-1.0392e-07, -2.3082e-07,  9.3085e-08,  ..., -1.8899e-07,\n",
       "              2.7971e-07, -2.0917e-07],\n",
       "            [ 8.3666e-08,  2.7117e-07, -3.6760e-08,  ...,  8.7180e-07,\n",
       "             -5.0085e-09, -2.8174e-07],\n",
       "            [-1.3124e-07,  8.2950e-08,  3.1570e-07,  ..., -3.0461e-07,\n",
       "              2.0549e-07, -1.9266e-07],\n",
       "            ...,\n",
       "            [-1.8650e-07, -3.3338e-08, -2.7423e-08,  ...,  2.4715e-07,\n",
       "              2.1864e-07, -5.0666e-07],\n",
       "            [-8.0387e-07, -7.8945e-08,  1.1709e-07,  ..., -3.8894e-07,\n",
       "              1.5880e-07,  3.0032e-07],\n",
       "            [-1.3982e-07, -8.7581e-09,  3.3843e-08,  ...,  9.0394e-08,\n",
       "             -2.6906e-07,  5.4094e-08]]),\n",
       "    'exp_avg_sq': tensor([[1.3789e-12, 1.1097e-12, 1.8896e-12,  ..., 1.5024e-12, 3.2758e-12,\n",
       "             1.2210e-12],\n",
       "            [1.0482e-12, 2.1882e-12, 1.5782e-12,  ..., 2.1115e-12, 1.9979e-12,\n",
       "             1.1848e-12],\n",
       "            [1.7900e-12, 1.1189e-12, 1.3294e-12,  ..., 1.7924e-12, 1.3057e-12,\n",
       "             8.2388e-13],\n",
       "            ...,\n",
       "            [1.0756e-12, 1.2721e-12, 1.4068e-12,  ..., 1.4028e-12, 1.5856e-12,\n",
       "             1.2179e-12],\n",
       "            [1.7299e-12, 1.8806e-12, 1.2871e-12,  ..., 1.3304e-12, 1.2237e-12,\n",
       "             1.0668e-12],\n",
       "            [1.2324e-12, 1.5512e-12, 1.2576e-12,  ..., 1.4297e-12, 1.4299e-12,\n",
       "             1.1046e-12]])},\n",
       "   'model.layers.3.mlp.up_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 2.2325e-07, -2.1422e-07, -4.4633e-07,  ...,  2.8342e-07,\n",
       "              6.6551e-07, -3.0458e-07],\n",
       "            [-3.9837e-07,  1.9851e-07, -2.5408e-08,  ...,  4.7077e-07,\n",
       "              1.2531e-07,  1.9051e-08],\n",
       "            [-1.1828e-07, -6.1351e-08, -4.1704e-07,  ..., -3.3321e-07,\n",
       "              2.5131e-07, -1.3429e-07],\n",
       "            ...,\n",
       "            [ 2.0257e-07,  1.0487e-07, -9.2949e-08,  ..., -3.2801e-07,\n",
       "              3.4411e-08, -3.4660e-07],\n",
       "            [-2.6774e-07, -4.5011e-07, -1.8431e-07,  ..., -2.8705e-07,\n",
       "              8.4341e-07,  1.5774e-07],\n",
       "            [-1.7804e-07, -3.0749e-07,  8.2407e-08,  ...,  1.4095e-07,\n",
       "              8.8706e-08,  1.9568e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.2877e-12, 1.5392e-12, 1.2170e-12,  ..., 1.2045e-12, 1.9136e-12,\n",
       "             1.5934e-12],\n",
       "            [1.8257e-12, 1.4708e-12, 2.0799e-12,  ..., 1.3468e-12, 2.2051e-12,\n",
       "             1.2319e-12],\n",
       "            [1.1025e-12, 1.1472e-12, 1.7130e-12,  ..., 1.5833e-12, 1.9044e-12,\n",
       "             2.0603e-12],\n",
       "            ...,\n",
       "            [2.0424e-12, 1.6627e-12, 1.3777e-12,  ..., 1.9527e-12, 1.7893e-12,\n",
       "             1.8436e-12],\n",
       "            [1.8739e-12, 1.6786e-12, 1.7139e-12,  ..., 1.6383e-12, 1.6420e-12,\n",
       "             1.4609e-12],\n",
       "            [2.0245e-12, 1.2145e-12, 1.6322e-12,  ..., 1.6698e-12, 1.5896e-12,\n",
       "             1.3403e-12]])},\n",
       "   'model.layers.3.post_attention_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-2.9759e-06,  6.5848e-06,  5.1945e-06,  ...,  5.7105e-07,\n",
       "             4.5106e-07,  2.6903e-07]),\n",
       "    'exp_avg_sq': tensor([3.5140e-10, 3.8645e-10, 5.5708e-10,  ..., 3.7820e-10, 6.0549e-10,\n",
       "            4.1515e-10])},\n",
       "   'model.layers.3.self_attn.k_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-2.6838e-06, -1.4571e-06, -4.3581e-08,  ..., -4.0086e-10,\n",
       "             1.9317e-09,  1.5826e-09]),\n",
       "    'exp_avg_sq': tensor([1.4451e-10, 6.7651e-11, 5.9297e-11,  ..., 8.7004e-17, 3.7498e-17,\n",
       "            4.8846e-17])},\n",
       "   'model.layers.3.self_attn.k_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 1.9883e-07, -7.1101e-07,  2.8059e-07,  ...,  1.3611e-07,\n",
       "             -7.3307e-07,  2.1977e-07],\n",
       "            [ 7.2720e-08, -8.9275e-08, -9.9349e-08,  ...,  1.4315e-07,\n",
       "             -7.3915e-07, -1.0196e-07],\n",
       "            [-1.2412e-07,  1.8400e-07,  1.5106e-07,  ...,  5.4765e-08,\n",
       "              3.3739e-07,  3.2774e-07],\n",
       "            ...,\n",
       "            [ 7.8424e-08, -9.2184e-09, -9.1750e-08,  ...,  7.3879e-09,\n",
       "             -1.0562e-07,  9.5634e-09],\n",
       "            [-1.0835e-07, -1.3847e-08, -2.0547e-07,  ..., -8.0164e-08,\n",
       "             -1.6943e-07, -5.0523e-08],\n",
       "            [ 3.5635e-08, -3.5172e-08, -3.8369e-08,  ...,  1.7959e-08,\n",
       "             -3.3581e-08, -6.5171e-08]]),\n",
       "    'exp_avg_sq': tensor([[9.3764e-13, 6.9619e-12, 9.8991e-13,  ..., 6.8776e-13, 8.0591e-12,\n",
       "             7.5197e-13],\n",
       "            [7.3350e-13, 2.5447e-12, 5.0255e-13,  ..., 7.0481e-13, 1.1734e-11,\n",
       "             4.7789e-13],\n",
       "            [4.1464e-13, 1.8459e-12, 2.9425e-13,  ..., 3.3125e-13, 5.1289e-12,\n",
       "             4.4269e-13],\n",
       "            ...,\n",
       "            [1.2898e-13, 1.0332e-13, 1.7589e-13,  ..., 1.3192e-13, 2.4560e-13,\n",
       "             1.2855e-13],\n",
       "            [1.2912e-13, 1.1458e-13, 1.8257e-13,  ..., 7.4878e-14, 6.1055e-13,\n",
       "             2.0949e-13],\n",
       "            [1.0011e-13, 1.0083e-13, 1.5736e-13,  ..., 9.0477e-14, 1.2096e-13,\n",
       "             2.1708e-13]])},\n",
       "   'model.layers.3.self_attn.o_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 2.7805e-07, -6.8834e-08,  1.4461e-07,  ...,  9.3517e-08,\n",
       "             -4.9467e-07,  2.8540e-07],\n",
       "            [-3.3305e-07, -3.5006e-07,  1.0885e-07,  ...,  8.8213e-07,\n",
       "              1.7150e-07,  4.3194e-07],\n",
       "            [-4.3773e-07, -9.4103e-08, -3.1822e-07,  ..., -2.0103e-07,\n",
       "              1.7478e-07, -2.9189e-07],\n",
       "            ...,\n",
       "            [-3.0539e-08,  1.8275e-07, -2.1662e-07,  ...,  1.2452e-06,\n",
       "             -1.5680e-07,  2.5070e-07],\n",
       "            [-3.1207e-07, -2.1199e-07,  2.0165e-07,  ..., -8.6157e-07,\n",
       "             -1.3853e-07, -9.7596e-07],\n",
       "            [-1.9384e-07, -1.1377e-07, -4.7861e-07,  ..., -5.6905e-07,\n",
       "             -4.3172e-08,  9.0756e-07]]),\n",
       "    'exp_avg_sq': tensor([[9.8989e-13, 2.2355e-12, 2.3964e-12,  ..., 2.0064e-12, 2.3455e-12,\n",
       "             3.2068e-12],\n",
       "            [1.8315e-12, 2.1796e-12, 2.3153e-12,  ..., 3.7407e-12, 3.9417e-12,\n",
       "             4.0616e-12],\n",
       "            [1.0576e-12, 1.7783e-12, 2.9222e-12,  ..., 3.7765e-12, 4.0756e-12,\n",
       "             3.0275e-12],\n",
       "            ...,\n",
       "            [8.5311e-13, 1.6894e-12, 2.5302e-12,  ..., 7.7530e-12, 4.0490e-12,\n",
       "             3.4147e-12],\n",
       "            [1.3122e-12, 2.9105e-12, 2.9954e-12,  ..., 4.8005e-12, 3.4896e-12,\n",
       "             7.0517e-12],\n",
       "            [1.8173e-12, 2.0273e-12, 2.5229e-12,  ..., 3.8889e-12, 4.6898e-12,\n",
       "             3.9910e-12]])},\n",
       "   'model.layers.3.self_attn.q_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-1.5153e-07, -3.1639e-07,  7.3401e-07,  ...,  3.9963e-07,\n",
       "             1.0154e-07,  5.9106e-07]),\n",
       "    'exp_avg_sq': tensor([1.0381e-11, 9.6158e-12, 1.7056e-11,  ..., 7.8582e-12, 8.1761e-12,\n",
       "            6.7025e-12])},\n",
       "   'model.layers.3.self_attn.q_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 7.7398e-08, -8.9059e-08,  7.8226e-09,  ...,  5.5909e-08,\n",
       "              1.5931e-08, -3.0300e-07],\n",
       "            [ 7.0832e-08,  4.8267e-08,  9.6678e-08,  ..., -3.4408e-08,\n",
       "              9.8678e-08,  5.3283e-08],\n",
       "            [ 1.2170e-07, -4.4519e-08,  6.7437e-08,  ...,  1.2747e-07,\n",
       "              8.3031e-09,  4.2254e-08],\n",
       "            ...,\n",
       "            [-3.8912e-08,  1.7076e-07,  1.3781e-07,  ..., -1.1750e-07,\n",
       "             -5.2347e-08,  9.7058e-08],\n",
       "            [ 9.7784e-09, -3.3553e-08,  8.7178e-08,  ..., -1.9858e-07,\n",
       "              6.1169e-09,  3.6749e-08],\n",
       "            [-1.7310e-07,  2.7286e-08, -8.9298e-08,  ...,  1.8576e-07,\n",
       "             -4.1686e-08, -9.7535e-08]]),\n",
       "    'exp_avg_sq': tensor([[1.6308e-13, 3.8909e-13, 2.7639e-13,  ..., 1.3440e-13, 2.1214e-13,\n",
       "             3.4729e-13],\n",
       "            [2.0127e-13, 1.1884e-13, 2.2707e-13,  ..., 1.4187e-13, 1.6510e-13,\n",
       "             2.4428e-13],\n",
       "            [4.0892e-13, 1.6004e-13, 3.0427e-13,  ..., 2.2940e-13, 2.0680e-13,\n",
       "             6.1746e-13],\n",
       "            ...,\n",
       "            [2.7843e-13, 1.3501e-13, 2.3483e-13,  ..., 1.2935e-13, 2.8099e-13,\n",
       "             2.0768e-13],\n",
       "            [1.6441e-13, 1.4640e-13, 2.0707e-13,  ..., 1.6115e-13, 2.3785e-13,\n",
       "             2.1821e-13],\n",
       "            [2.2040e-13, 1.3054e-13, 1.5796e-13,  ..., 1.8882e-13, 1.7092e-13,\n",
       "             2.2269e-13]])},\n",
       "   'model.layers.3.self_attn.v_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 2.6123e-06, -4.7108e-07, -1.8622e-05,  ..., -2.9395e-06,\n",
       "            -1.4986e-06, -2.6652e-06]),\n",
       "    'exp_avg_sq': tensor([9.9326e-10, 8.8564e-10, 1.6520e-09,  ..., 1.5585e-09, 1.3832e-09,\n",
       "            1.4845e-09])},\n",
       "   'model.layers.3.self_attn.v_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-1.1806e-07, -1.8806e-07, -1.1567e-07,  ..., -3.6002e-08,\n",
       "             -2.7830e-07,  1.8053e-07],\n",
       "            [-3.3519e-08,  4.0754e-07, -8.6128e-08,  ..., -1.1697e-07,\n",
       "              6.8432e-08,  2.7931e-07],\n",
       "            [-1.2712e-08,  1.0042e-07, -1.3293e-07,  ..., -1.9174e-07,\n",
       "              2.3838e-07, -1.6752e-07],\n",
       "            ...,\n",
       "            [ 2.9674e-07, -6.2351e-08,  1.9406e-07,  ..., -1.8163e-07,\n",
       "              3.0968e-07, -2.0999e-07],\n",
       "            [ 3.3865e-07,  3.6711e-07, -6.6087e-08,  ...,  8.2343e-08,\n",
       "             -2.1655e-09, -2.7101e-07],\n",
       "            [ 5.4394e-07, -1.9553e-07, -3.5026e-07,  ...,  1.3857e-07,\n",
       "             -4.5099e-07,  7.6713e-07]]),\n",
       "    'exp_avg_sq': tensor([[7.2798e-13, 8.3651e-13, 1.6032e-12,  ..., 7.0381e-13, 6.2278e-13,\n",
       "             9.8119e-13],\n",
       "            [9.3776e-13, 9.0416e-13, 9.9859e-13,  ..., 6.9738e-13, 7.9649e-13,\n",
       "             8.8464e-13],\n",
       "            [6.8924e-13, 9.7601e-13, 1.1561e-12,  ..., 5.1138e-13, 1.1118e-12,\n",
       "             1.4325e-12],\n",
       "            ...,\n",
       "            [1.5830e-12, 2.9070e-12, 1.9975e-12,  ..., 1.3002e-12, 3.6815e-12,\n",
       "             2.6538e-12],\n",
       "            [2.5069e-12, 1.8042e-12, 1.8858e-12,  ..., 1.5797e-12, 2.0878e-12,\n",
       "             2.3439e-12],\n",
       "            [2.0861e-12, 1.6967e-12, 2.0280e-12,  ..., 2.0542e-12, 1.8979e-12,\n",
       "             4.1458e-12]])},\n",
       "   'model.layers.4.input_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-4.7545e-07,  6.7509e-07, -2.8082e-06,  ..., -2.3388e-06,\n",
       "             3.4627e-06, -3.5449e-06]),\n",
       "    'exp_avg_sq': tensor([6.0858e-10, 4.3207e-10, 6.5634e-10,  ..., 4.1192e-10, 5.0226e-10,\n",
       "            4.4796e-10])},\n",
       "   'model.layers.4.mlp.down_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-1.2081e-07,  2.8747e-07, -3.3159e-08,  ...,  8.7348e-07,\n",
       "             -1.0031e-06, -8.2939e-08],\n",
       "            [ 5.8417e-07,  6.9621e-07, -1.3663e-07,  ...,  3.4054e-07,\n",
       "              1.1314e-07, -8.1613e-07],\n",
       "            [-2.7157e-07, -2.5790e-07,  2.9505e-07,  ...,  3.9944e-07,\n",
       "             -2.4619e-07, -3.8152e-07],\n",
       "            ...,\n",
       "            [-1.8595e-07, -7.0851e-08, -6.3212e-09,  ..., -3.1329e-07,\n",
       "              8.6194e-08, -2.6863e-07],\n",
       "            [-5.0213e-07, -5.1838e-08, -1.2356e-07,  ..., -4.8497e-07,\n",
       "              1.0933e-08, -2.4408e-07],\n",
       "            [-2.6399e-07,  5.4818e-07, -1.8430e-07,  ...,  5.9413e-07,\n",
       "              1.0456e-06,  5.3757e-07]]),\n",
       "    'exp_avg_sq': tensor([[7.8204e-12, 6.5925e-12, 3.6402e-12,  ..., 5.3679e-12, 1.1924e-11,\n",
       "             2.9428e-12],\n",
       "            [3.6625e-12, 5.9824e-12, 4.8629e-12,  ..., 4.1478e-12, 1.2062e-11,\n",
       "             6.8184e-12],\n",
       "            [4.6558e-12, 4.5320e-12, 3.8010e-12,  ..., 4.1088e-12, 9.7967e-12,\n",
       "             6.6847e-12],\n",
       "            ...,\n",
       "            [5.3913e-12, 4.8838e-12, 4.9734e-12,  ..., 6.6429e-12, 1.3434e-11,\n",
       "             6.0735e-12],\n",
       "            [5.6819e-12, 8.0951e-12, 5.3288e-12,  ..., 5.8235e-12, 3.3081e-11,\n",
       "             7.9100e-12],\n",
       "            [6.3473e-12, 6.7678e-12, 6.2365e-12,  ..., 4.1997e-12, 1.4780e-11,\n",
       "             6.9220e-12]])},\n",
       "   'model.layers.4.mlp.gate_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 1.2380e-07, -3.8195e-07, -4.1755e-08,  ...,  1.1677e-07,\n",
       "              7.3992e-08, -3.2318e-08],\n",
       "            [-6.2857e-09,  9.8789e-07, -2.0590e-07,  ..., -1.7460e-07,\n",
       "              8.8689e-08, -5.4076e-07],\n",
       "            [-5.3524e-09, -2.1394e-07, -1.7083e-07,  ...,  1.4052e-07,\n",
       "              1.1969e-07,  1.7253e-07],\n",
       "            ...,\n",
       "            [ 1.9699e-07, -3.5915e-07, -1.6429e-08,  ..., -6.3398e-07,\n",
       "             -4.4919e-07,  2.8251e-07],\n",
       "            [ 1.8254e-08, -6.1581e-07,  1.0313e-06,  ..., -5.4882e-07,\n",
       "             -2.6820e-07,  6.6005e-07],\n",
       "            [ 1.8551e-07, -9.4792e-08,  3.4982e-07,  ...,  1.3035e-07,\n",
       "             -2.3353e-08, -3.5507e-07]]),\n",
       "    'exp_avg_sq': tensor([[2.1877e-12, 1.5219e-12, 2.3248e-12,  ..., 2.0373e-12, 2.5935e-12,\n",
       "             3.5786e-12],\n",
       "            [2.9200e-12, 3.8626e-12, 2.8313e-12,  ..., 1.8864e-12, 4.6709e-12,\n",
       "             1.9603e-12],\n",
       "            [1.5210e-12, 1.7575e-12, 2.3153e-12,  ..., 2.4157e-12, 2.8927e-12,\n",
       "             2.0266e-12],\n",
       "            ...,\n",
       "            [2.0791e-12, 1.8383e-12, 1.7760e-12,  ..., 2.1865e-12, 2.3033e-12,\n",
       "             1.8277e-12],\n",
       "            [3.0444e-12, 3.9376e-12, 8.5692e-12,  ..., 2.9480e-12, 1.5503e-11,\n",
       "             4.5356e-12],\n",
       "            [4.0866e-12, 2.1994e-12, 1.8674e-12,  ..., 3.0008e-12, 3.2709e-12,\n",
       "             2.6716e-12]])},\n",
       "   'model.layers.4.mlp.up_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-5.9093e-07, -1.7409e-07, -1.6211e-07,  ..., -3.9327e-07,\n",
       "              1.0174e-08, -1.3280e-07],\n",
       "            [ 2.1790e-07,  3.5194e-07,  1.8678e-07,  ..., -4.2315e-07,\n",
       "              3.1662e-08, -3.1577e-07],\n",
       "            [-5.5114e-07, -3.4476e-07,  3.1084e-08,  ..., -2.2710e-07,\n",
       "              3.0022e-07,  1.3584e-07],\n",
       "            ...,\n",
       "            [ 9.7162e-07,  3.1628e-07,  7.2891e-07,  ..., -2.3739e-08,\n",
       "              5.0554e-07, -3.5794e-07],\n",
       "            [-3.2600e-08, -2.4840e-08, -5.2502e-07,  ..., -2.9163e-07,\n",
       "              4.4608e-07,  3.6343e-07],\n",
       "            [ 5.5439e-07, -2.6047e-07,  1.4769e-07,  ...,  4.0998e-07,\n",
       "              6.4756e-07,  3.3602e-07]]),\n",
       "    'exp_avg_sq': tensor([[3.6639e-12, 2.8406e-12, 1.6371e-12,  ..., 2.6946e-12, 2.4039e-12,\n",
       "             1.9585e-12],\n",
       "            [5.2232e-12, 2.3340e-12, 2.8265e-12,  ..., 3.2055e-12, 3.2853e-12,\n",
       "             2.5825e-12],\n",
       "            [4.7581e-12, 3.1140e-12, 2.2292e-12,  ..., 2.4314e-12, 2.8754e-12,\n",
       "             2.7810e-12],\n",
       "            ...,\n",
       "            [2.8649e-12, 1.9758e-12, 1.8371e-12,  ..., 2.6680e-12, 2.6370e-12,\n",
       "             2.3977e-12],\n",
       "            [3.3175e-12, 1.9733e-12, 3.1975e-12,  ..., 3.1201e-12, 4.6956e-12,\n",
       "             2.4544e-12],\n",
       "            [3.1089e-12, 3.0810e-12, 1.8503e-12,  ..., 1.9356e-12, 3.9535e-12,\n",
       "             1.7931e-12]])},\n",
       "   'model.layers.4.post_attention_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 9.2497e-07, -6.3621e-06, -1.5920e-06,  ...,  2.2219e-06,\n",
       "             2.4797e-06, -3.0167e-07]),\n",
       "    'exp_avg_sq': tensor([4.8777e-10, 3.8295e-10, 6.4203e-10,  ..., 5.5620e-10, 5.2926e-10,\n",
       "            7.0263e-10])},\n",
       "   'model.layers.4.self_attn.k_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 3.4610e-06, -2.3849e-07,  2.0190e-06,  ...,  1.2377e-08,\n",
       "             3.3658e-09, -1.6671e-09]),\n",
       "    'exp_avg_sq': tensor([3.6121e-10, 2.0626e-11, 1.7006e-10,  ..., 1.1067e-15, 6.7660e-16,\n",
       "            7.9011e-16])},\n",
       "   'model.layers.4.self_attn.k_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-3.7403e-07, -1.8156e-07, -2.0818e-07,  ..., -4.3239e-07,\n",
       "             -4.9198e-07,  5.0309e-08],\n",
       "            [-2.0430e-07, -3.0493e-07,  1.7739e-07,  ...,  5.8163e-08,\n",
       "             -2.2721e-08,  2.4285e-08],\n",
       "            [-4.3636e-07, -2.9144e-07, -2.9940e-08,  ..., -3.2192e-07,\n",
       "             -1.3531e-07, -2.3730e-08],\n",
       "            ...,\n",
       "            [-4.5377e-07, -5.3211e-07, -4.6713e-08,  ...,  1.6674e-08,\n",
       "              1.2242e-06,  7.6099e-09],\n",
       "            [-6.6378e-07, -1.0762e-07, -5.0162e-07,  ..., -4.2525e-07,\n",
       "              1.2436e-06,  5.9569e-08],\n",
       "            [ 2.8938e-07,  5.8224e-08,  2.4992e-08,  ...,  1.4983e-07,\n",
       "             -1.2996e-07, -5.4956e-07]]),\n",
       "    'exp_avg_sq': tensor([[4.9163e-12, 4.7976e-12, 6.2531e-12,  ..., 3.7920e-12, 1.4967e-11,\n",
       "             7.6368e-12],\n",
       "            [1.0696e-12, 1.1695e-12, 1.1440e-12,  ..., 6.5376e-13, 1.6047e-12,\n",
       "             1.4044e-12],\n",
       "            [2.6642e-12, 3.1049e-12, 3.5209e-12,  ..., 1.9551e-12, 6.4751e-12,\n",
       "             3.8087e-12],\n",
       "            ...,\n",
       "            [8.1247e-12, 6.4719e-12, 4.5198e-12,  ..., 6.3310e-12, 6.1064e-11,\n",
       "             8.6644e-12],\n",
       "            [3.3716e-12, 2.8575e-12, 3.7920e-12,  ..., 3.3757e-12, 6.9895e-12,\n",
       "             3.7492e-12],\n",
       "            [4.1795e-12, 3.6680e-12, 3.7754e-12,  ..., 2.0380e-12, 1.3939e-11,\n",
       "             7.0943e-12]])},\n",
       "   'model.layers.4.self_attn.o_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 2.0931e-06, -5.9787e-07, -2.7897e-07,  ...,  1.2934e-06,\n",
       "              5.2296e-07, -4.5135e-07],\n",
       "            [-1.3983e-07,  4.3481e-07, -8.1042e-07,  ..., -1.0293e-06,\n",
       "              9.0033e-08,  1.7435e-07],\n",
       "            [ 6.1268e-07, -4.8930e-07,  1.3232e-06,  ...,  3.3336e-07,\n",
       "             -1.0177e-06,  4.4595e-07],\n",
       "            ...,\n",
       "            [-1.3560e-07, -1.7886e-07,  4.8668e-07,  ..., -6.7540e-07,\n",
       "             -3.1605e-07,  8.9789e-07],\n",
       "            [-5.3007e-07, -9.3125e-07,  1.1597e-06,  ...,  2.2757e-07,\n",
       "              9.0614e-07, -7.7356e-08],\n",
       "            [ 1.4124e-06,  2.7225e-07,  8.5571e-08,  ..., -3.8873e-07,\n",
       "              3.5197e-07, -4.8372e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.1436e-11, 1.8075e-11, 6.6130e-12,  ..., 7.8038e-12, 7.8115e-12,\n",
       "             6.5957e-12],\n",
       "            [6.9283e-12, 1.2548e-11, 8.8901e-12,  ..., 7.6076e-12, 1.0831e-11,\n",
       "             9.7124e-12],\n",
       "            [5.1693e-12, 7.4291e-12, 8.8140e-12,  ..., 5.6926e-12, 7.7533e-12,\n",
       "             1.0378e-11],\n",
       "            ...,\n",
       "            [1.3947e-11, 1.1398e-11, 1.1883e-11,  ..., 8.7489e-12, 5.4423e-12,\n",
       "             7.6463e-12],\n",
       "            [8.4111e-12, 1.1189e-11, 1.0907e-11,  ..., 7.1735e-12, 6.9689e-12,\n",
       "             8.3514e-12],\n",
       "            [1.1500e-11, 7.9094e-12, 8.6448e-12,  ..., 6.7736e-12, 5.2784e-12,\n",
       "             7.3898e-12]])},\n",
       "   'model.layers.4.self_attn.q_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-1.6814e-07, -2.7265e-06,  1.5020e-06,  ..., -1.0884e-06,\n",
       "             1.4041e-06,  9.4385e-07]),\n",
       "    'exp_avg_sq': tensor([7.0475e-11, 1.3590e-10, 1.0534e-10,  ..., 1.1002e-10, 6.2329e-11,\n",
       "            4.7524e-11])},\n",
       "   'model.layers.4.self_attn.q_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-2.4390e-07, -1.2480e-08, -2.8670e-07,  ..., -8.9250e-07,\n",
       "              1.8576e-08, -8.8758e-07],\n",
       "            [-2.1180e-07,  4.0649e-07,  4.5643e-08,  ..., -4.9433e-07,\n",
       "              6.8332e-07, -4.4860e-08],\n",
       "            [ 1.6600e-08, -5.6468e-07,  1.4921e-07,  ..., -4.0334e-07,\n",
       "             -6.9555e-07, -3.6962e-07],\n",
       "            ...,\n",
       "            [-3.3345e-07, -5.5552e-07, -6.1078e-07,  ..., -1.5260e-07,\n",
       "              2.8932e-08, -1.7495e-07],\n",
       "            [-9.2268e-08, -3.8727e-07, -9.4356e-07,  ..., -5.5027e-08,\n",
       "             -1.1580e-06, -1.9435e-07],\n",
       "            [ 1.0851e-07,  3.0631e-07,  5.2064e-08,  ...,  2.4260e-07,\n",
       "              2.4849e-07, -6.1286e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.6751e-12, 1.8637e-12, 3.4834e-12,  ..., 3.1575e-12, 3.9599e-12,\n",
       "             3.2092e-12],\n",
       "            [4.1047e-12, 2.5142e-12, 2.7396e-12,  ..., 2.3774e-12, 6.6570e-12,\n",
       "             2.9311e-12],\n",
       "            [2.9113e-12, 3.8867e-12, 4.4375e-12,  ..., 3.1486e-12, 4.0142e-12,\n",
       "             3.2751e-12],\n",
       "            ...,\n",
       "            [2.1206e-11, 2.7892e-12, 7.6546e-12,  ..., 7.2534e-12, 1.2116e-11,\n",
       "             5.2778e-12],\n",
       "            [3.7901e-12, 2.5972e-12, 6.5835e-12,  ..., 3.1963e-12, 4.5949e-12,\n",
       "             6.1608e-12],\n",
       "            [2.0289e-12, 2.2058e-12, 4.5982e-12,  ..., 3.8259e-12, 5.4266e-12,\n",
       "             4.2125e-12]])},\n",
       "   'model.layers.4.self_attn.v_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 1.6470e-05,  6.9961e-06,  7.4674e-06,  ..., -3.6068e-06,\n",
       "            -7.9699e-06, -1.1563e-05]),\n",
       "    'exp_avg_sq': tensor([2.7021e-09, 1.7807e-09, 1.2852e-09,  ..., 1.7707e-09, 1.9619e-09,\n",
       "            2.1979e-09])},\n",
       "   'model.layers.4.self_attn.v_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 6.2236e-07, -6.4467e-08,  1.0924e-07,  ..., -1.0901e-07,\n",
       "              4.8479e-07,  7.8632e-07],\n",
       "            [-4.1093e-07,  7.4500e-09,  8.4526e-07,  ...,  1.5102e-07,\n",
       "             -3.4336e-07,  1.1414e-07],\n",
       "            [ 3.1002e-07, -9.2683e-07, -9.0675e-08,  ...,  7.2542e-07,\n",
       "              1.0260e-06, -7.7535e-07],\n",
       "            ...,\n",
       "            [-5.5754e-07,  6.3073e-07,  1.9964e-07,  ..., -5.7037e-07,\n",
       "             -2.5763e-07, -7.7423e-08],\n",
       "            [ 4.4608e-07, -8.5732e-07, -1.5560e-06,  ..., -7.7594e-09,\n",
       "              1.1275e-06, -2.3506e-07],\n",
       "            [ 8.2661e-07,  3.2332e-07, -7.8803e-07,  ..., -6.7214e-07,\n",
       "             -6.5464e-07, -4.6065e-07]]),\n",
       "    'exp_avg_sq': tensor([[5.2099e-12, 5.2601e-12, 6.2755e-12,  ..., 5.7452e-12, 5.9871e-12,\n",
       "             8.4544e-12],\n",
       "            [5.1381e-12, 4.0547e-12, 8.4941e-12,  ..., 4.7060e-12, 9.8178e-12,\n",
       "             7.5236e-12],\n",
       "            [3.0501e-12, 5.3692e-12, 7.8079e-12,  ..., 5.3800e-12, 9.9659e-12,\n",
       "             7.3224e-12],\n",
       "            ...,\n",
       "            [3.6961e-12, 5.2083e-12, 5.0228e-12,  ..., 3.2870e-12, 3.5083e-12,\n",
       "             5.2998e-12],\n",
       "            [3.2269e-12, 4.7285e-12, 7.5200e-12,  ..., 4.3192e-12, 1.0048e-11,\n",
       "             7.1596e-12],\n",
       "            [5.3008e-12, 3.7871e-12, 6.6618e-12,  ..., 4.8863e-12, 1.3260e-11,\n",
       "             8.2580e-12]])},\n",
       "   'model.layers.5.input_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-2.8475e-07, -1.0542e-06, -2.0510e-06,  ..., -4.5726e-06,\n",
       "            -3.4309e-06, -2.8853e-06]),\n",
       "    'exp_avg_sq': tensor([4.5637e-10, 5.5885e-10, 4.4357e-10,  ..., 6.4493e-10, 3.8262e-10,\n",
       "            3.9248e-10])},\n",
       "   'model.layers.5.mlp.down_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-5.3889e-07, -9.6160e-07, -6.2316e-07,  ...,  3.0521e-07,\n",
       "             -1.2887e-07,  1.2590e-06],\n",
       "            [-2.9059e-07, -6.6732e-07, -1.9516e-07,  ..., -3.2820e-07,\n",
       "              5.5156e-07,  3.0138e-07],\n",
       "            [ 3.3019e-07,  3.4390e-07,  2.5727e-07,  ...,  1.4811e-07,\n",
       "              8.0033e-07, -5.1176e-07],\n",
       "            ...,\n",
       "            [ 9.6458e-07, -2.5620e-07, -1.0065e-08,  ...,  9.6272e-08,\n",
       "              3.7264e-07, -1.4977e-07],\n",
       "            [-9.8080e-07,  8.3612e-07,  2.8563e-07,  ...,  1.7607e-07,\n",
       "              1.8094e-07,  4.2025e-07],\n",
       "            [-2.1539e-07, -7.3602e-07,  2.3327e-07,  ..., -4.9744e-07,\n",
       "              3.3030e-07,  8.9501e-07]]),\n",
       "    'exp_avg_sq': tensor([[6.6209e-12, 4.6280e-12, 6.5659e-12,  ..., 5.2656e-12, 7.7285e-12,\n",
       "             6.2741e-12],\n",
       "            [9.2644e-12, 5.6683e-12, 3.9136e-12,  ..., 4.9805e-12, 7.6365e-12,\n",
       "             5.4243e-12],\n",
       "            [7.5588e-12, 5.1709e-12, 4.7163e-12,  ..., 4.2345e-12, 6.3325e-12,\n",
       "             5.5416e-12],\n",
       "            ...,\n",
       "            [6.1225e-12, 6.1817e-12, 8.7595e-12,  ..., 8.2208e-12, 3.9824e-12,\n",
       "             5.9176e-12],\n",
       "            [7.7217e-12, 6.6617e-12, 4.8587e-12,  ..., 6.8767e-12, 6.3915e-12,\n",
       "             5.2565e-12],\n",
       "            [5.6557e-12, 7.4626e-12, 4.6088e-12,  ..., 6.7243e-12, 6.5457e-12,\n",
       "             7.2485e-12]])},\n",
       "   'model.layers.5.mlp.gate_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 3.0751e-07, -4.9240e-07, -1.2892e-07,  ..., -1.4680e-07,\n",
       "             -9.3525e-07, -3.5860e-07],\n",
       "            [ 5.9510e-08,  7.4683e-08, -6.2899e-08,  ..., -1.5731e-07,\n",
       "              3.5089e-08,  3.0966e-07],\n",
       "            [-3.7770e-07, -2.4581e-07,  3.4385e-07,  ..., -2.4480e-08,\n",
       "             -1.1535e-07, -2.3439e-07],\n",
       "            ...,\n",
       "            [-1.1990e-07, -3.7849e-07, -4.0975e-07,  ..., -1.4156e-07,\n",
       "              7.6258e-07,  6.2088e-07],\n",
       "            [ 5.2384e-08, -2.9180e-07,  2.3656e-07,  ..., -1.5439e-07,\n",
       "              2.6391e-07,  2.7327e-07],\n",
       "            [ 3.2615e-07, -6.7067e-07,  4.9710e-07,  ...,  3.3545e-07,\n",
       "             -7.1087e-07, -5.1453e-07]]),\n",
       "    'exp_avg_sq': tensor([[3.6534e-12, 3.7065e-12, 2.6590e-12,  ..., 5.0273e-12, 5.5907e-12,\n",
       "             3.4231e-12],\n",
       "            [2.2106e-12, 2.8165e-12, 1.9724e-12,  ..., 3.1914e-12, 4.3878e-12,\n",
       "             3.2681e-12],\n",
       "            [2.4725e-12, 3.8166e-12, 1.9173e-12,  ..., 2.5633e-12, 2.4454e-12,\n",
       "             4.3989e-12],\n",
       "            ...,\n",
       "            [2.9250e-12, 2.6963e-12, 2.2086e-12,  ..., 3.4245e-12, 5.0496e-12,\n",
       "             4.0590e-12],\n",
       "            [3.4380e-12, 3.9841e-12, 2.6967e-12,  ..., 3.9942e-12, 5.5921e-12,\n",
       "             2.6595e-12],\n",
       "            [3.4845e-12, 3.9190e-12, 2.4786e-12,  ..., 4.8562e-12, 5.0820e-12,\n",
       "             2.9589e-12]])},\n",
       "   'model.layers.5.mlp.up_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-4.7440e-07, -8.1250e-08, -2.9329e-07,  ..., -1.3044e-09,\n",
       "              4.1489e-07,  1.6083e-07],\n",
       "            [ 1.7803e-07, -2.3564e-07,  7.1393e-08,  ..., -1.5587e-07,\n",
       "              3.2631e-07, -4.4038e-07],\n",
       "            [-1.5374e-07,  3.2938e-07, -3.6196e-07,  ..., -3.1992e-07,\n",
       "              9.0222e-07,  5.1204e-07],\n",
       "            ...,\n",
       "            [-9.8898e-07, -4.5230e-08, -1.0360e-07,  ..., -2.4696e-07,\n",
       "              7.8760e-07, -2.8570e-08],\n",
       "            [ 5.8513e-07,  2.4846e-07,  6.7282e-07,  ..., -2.7136e-07,\n",
       "              2.8337e-07, -6.2971e-07],\n",
       "            [-6.5170e-09,  2.1484e-07, -1.2849e-07,  ..., -5.2350e-07,\n",
       "             -2.3633e-07,  5.2172e-08]]),\n",
       "    'exp_avg_sq': tensor([[3.8419e-12, 2.9170e-12, 3.6292e-12,  ..., 4.1504e-12, 4.7906e-12,\n",
       "             1.9028e-12],\n",
       "            [2.9273e-12, 2.5469e-12, 2.6669e-12,  ..., 2.6908e-12, 4.3755e-12,\n",
       "             1.9998e-12],\n",
       "            [2.2328e-12, 3.6305e-12, 1.6220e-12,  ..., 2.9616e-12, 5.0158e-12,\n",
       "             2.0411e-12],\n",
       "            ...,\n",
       "            [4.1797e-12, 3.0945e-12, 3.8435e-12,  ..., 3.4220e-12, 3.8520e-12,\n",
       "             3.4075e-12],\n",
       "            [4.2548e-12, 2.9718e-12, 2.3201e-12,  ..., 3.9261e-12, 4.4030e-12,\n",
       "             3.5375e-12],\n",
       "            [3.4151e-12, 3.4083e-12, 2.7843e-12,  ..., 5.4797e-12, 4.2700e-12,\n",
       "             3.2406e-12]])},\n",
       "   'model.layers.5.post_attention_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-2.4568e-06, -1.6515e-06,  3.4296e-06,  ..., -1.9567e-08,\n",
       "            -7.3460e-08,  3.6810e-06]),\n",
       "    'exp_avg_sq': tensor([5.7992e-10, 5.4730e-10, 7.5595e-10,  ..., 4.3317e-10, 5.1757e-10,\n",
       "            6.5322e-10])},\n",
       "   'model.layers.5.self_attn.k_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 4.9293e-07, -8.7252e-07,  7.5172e-07,  ..., -1.5204e-09,\n",
       "            -1.7727e-09, -1.0213e-09]),\n",
       "    'exp_avg_sq': tensor([3.9202e-11, 3.3481e-11, 3.9762e-11,  ..., 1.1889e-16, 1.9008e-16,\n",
       "            1.2148e-16])},\n",
       "   'model.layers.5.self_attn.k_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-1.8679e-06,  1.3198e-07,  6.3738e-07,  ...,  3.2785e-07,\n",
       "             -1.7560e-06, -1.5405e-06],\n",
       "            [ 8.7168e-07, -4.6946e-07, -3.0989e-07,  ..., -7.8293e-08,\n",
       "              7.7481e-07,  6.7074e-07],\n",
       "            [-8.0778e-07,  1.7717e-07,  6.4310e-08,  ...,  1.9733e-07,\n",
       "             -6.7394e-07, -7.7251e-07],\n",
       "            ...,\n",
       "            [-1.3194e-07,  5.1283e-07,  3.9764e-07,  ...,  1.1374e-07,\n",
       "             -5.1666e-08, -1.6085e-07],\n",
       "            [ 6.6375e-08, -3.3760e-07,  2.5507e-07,  ..., -5.1166e-07,\n",
       "             -3.9442e-08, -8.0518e-08],\n",
       "            [ 8.5608e-09,  2.4596e-07, -2.3975e-07,  ..., -9.4572e-08,\n",
       "             -7.0859e-08, -8.8550e-08]]),\n",
       "    'exp_avg_sq': tensor([[2.3758e-11, 2.2546e-11, 1.6907e-11,  ..., 1.6272e-11, 2.2527e-11,\n",
       "             3.8450e-11],\n",
       "            [6.2496e-12, 7.0199e-12, 6.0728e-12,  ..., 5.4321e-12, 5.2904e-12,\n",
       "             1.0450e-11],\n",
       "            [6.5081e-12, 7.4989e-12, 4.9297e-12,  ..., 6.0631e-12, 6.2618e-12,\n",
       "             1.1461e-11],\n",
       "            ...,\n",
       "            [9.6579e-13, 1.6257e-12, 1.2420e-12,  ..., 1.1424e-12, 7.2418e-13,\n",
       "             1.5087e-12],\n",
       "            [2.5330e-12, 2.0311e-12, 2.0407e-12,  ..., 2.0378e-12, 1.5416e-12,\n",
       "             2.3272e-12],\n",
       "            [1.3520e-12, 1.9387e-12, 1.2033e-12,  ..., 8.5382e-13, 1.1235e-12,\n",
       "             1.4542e-12]])},\n",
       "   'model.layers.5.self_attn.o_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-8.5275e-07,  1.5534e-06, -7.2855e-08,  ...,  2.0831e-07,\n",
       "              3.3923e-07, -2.5646e-06],\n",
       "            [-3.7623e-07, -3.1560e-07, -1.6537e-07,  ...,  3.4987e-07,\n",
       "              3.1777e-07,  1.4037e-06],\n",
       "            [-9.1112e-07, -5.4052e-07, -9.6341e-07,  ..., -5.4478e-07,\n",
       "              1.4569e-07, -1.7349e-06],\n",
       "            ...,\n",
       "            [ 4.8806e-07, -1.1218e-06, -7.2464e-07,  ..., -5.8720e-07,\n",
       "              9.6274e-07,  8.8270e-07],\n",
       "            [-2.8121e-07, -9.9421e-07, -5.1874e-07,  ..., -4.9283e-09,\n",
       "             -2.0907e-07, -2.2837e-06],\n",
       "            [-3.5644e-07,  1.2611e-07, -7.8639e-07,  ..., -8.6530e-07,\n",
       "             -2.5845e-07,  1.2360e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.7915e-11, 2.2392e-11, 1.1679e-11,  ..., 8.9608e-12, 8.4112e-12,\n",
       "             1.7597e-11],\n",
       "            [2.3521e-11, 1.7313e-11, 1.1929e-11,  ..., 9.8401e-12, 8.4861e-12,\n",
       "             1.9381e-11],\n",
       "            [1.7844e-11, 1.6389e-11, 1.4934e-11,  ..., 1.1109e-11, 6.2787e-12,\n",
       "             2.7228e-11],\n",
       "            ...,\n",
       "            [1.5766e-11, 2.0787e-11, 1.6688e-11,  ..., 1.3705e-11, 4.6245e-12,\n",
       "             2.5032e-11],\n",
       "            [1.7707e-11, 1.6343e-11, 1.2163e-11,  ..., 8.0755e-12, 5.4455e-12,\n",
       "             2.9598e-11],\n",
       "            [1.2298e-11, 1.1942e-11, 1.4721e-11,  ..., 9.4953e-12, 6.2214e-12,\n",
       "             2.5150e-11]])},\n",
       "   'model.layers.5.self_attn.q_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 1.3633e-06, -2.0990e-06,  1.6654e-06,  ..., -9.9308e-07,\n",
       "             3.3498e-06,  1.7423e-07]),\n",
       "    'exp_avg_sq': tensor([4.5050e-10, 9.8131e-11, 6.0170e-11,  ..., 9.0281e-11, 9.0163e-11,\n",
       "            8.2309e-11])},\n",
       "   'model.layers.5.self_attn.q_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 1.4891e-07,  7.5958e-07, -2.4183e-07,  ..., -1.7529e-08,\n",
       "             -1.5354e-07,  2.0894e-07],\n",
       "            [ 2.6250e-07, -2.9504e-07,  5.3756e-08,  ...,  3.9440e-07,\n",
       "              8.4501e-07, -6.1182e-07],\n",
       "            [-3.2908e-08,  2.6479e-08,  1.8045e-08,  ..., -2.2267e-07,\n",
       "             -6.8393e-07,  3.5553e-07],\n",
       "            ...,\n",
       "            [ 1.7581e-07, -2.0101e-07, -3.4417e-07,  ...,  5.2024e-07,\n",
       "              9.0228e-07,  2.7853e-07],\n",
       "            [-8.0458e-08,  1.9553e-07, -6.0262e-08,  ..., -2.5677e-07,\n",
       "             -4.8403e-08,  2.1860e-07],\n",
       "            [-4.0530e-07,  2.8763e-07, -5.1242e-07,  ..., -1.8033e-08,\n",
       "             -8.1656e-07, -5.1754e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.8456e-11, 1.5697e-11, 1.3977e-11,  ..., 1.7024e-11, 1.4614e-11,\n",
       "             1.5150e-11],\n",
       "            [3.8175e-12, 3.9459e-12, 3.8978e-12,  ..., 4.4945e-12, 4.2076e-12,\n",
       "             4.6416e-12],\n",
       "            [2.5303e-12, 2.2371e-12, 2.3174e-12,  ..., 2.6745e-12, 2.2703e-12,\n",
       "             2.8315e-12],\n",
       "            ...,\n",
       "            [2.8525e-12, 1.7267e-12, 3.5485e-12,  ..., 2.2560e-12, 3.3230e-12,\n",
       "             4.0833e-12],\n",
       "            [2.8122e-12, 2.7206e-12, 2.8397e-12,  ..., 2.3519e-12, 3.4803e-12,\n",
       "             2.9833e-12],\n",
       "            [2.5526e-12, 3.6412e-12, 1.9776e-12,  ..., 2.1849e-12, 2.4464e-12,\n",
       "             3.1687e-12]])},\n",
       "   'model.layers.5.self_attn.v_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-8.1635e-07,  3.3517e-06, -6.6496e-06,  ...,  1.3848e-05,\n",
       "             1.4376e-06, -5.1585e-06]),\n",
       "    'exp_avg_sq': tensor([1.2272e-09, 1.2847e-09, 9.0958e-10,  ..., 1.4509e-09, 1.2544e-09,\n",
       "            2.1753e-09])},\n",
       "   'model.layers.5.self_attn.v_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-6.4017e-07, -2.5506e-07, -2.1473e-07,  ..., -7.5077e-07,\n",
       "              3.8573e-07, -5.8419e-07],\n",
       "            [-8.9069e-07,  1.2627e-07,  8.1528e-07,  ..., -1.9233e-07,\n",
       "              3.9224e-07, -4.3296e-07],\n",
       "            [-7.1437e-07,  5.4554e-07, -6.1811e-07,  ..., -5.6868e-07,\n",
       "             -5.8609e-07, -1.2959e-07],\n",
       "            ...,\n",
       "            [-1.0141e-06, -1.0560e-07,  8.4518e-07,  ..., -4.2295e-07,\n",
       "             -2.4556e-07,  4.9761e-07],\n",
       "            [ 3.5397e-07,  1.2402e-06,  2.5729e-07,  ...,  1.1384e-07,\n",
       "             -2.7510e-08, -9.8060e-07],\n",
       "            [ 3.7712e-08,  4.3486e-07, -5.3958e-07,  ...,  4.6189e-07,\n",
       "             -8.7261e-07, -1.6406e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.2220e-11, 1.2856e-11, 1.1382e-11,  ..., 9.4399e-12, 1.8799e-11,\n",
       "             1.7547e-11],\n",
       "            [1.2206e-11, 6.8477e-12, 1.4216e-11,  ..., 1.0812e-11, 1.0492e-11,\n",
       "             1.0931e-11],\n",
       "            [1.0916e-11, 9.4299e-12, 9.1816e-12,  ..., 9.1899e-12, 9.4544e-12,\n",
       "             1.0736e-11],\n",
       "            ...,\n",
       "            [7.5279e-12, 6.5777e-12, 4.8027e-12,  ..., 4.4618e-12, 5.5774e-12,\n",
       "             4.5361e-12],\n",
       "            [6.5726e-12, 6.2151e-12, 3.6422e-12,  ..., 3.2419e-12, 3.4832e-12,\n",
       "             3.6402e-12],\n",
       "            [1.2748e-11, 9.2244e-12, 7.5050e-12,  ..., 4.7413e-12, 5.5858e-12,\n",
       "             1.5395e-11]])},\n",
       "   'model.layers.6.input_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-2.9437e-06,  3.6710e-06, -2.1473e-06,  ...,  1.6134e-06,\n",
       "             6.0544e-06, -7.1826e-07]),\n",
       "    'exp_avg_sq': tensor([4.2301e-10, 3.7261e-10, 4.3640e-10,  ..., 3.9817e-10, 5.3750e-10,\n",
       "            3.3145e-10])},\n",
       "   'model.layers.6.mlp.down_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 1.0927e-06,  9.9662e-07,  1.8062e-07,  ..., -3.9482e-07,\n",
       "              4.6112e-07,  9.0724e-07],\n",
       "            [-2.0848e-07,  9.8288e-07, -3.5186e-07,  ..., -2.9047e-07,\n",
       "             -7.3316e-07,  8.7458e-07],\n",
       "            [-2.7686e-07,  1.0165e-07, -3.6433e-07,  ...,  7.7755e-07,\n",
       "             -8.6695e-08, -7.0997e-08],\n",
       "            ...,\n",
       "            [-4.8773e-07,  4.1384e-07,  5.8874e-08,  ...,  9.4542e-08,\n",
       "             -1.8750e-07,  6.8445e-08],\n",
       "            [-6.7568e-07,  4.2417e-07,  2.7752e-07,  ...,  1.4601e-06,\n",
       "             -4.0155e-07,  7.9230e-07],\n",
       "            [-4.3169e-07, -3.9776e-07, -1.9343e-07,  ..., -8.9913e-07,\n",
       "             -5.4161e-07,  1.9969e-07]]),\n",
       "    'exp_avg_sq': tensor([[7.2837e-12, 5.9780e-12, 5.8646e-12,  ..., 5.9466e-12, 5.0798e-12,\n",
       "             7.9611e-12],\n",
       "            [5.3863e-12, 6.1957e-12, 6.2762e-12,  ..., 7.0265e-12, 7.5835e-12,\n",
       "             1.1572e-11],\n",
       "            [8.0755e-12, 3.0165e-12, 5.7471e-12,  ..., 7.0746e-12, 6.7961e-12,\n",
       "             5.6783e-12],\n",
       "            ...,\n",
       "            [7.9921e-12, 6.8933e-12, 4.8830e-12,  ..., 5.0039e-12, 6.0411e-12,\n",
       "             6.7132e-12],\n",
       "            [9.0341e-12, 4.1078e-12, 5.1024e-12,  ..., 9.6636e-12, 5.5960e-12,\n",
       "             5.1596e-12],\n",
       "            [8.2264e-12, 6.2754e-12, 6.4393e-12,  ..., 6.3640e-12, 6.2643e-12,\n",
       "             6.6269e-12]])},\n",
       "   'model.layers.6.mlp.gate_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-9.8804e-08, -4.1667e-07, -5.4564e-07,  ..., -1.9799e-07,\n",
       "             -8.8982e-07, -2.9875e-07],\n",
       "            [-5.1985e-08,  3.1747e-07, -1.5197e-08,  ..., -1.1698e-06,\n",
       "             -4.5186e-08,  3.4429e-08],\n",
       "            [ 1.0840e-07, -5.8634e-07, -3.8189e-07,  ...,  6.3040e-07,\n",
       "             -1.8050e-08,  1.0983e-06],\n",
       "            ...,\n",
       "            [ 1.1993e-07,  7.0856e-07, -5.3898e-08,  ..., -4.4992e-07,\n",
       "             -5.2300e-07, -1.7042e-07],\n",
       "            [ 2.3984e-07,  4.8241e-08,  2.2990e-07,  ...,  9.3189e-07,\n",
       "              4.6180e-07,  2.7636e-07],\n",
       "            [ 7.4006e-08, -7.5256e-07,  4.3337e-07,  ..., -1.4119e-08,\n",
       "              1.4798e-08, -4.3728e-07]]),\n",
       "    'exp_avg_sq': tensor([[7.2776e-12, 3.0049e-12, 3.4915e-12,  ..., 5.7756e-12, 7.9944e-12,\n",
       "             7.6687e-12],\n",
       "            [3.7603e-12, 3.0601e-12, 1.2276e-12,  ..., 4.7862e-12, 3.8031e-12,\n",
       "             3.7479e-12],\n",
       "            [2.7064e-12, 3.1387e-12, 3.2689e-12,  ..., 4.4142e-12, 3.2755e-12,\n",
       "             4.6942e-12],\n",
       "            ...,\n",
       "            [4.8611e-12, 4.1185e-12, 3.8268e-12,  ..., 5.1963e-12, 3.8869e-12,\n",
       "             3.9404e-12],\n",
       "            [2.8221e-12, 5.5196e-12, 3.3248e-12,  ..., 4.1430e-12, 4.3894e-12,\n",
       "             3.5736e-12],\n",
       "            [3.8214e-12, 4.1467e-12, 2.7565e-12,  ..., 2.6406e-12, 4.0546e-12,\n",
       "             6.5462e-12]])},\n",
       "   'model.layers.6.mlp.up_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-5.6052e-08,  3.5976e-08, -5.8325e-07,  ..., -4.7189e-07,\n",
       "             -1.7945e-07,  4.1779e-07],\n",
       "            [-1.2872e-07,  3.2499e-07, -7.6015e-07,  ...,  7.4722e-07,\n",
       "             -3.3565e-07,  7.2377e-07],\n",
       "            [-6.1566e-07, -8.1631e-07, -2.2579e-08,  ..., -2.0171e-07,\n",
       "             -3.7445e-07, -2.9005e-07],\n",
       "            ...,\n",
       "            [-1.0330e-06,  3.2278e-07, -3.9811e-08,  ...,  9.8025e-07,\n",
       "              5.4470e-07, -5.5941e-07],\n",
       "            [-6.1428e-07, -3.6631e-07, -1.6088e-07,  ..., -8.2877e-08,\n",
       "              9.9683e-07, -7.5628e-07],\n",
       "            [ 6.1389e-07, -1.2640e-06,  4.6714e-08,  ...,  1.3619e-07,\n",
       "              5.6964e-08,  7.1775e-07]]),\n",
       "    'exp_avg_sq': tensor([[5.3163e-12, 4.1246e-12, 5.7901e-12,  ..., 5.1420e-12, 3.2100e-12,\n",
       "             3.9708e-12],\n",
       "            [4.3712e-12, 5.2632e-12, 3.7987e-12,  ..., 3.8881e-12, 5.8790e-12,\n",
       "             4.8859e-12],\n",
       "            [4.7003e-12, 5.4792e-12, 3.0429e-12,  ..., 2.9676e-12, 4.1122e-12,\n",
       "             4.7288e-12],\n",
       "            ...,\n",
       "            [5.4642e-12, 3.1025e-12, 4.0299e-12,  ..., 3.7396e-12, 5.7295e-12,\n",
       "             4.9402e-12],\n",
       "            [6.5916e-12, 3.7704e-12, 2.1913e-12,  ..., 3.7161e-12, 4.3172e-12,\n",
       "             5.0038e-12],\n",
       "            [2.9274e-12, 5.4931e-12, 2.7500e-12,  ..., 3.2432e-12, 3.6459e-12,\n",
       "             2.8544e-12]])},\n",
       "   'model.layers.6.post_attention_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-3.1747e-06, -6.7814e-06,  3.7996e-06,  ...,  6.6886e-06,\n",
       "             7.9121e-07, -1.8292e-06]),\n",
       "    'exp_avg_sq': tensor([7.0898e-10, 7.6195e-10, 5.4057e-10,  ..., 4.5054e-10, 7.8912e-10,\n",
       "            4.9758e-10])},\n",
       "   'model.layers.6.self_attn.k_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 6.9723e-08,  7.1196e-07,  7.9814e-07,  ..., -2.9549e-09,\n",
       "             9.2135e-10, -1.4199e-09]),\n",
       "    'exp_avg_sq': tensor([4.2324e-12, 4.2800e-12, 5.3455e-12,  ..., 9.2970e-17, 8.4113e-17,\n",
       "            4.3346e-17])},\n",
       "   'model.layers.6.self_attn.k_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 5.8014e-08,  2.0085e-07, -3.2167e-08,  ...,  3.5563e-08,\n",
       "              1.5886e-07, -9.4353e-09],\n",
       "            [-5.2355e-08,  4.2217e-08, -5.5184e-09,  ..., -1.2941e-07,\n",
       "             -2.0501e-07,  6.2099e-08],\n",
       "            [ 2.5280e-07, -6.8642e-09, -2.3440e-07,  ...,  3.8956e-08,\n",
       "             -2.7977e-07, -6.0266e-08],\n",
       "            ...,\n",
       "            [-1.2048e-07,  1.2198e-07, -3.4800e-08,  ...,  8.7914e-08,\n",
       "              2.6061e-08,  1.0151e-07],\n",
       "            [-1.3384e-08, -1.5968e-08,  1.2342e-07,  ..., -1.0174e-07,\n",
       "             -2.1937e-07,  4.4613e-08],\n",
       "            [ 3.1403e-08,  3.5968e-07,  8.5075e-08,  ..., -2.2155e-07,\n",
       "              8.6934e-08, -6.8547e-08]]),\n",
       "    'exp_avg_sq': tensor([[2.2151e-13, 2.2033e-13, 2.2057e-13,  ..., 2.5816e-13, 2.4858e-13,\n",
       "             3.0191e-13],\n",
       "            [5.9247e-13, 1.6478e-13, 3.1969e-13,  ..., 2.1819e-13, 3.0929e-13,\n",
       "             2.8359e-13],\n",
       "            [4.3505e-13, 1.8055e-13, 4.4566e-13,  ..., 1.9235e-13, 2.8316e-13,\n",
       "             2.2159e-13],\n",
       "            ...,\n",
       "            [3.5464e-13, 4.5689e-13, 4.7635e-13,  ..., 2.0886e-13, 3.9604e-13,\n",
       "             3.6114e-13],\n",
       "            [1.7801e-13, 3.3447e-13, 2.1450e-13,  ..., 2.3289e-13, 5.8341e-13,\n",
       "             3.5135e-13],\n",
       "            [3.2821e-13, 5.6772e-13, 3.8322e-13,  ..., 2.2080e-13, 7.1060e-13,\n",
       "             4.0069e-13]])},\n",
       "   'model.layers.6.self_attn.o_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 1.1011e-08, -6.2940e-08, -6.8175e-08,  ..., -4.6582e-07,\n",
       "              1.4108e-07,  2.5468e-07],\n",
       "            [ 1.8239e-07,  2.6778e-07,  1.9525e-07,  ...,  8.4162e-07,\n",
       "              2.8924e-07,  1.6460e-07],\n",
       "            [-4.0107e-07, -4.3526e-07,  1.6433e-07,  ..., -3.7174e-07,\n",
       "              1.3036e-06,  2.6702e-07],\n",
       "            ...,\n",
       "            [ 1.2099e-07, -6.8595e-08,  4.5857e-07,  ...,  8.2534e-07,\n",
       "             -9.8996e-07, -5.4172e-07],\n",
       "            [-5.5542e-07, -2.2960e-07,  1.1297e-08,  ..., -7.7391e-07,\n",
       "             -6.0813e-07, -1.1577e-06],\n",
       "            [-3.5034e-07, -1.8552e-07, -4.2418e-07,  ...,  5.5063e-07,\n",
       "             -2.1445e-07, -1.3596e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.9542e-12, 3.0970e-12, 2.7981e-12,  ..., 7.9694e-12, 8.3701e-12,\n",
       "             6.3824e-12],\n",
       "            [2.7597e-12, 2.8474e-12, 4.9789e-12,  ..., 4.6327e-12, 7.2083e-12,\n",
       "             7.9785e-12],\n",
       "            [2.0161e-12, 2.7235e-12, 2.8523e-12,  ..., 6.2888e-12, 7.5986e-12,\n",
       "             9.7980e-12],\n",
       "            ...,\n",
       "            [2.7946e-12, 3.6290e-12, 5.3392e-12,  ..., 8.6434e-12, 1.5948e-11,\n",
       "             9.6918e-12],\n",
       "            [2.8724e-12, 4.9937e-12, 2.8314e-12,  ..., 8.1588e-12, 6.4472e-12,\n",
       "             5.6174e-12],\n",
       "            [1.7114e-12, 3.3236e-12, 4.3744e-12,  ..., 6.3255e-12, 7.7258e-12,\n",
       "             6.3213e-12]])},\n",
       "   'model.layers.6.self_attn.q_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 2.0848e-07,  3.6064e-07,  1.3304e-06,  ...,  7.9925e-07,\n",
       "             4.8990e-07, -5.2405e-07]),\n",
       "    'exp_avg_sq': tensor([4.7856e-12, 6.7692e-12, 1.3138e-11,  ..., 9.5237e-12, 1.4382e-11,\n",
       "            6.6346e-12])},\n",
       "   'model.layers.6.self_attn.q_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-9.6783e-08, -2.0432e-07,  1.4015e-07,  ..., -7.6364e-08,\n",
       "              2.8872e-08, -1.8768e-07],\n",
       "            [-3.2175e-08,  4.6293e-08,  1.2366e-07,  ..., -1.0176e-08,\n",
       "              3.8672e-08, -3.5550e-08],\n",
       "            [ 2.2367e-07,  1.3309e-07,  2.9296e-07,  ..., -1.6809e-07,\n",
       "              1.7476e-07, -1.6473e-07],\n",
       "            ...,\n",
       "            [-1.1086e-07,  7.9053e-08,  4.0721e-08,  ..., -1.8927e-07,\n",
       "              8.1705e-08,  2.2104e-07],\n",
       "            [-4.2167e-08, -9.1106e-08,  4.9641e-08,  ..., -1.1444e-08,\n",
       "              1.1089e-07, -1.0717e-07],\n",
       "            [ 1.4713e-07,  6.6366e-08,  3.8821e-08,  ..., -5.0944e-08,\n",
       "              1.7158e-07, -2.8463e-08]]),\n",
       "    'exp_avg_sq': tensor([[2.1266e-13, 2.8700e-13, 2.2692e-13,  ..., 1.6920e-13, 2.6166e-13,\n",
       "             4.2529e-13],\n",
       "            [4.5566e-13, 2.0131e-13, 3.5881e-13,  ..., 2.5469e-13, 5.4550e-13,\n",
       "             4.6967e-13],\n",
       "            [4.9447e-13, 3.6408e-13, 5.2128e-13,  ..., 3.0454e-13, 4.8331e-13,\n",
       "             8.5967e-13],\n",
       "            ...,\n",
       "            [2.0524e-13, 2.6192e-13, 2.8752e-13,  ..., 2.7086e-13, 3.3695e-13,\n",
       "             3.5160e-13],\n",
       "            [3.4270e-13, 3.3449e-13, 2.7110e-13,  ..., 2.5574e-13, 4.7785e-13,\n",
       "             4.1135e-13],\n",
       "            [4.3384e-13, 2.5498e-13, 2.4955e-13,  ..., 1.7660e-13, 4.2054e-13,\n",
       "             2.9418e-13]])},\n",
       "   'model.layers.6.self_attn.v_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 2.8791e-06, -1.0767e-07,  3.4554e-06,  ...,  5.5179e-06,\n",
       "             4.3110e-06, -2.1397e-06]),\n",
       "    'exp_avg_sq': tensor([2.0035e-09, 1.1494e-09, 2.1461e-09,  ..., 2.0789e-09, 1.0947e-09,\n",
       "            2.0000e-09])},\n",
       "   'model.layers.6.self_attn.v_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 5.6070e-08, -1.5872e-07,  1.7997e-07,  ..., -1.7131e-07,\n",
       "             -4.9226e-07,  5.6160e-08],\n",
       "            [-3.1454e-07, -1.3322e-07,  5.7031e-08,  ...,  9.9622e-08,\n",
       "             -2.6652e-07,  5.0403e-07],\n",
       "            [-1.2808e-07,  3.5658e-07, -2.7833e-07,  ...,  1.2283e-07,\n",
       "              1.3960e-07,  2.6963e-07],\n",
       "            ...,\n",
       "            [-5.5167e-07, -1.9608e-07,  9.5774e-08,  ..., -5.8684e-07,\n",
       "              3.5893e-08, -5.0574e-07],\n",
       "            [ 3.8011e-07, -1.1137e-06, -4.3909e-07,  ...,  9.8790e-08,\n",
       "              7.5081e-07,  5.4706e-07],\n",
       "            [ 2.3605e-08,  3.2617e-07, -2.5209e-07,  ..., -1.2452e-06,\n",
       "              7.9723e-07,  4.0864e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.6110e-12, 2.0038e-12, 1.6234e-12,  ..., 9.2195e-13, 1.6517e-12,\n",
       "             2.0176e-12],\n",
       "            [2.7055e-12, 2.2623e-12, 2.2584e-12,  ..., 1.7617e-12, 1.9799e-12,\n",
       "             3.6709e-12],\n",
       "            [4.1805e-12, 2.3514e-12, 2.7034e-12,  ..., 3.6305e-12, 2.8930e-12,\n",
       "             3.4794e-12],\n",
       "            ...,\n",
       "            [3.2019e-12, 4.2111e-12, 4.2881e-12,  ..., 3.6390e-12, 3.8271e-12,\n",
       "             4.8313e-12],\n",
       "            [4.5855e-12, 4.8671e-12, 5.9967e-12,  ..., 3.2396e-12, 2.2043e-11,\n",
       "             8.2116e-12],\n",
       "            [5.5159e-12, 4.2898e-12, 6.2383e-12,  ..., 5.0558e-12, 1.4266e-11,\n",
       "             8.8796e-12]])},\n",
       "   'model.layers.7.input_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-6.7946e-06,  2.8349e-06, -7.8714e-06,  ...,  3.6008e-06,\n",
       "             3.4051e-06, -4.8850e-06]),\n",
       "    'exp_avg_sq': tensor([7.6453e-10, 3.1807e-10, 9.6866e-10,  ..., 3.5818e-10, 1.0950e-09,\n",
       "            5.0549e-10])},\n",
       "   'model.layers.7.mlp.down_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 2.4564e-07,  8.1397e-07, -4.3546e-07,  ..., -5.6984e-07,\n",
       "              2.8370e-07, -7.3904e-07],\n",
       "            [ 5.6323e-07, -3.2758e-07, -6.1617e-07,  ..., -7.7017e-07,\n",
       "              7.9775e-07,  1.2225e-07],\n",
       "            [ 5.8428e-07, -4.4860e-07,  2.2197e-07,  ...,  1.7132e-07,\n",
       "              3.9308e-07, -2.9032e-07],\n",
       "            ...,\n",
       "            [ 9.4429e-08, -5.8974e-07, -1.2809e-07,  ...,  9.2541e-07,\n",
       "             -4.0170e-07, -5.4262e-07],\n",
       "            [ 7.6934e-07,  4.8144e-07, -3.9284e-07,  ...,  2.9017e-07,\n",
       "             -1.0918e-07,  4.1410e-07],\n",
       "            [ 1.3371e-06,  1.8428e-07, -4.6954e-07,  ...,  5.3050e-07,\n",
       "              1.0395e-06, -8.9269e-07]]),\n",
       "    'exp_avg_sq': tensor([[4.5196e-12, 9.1755e-12, 5.1693e-12,  ..., 4.0019e-12, 7.1014e-12,\n",
       "             7.6589e-12],\n",
       "            [5.5464e-12, 1.3865e-11, 1.2281e-11,  ..., 5.9244e-12, 4.5859e-12,\n",
       "             3.6553e-12],\n",
       "            [4.7080e-12, 9.3318e-12, 5.2018e-12,  ..., 5.1738e-12, 1.0018e-11,\n",
       "             5.9881e-12],\n",
       "            ...,\n",
       "            [5.3567e-12, 8.1118e-12, 8.8516e-12,  ..., 6.2457e-12, 6.4422e-12,\n",
       "             5.7437e-12],\n",
       "            [8.2444e-12, 1.0840e-11, 9.9458e-12,  ..., 4.5913e-12, 7.3374e-12,\n",
       "             5.4187e-12],\n",
       "            [7.5866e-12, 6.6485e-12, 8.9868e-12,  ..., 3.4877e-12, 9.7256e-12,\n",
       "             6.5319e-12]])},\n",
       "   'model.layers.7.mlp.gate_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 2.8401e-07, -8.5625e-07, -6.5699e-07,  ...,  3.7940e-07,\n",
       "              5.1095e-07,  1.8172e-07],\n",
       "            [-6.5156e-07, -4.2790e-07,  1.7573e-09,  ..., -2.3233e-07,\n",
       "             -8.4324e-07, -1.3624e-07],\n",
       "            [ 5.9233e-07, -8.3248e-08, -2.6139e-08,  ..., -5.4420e-07,\n",
       "             -3.5186e-07, -1.6165e-07],\n",
       "            ...,\n",
       "            [ 7.5962e-08, -6.0957e-07, -3.4695e-07,  ...,  2.9031e-07,\n",
       "              2.7789e-07,  2.8491e-07],\n",
       "            [-4.9200e-07, -6.3227e-07, -8.5152e-07,  ...,  2.5411e-07,\n",
       "             -4.8223e-07,  8.2199e-07],\n",
       "            [-3.5736e-08,  8.7133e-07,  2.3867e-07,  ...,  7.7448e-08,\n",
       "              4.0014e-08,  3.5203e-07]]),\n",
       "    'exp_avg_sq': tensor([[3.5080e-12, 4.4218e-12, 2.5056e-12,  ..., 4.6261e-12, 4.7153e-12,\n",
       "             3.9910e-12],\n",
       "            [6.8089e-12, 7.4374e-12, 3.4880e-12,  ..., 6.7020e-12, 6.9176e-12,\n",
       "             6.1100e-12],\n",
       "            [3.7795e-12, 3.0565e-12, 3.9177e-12,  ..., 4.3272e-12, 4.3339e-12,\n",
       "             4.1862e-12],\n",
       "            ...,\n",
       "            [2.3847e-12, 1.1017e-11, 4.1962e-12,  ..., 4.9399e-12, 2.4843e-12,\n",
       "             6.1114e-12],\n",
       "            [6.2467e-12, 3.1826e-12, 3.6132e-12,  ..., 5.4655e-12, 6.4047e-12,\n",
       "             3.8256e-12],\n",
       "            [3.2000e-12, 4.7612e-12, 2.7120e-12,  ..., 4.1246e-12, 3.8338e-12,\n",
       "             3.3315e-12]])},\n",
       "   'model.layers.7.mlp.up_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-2.7775e-07, -1.3523e-07,  3.9032e-08,  ...,  4.0025e-07,\n",
       "              1.7829e-07, -7.1238e-07],\n",
       "            [-1.9429e-07,  1.2653e-07, -6.7169e-07,  ...,  2.7482e-07,\n",
       "             -4.8474e-07, -3.7187e-07],\n",
       "            [ 3.5733e-07, -7.4280e-07,  5.9735e-08,  ..., -2.9502e-07,\n",
       "              2.7597e-07,  1.9055e-07],\n",
       "            ...,\n",
       "            [-3.7546e-08, -8.3325e-07, -3.9228e-07,  ...,  4.6005e-07,\n",
       "              2.3194e-07, -3.8756e-08],\n",
       "            [-4.6281e-07, -8.1843e-08, -6.7113e-07,  ..., -1.3793e-06,\n",
       "              1.5311e-07, -3.0017e-07],\n",
       "            [ 1.7289e-07, -1.8539e-07,  4.3557e-07,  ..., -4.5247e-07,\n",
       "             -6.1058e-08, -4.9584e-07]]),\n",
       "    'exp_avg_sq': tensor([[4.3532e-12, 3.2015e-12, 3.1045e-12,  ..., 3.8395e-12, 3.6564e-12,\n",
       "             4.0732e-12],\n",
       "            [4.1537e-12, 6.2850e-12, 3.6125e-12,  ..., 7.5347e-12, 4.3204e-12,\n",
       "             6.5128e-12],\n",
       "            [3.8765e-12, 4.6827e-12, 3.3747e-12,  ..., 5.2617e-12, 3.5589e-12,\n",
       "             5.0198e-12],\n",
       "            ...,\n",
       "            [1.7075e-11, 1.9460e-11, 3.0252e-12,  ..., 3.2034e-12, 4.5264e-12,\n",
       "             4.6408e-12],\n",
       "            [6.0604e-12, 5.2510e-12, 4.6630e-12,  ..., 5.7241e-12, 3.2907e-12,\n",
       "             5.7230e-12],\n",
       "            [3.2525e-12, 2.9180e-12, 3.2143e-12,  ..., 3.6474e-12, 3.7658e-12,\n",
       "             3.9849e-12]])},\n",
       "   'model.layers.7.post_attention_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 1.0916e-05, -7.6973e-06,  5.0424e-06,  ..., -6.3516e-06,\n",
       "            -1.2413e-05, -4.2478e-06]),\n",
       "    'exp_avg_sq': tensor([1.1398e-09, 9.7740e-10, 9.2593e-10,  ..., 5.7135e-10, 8.9899e-10,\n",
       "            1.0595e-09])},\n",
       "   'model.layers.7.self_attn.k_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-3.5745e-07,  2.9722e-07,  3.9515e-07,  ..., -1.5722e-09,\n",
       "            -3.3488e-09, -6.3328e-10]),\n",
       "    'exp_avg_sq': tensor([3.9550e-11, 1.4428e-11, 9.3430e-12,  ..., 1.1145e-16, 1.6098e-16,\n",
       "            1.7687e-16])},\n",
       "   'model.layers.7.self_attn.k_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 1.8741e-07,  2.5836e-07, -1.1983e-07,  ..., -9.8057e-08,\n",
       "              1.4872e-07,  1.9523e-07],\n",
       "            [-3.0342e-07, -3.8023e-07, -2.2770e-08,  ...,  2.9756e-08,\n",
       "              3.5994e-08,  1.2641e-07],\n",
       "            [ 9.2335e-08,  1.9175e-07,  2.3488e-07,  ...,  4.8746e-08,\n",
       "             -1.0617e-07, -1.1855e-07],\n",
       "            ...,\n",
       "            [-2.4375e-07, -4.7249e-07, -1.0517e-07,  ...,  4.2827e-08,\n",
       "              1.6277e-07,  3.8057e-07],\n",
       "            [ 3.1060e-07,  3.9079e-07,  4.1812e-07,  ...,  1.3619e-07,\n",
       "              3.6354e-07, -7.1516e-08],\n",
       "            [ 2.0056e-07,  6.8454e-07, -6.9957e-07,  ...,  1.9092e-07,\n",
       "              2.6034e-07, -3.9981e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.5799e-12, 2.2660e-12, 1.4460e-12,  ..., 1.0702e-12, 2.1456e-12,\n",
       "             1.8251e-12],\n",
       "            [1.0920e-12, 1.0185e-12, 9.7573e-13,  ..., 5.1633e-13, 1.2157e-12,\n",
       "             1.3867e-12],\n",
       "            [4.5599e-13, 5.8255e-13, 1.0415e-12,  ..., 3.6881e-13, 5.7459e-13,\n",
       "             9.0165e-13],\n",
       "            ...,\n",
       "            [6.7866e-13, 1.4150e-12, 1.3779e-12,  ..., 7.7948e-13, 1.2443e-12,\n",
       "             2.5865e-12],\n",
       "            [1.8788e-12, 4.6498e-12, 3.1442e-12,  ..., 1.9980e-12, 1.8569e-12,\n",
       "             4.2913e-12],\n",
       "            [2.3666e-12, 8.9093e-12, 6.4361e-12,  ..., 2.1422e-12, 1.6713e-12,\n",
       "             3.3400e-12]])},\n",
       "   'model.layers.7.self_attn.o_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-6.9152e-08,  9.2773e-07,  5.3850e-07,  ..., -6.0918e-08,\n",
       "             -2.0807e-07, -1.0547e-06],\n",
       "            [-7.4112e-07, -4.5809e-07,  1.2957e-06,  ...,  4.1260e-07,\n",
       "              4.7412e-07, -6.1572e-07],\n",
       "            [ 3.9572e-07, -9.6833e-07,  1.9940e-07,  ..., -3.2675e-08,\n",
       "             -5.1117e-07, -4.5887e-07],\n",
       "            ...,\n",
       "            [-4.9409e-07, -5.2900e-07, -9.1052e-07,  ..., -2.8237e-07,\n",
       "             -2.6451e-08,  1.4001e-06],\n",
       "            [-6.0669e-07,  3.7310e-07, -5.2795e-07,  ..., -1.3460e-07,\n",
       "              5.7381e-07,  1.4867e-07],\n",
       "            [ 1.4872e-08,  2.9126e-07,  5.9267e-07,  ..., -4.0327e-07,\n",
       "              3.3060e-07, -1.1303e-06]]),\n",
       "    'exp_avg_sq': tensor([[4.1392e-12, 6.6435e-12, 5.3701e-12,  ..., 5.8686e-12, 2.9256e-12,\n",
       "             2.2819e-11],\n",
       "            [6.3170e-12, 9.1214e-12, 6.7298e-12,  ..., 5.1428e-12, 2.6578e-12,\n",
       "             3.1854e-11],\n",
       "            [4.2485e-12, 8.4228e-12, 6.4094e-12,  ..., 4.0652e-12, 2.5618e-12,\n",
       "             4.2634e-11],\n",
       "            ...,\n",
       "            [4.6117e-12, 1.1023e-11, 6.7642e-12,  ..., 5.7463e-12, 4.1189e-12,\n",
       "             3.6961e-11],\n",
       "            [4.4982e-12, 7.7234e-12, 5.1530e-12,  ..., 5.8158e-12, 2.9830e-12,\n",
       "             5.0746e-11],\n",
       "            [5.6319e-12, 1.0070e-11, 5.7551e-12,  ..., 4.5480e-12, 2.1683e-12,\n",
       "             1.7391e-11]])},\n",
       "   'model.layers.7.self_attn.q_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 1.6440e-06, -8.0149e-07, -1.6608e-06,  ...,  2.1143e-06,\n",
       "             1.3663e-06,  6.6160e-07]),\n",
       "    'exp_avg_sq': tensor([5.4893e-11, 2.9879e-11, 1.6826e-11,  ..., 1.1425e-10, 1.1636e-10,\n",
       "            8.7841e-11])},\n",
       "   'model.layers.7.self_attn.q_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-4.5632e-08,  3.1474e-07, -3.8312e-07,  ...,  2.0987e-07,\n",
       "              3.9403e-07, -5.7155e-07],\n",
       "            [ 2.0907e-07,  3.7209e-08,  2.9461e-07,  ..., -3.5351e-08,\n",
       "             -1.8312e-07, -1.1864e-09],\n",
       "            [-8.2173e-08, -7.4888e-08,  1.3748e-07,  ...,  7.8051e-08,\n",
       "              8.3656e-08, -1.0801e-07],\n",
       "            ...,\n",
       "            [-1.7471e-07, -9.5102e-08,  6.0452e-08,  ...,  7.9479e-08,\n",
       "              3.0694e-08,  1.5110e-07],\n",
       "            [ 1.7717e-07, -1.5383e-07,  2.4945e-07,  ..., -2.3407e-07,\n",
       "             -4.7668e-07,  5.1147e-07],\n",
       "            [ 2.9318e-07,  1.8172e-07, -4.2571e-08,  ...,  3.7209e-08,\n",
       "              8.7268e-08,  4.3814e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.5223e-12, 2.4407e-12, 2.5751e-12,  ..., 1.6576e-12, 2.6779e-12,\n",
       "             3.6186e-12],\n",
       "            [1.4741e-12, 1.4069e-12, 1.3576e-12,  ..., 1.1770e-12, 1.5402e-12,\n",
       "             1.8979e-12],\n",
       "            [7.3809e-13, 6.2198e-13, 1.0420e-12,  ..., 1.1623e-12, 6.2591e-13,\n",
       "             8.4461e-13],\n",
       "            ...,\n",
       "            [9.1772e-13, 2.2073e-12, 1.8897e-12,  ..., 8.2762e-13, 2.5515e-12,\n",
       "             1.3042e-12],\n",
       "            [1.3122e-12, 2.0006e-12, 2.6440e-12,  ..., 1.5849e-12, 2.5518e-12,\n",
       "             2.9484e-12],\n",
       "            [1.2831e-12, 2.2403e-12, 1.5329e-12,  ..., 1.1571e-12, 1.3649e-12,\n",
       "             1.6022e-12]])},\n",
       "   'model.layers.7.self_attn.v_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 4.4826e-06,  2.4079e-07, -1.3719e-05,  ...,  2.0954e-05,\n",
       "            -5.5832e-06, -1.9821e-05]),\n",
       "    'exp_avg_sq': tensor([2.0856e-09, 1.6557e-09, 2.7661e-09,  ..., 2.1550e-09, 1.5194e-09,\n",
       "            5.8178e-09])},\n",
       "   'model.layers.7.self_attn.v_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 3.9972e-07,  2.7837e-07,  8.0114e-07,  ...,  5.1429e-08,\n",
       "              5.1253e-08,  2.5585e-07],\n",
       "            [ 3.4872e-07,  3.7587e-07, -7.5749e-07,  ...,  1.0266e-06,\n",
       "              3.3611e-07, -4.8915e-07],\n",
       "            [ 8.9319e-07,  2.5528e-07,  1.4264e-07,  ...,  5.1114e-09,\n",
       "              2.7205e-07,  4.9113e-08],\n",
       "            ...,\n",
       "            [-2.0495e-07,  5.5504e-07, -3.5733e-07,  ..., -6.3928e-07,\n",
       "              6.4672e-08,  3.4536e-07],\n",
       "            [ 4.3622e-07, -1.8371e-07,  2.3810e-07,  ...,  2.2931e-07,\n",
       "             -3.4961e-08, -3.3813e-07],\n",
       "            [ 6.0325e-07, -2.1026e-07,  4.6255e-07,  ..., -2.3319e-07,\n",
       "             -2.3400e-07,  1.5595e-06]]),\n",
       "    'exp_avg_sq': tensor([[7.2928e-12, 3.9529e-12, 6.0258e-12,  ..., 2.6963e-12, 6.7928e-12,\n",
       "             8.3294e-12],\n",
       "            [4.9543e-12, 5.4487e-12, 5.3620e-12,  ..., 4.5897e-12, 4.0233e-12,\n",
       "             1.0042e-11],\n",
       "            [6.6663e-12, 4.2092e-12, 5.2914e-12,  ..., 3.9535e-12, 5.7117e-12,\n",
       "             7.2341e-12],\n",
       "            ...,\n",
       "            [3.5734e-12, 4.2108e-12, 2.8260e-12,  ..., 3.0708e-12, 3.8431e-12,\n",
       "             3.3225e-12],\n",
       "            [3.0722e-12, 3.2088e-12, 2.9948e-12,  ..., 1.3647e-12, 1.4972e-12,\n",
       "             1.7689e-12],\n",
       "            [1.3189e-11, 1.3303e-11, 1.6939e-11,  ..., 1.3308e-11, 7.1678e-12,\n",
       "             1.9536e-11]])},\n",
       "   'model.layers.8.input_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 9.8352e-07,  8.0493e-06,  4.2985e-06,  ...,  2.0586e-06,\n",
       "             1.1527e-05, -1.6272e-06]),\n",
       "    'exp_avg_sq': tensor([7.7206e-10, 6.9974e-10, 8.3744e-10,  ..., 6.0570e-10, 1.1419e-09,\n",
       "            8.8893e-10])},\n",
       "   'model.layers.8.mlp.down_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-9.8845e-07, -6.4801e-07, -7.9059e-08,  ..., -1.7529e-07,\n",
       "             -2.5142e-07,  1.0767e-06],\n",
       "            [ 3.8971e-07,  5.5112e-07, -2.2900e-07,  ...,  3.6108e-07,\n",
       "             -7.8622e-08, -8.0192e-08],\n",
       "            [ 2.5176e-07, -9.9577e-08, -1.3200e-06,  ...,  3.8235e-07,\n",
       "             -8.8650e-07,  4.2835e-07],\n",
       "            ...,\n",
       "            [-6.6985e-07,  5.6318e-07, -1.0164e-06,  ...,  3.1278e-07,\n",
       "             -5.5874e-08, -7.9511e-07],\n",
       "            [-3.7950e-07, -8.2539e-07, -1.0184e-06,  ..., -7.8490e-07,\n",
       "              7.5704e-07, -8.1203e-07],\n",
       "            [-1.1263e-06,  2.9930e-08, -6.3252e-07,  ...,  3.4613e-08,\n",
       "             -2.6842e-07,  5.6245e-07]]),\n",
       "    'exp_avg_sq': tensor([[5.3021e-12, 4.5879e-12, 7.0044e-12,  ..., 5.3142e-12, 6.4434e-12,\n",
       "             7.5148e-12],\n",
       "            [3.8466e-12, 6.7553e-12, 6.2613e-12,  ..., 6.5277e-12, 7.2486e-12,\n",
       "             8.6746e-12],\n",
       "            [6.0907e-12, 4.0501e-12, 5.3927e-12,  ..., 4.1649e-12, 5.2140e-12,\n",
       "             7.7240e-12],\n",
       "            ...,\n",
       "            [7.8066e-12, 4.1093e-12, 7.9061e-12,  ..., 3.6708e-12, 6.3834e-12,\n",
       "             7.4302e-12],\n",
       "            [4.8741e-12, 6.7022e-12, 8.7261e-12,  ..., 1.0231e-11, 6.3039e-12,\n",
       "             6.2446e-12],\n",
       "            [8.2190e-12, 4.0269e-12, 9.9232e-12,  ..., 6.5591e-12, 6.6986e-12,\n",
       "             5.8900e-12]])},\n",
       "   'model.layers.8.mlp.gate_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-2.9267e-07,  6.0255e-07,  3.0711e-07,  ..., -7.0101e-07,\n",
       "             -4.6894e-07,  8.8439e-08],\n",
       "            [-2.7887e-07, -3.5025e-07,  5.0473e-07,  ..., -3.7077e-07,\n",
       "             -5.7937e-07,  1.0946e-07],\n",
       "            [-6.3462e-07, -1.1412e-06,  8.4761e-07,  ..., -2.2842e-07,\n",
       "             -5.2013e-07, -2.8238e-07],\n",
       "            ...,\n",
       "            [-3.3716e-07,  9.5199e-07, -7.3550e-08,  ..., -5.0197e-07,\n",
       "              3.3453e-07, -8.0502e-07],\n",
       "            [ 3.5834e-07,  1.0513e-07, -2.2954e-07,  ..., -7.2656e-08,\n",
       "             -1.3586e-07,  1.2146e-08],\n",
       "            [-6.0580e-07, -1.2089e-07, -9.3099e-08,  ..., -2.7979e-07,\n",
       "              1.1101e-06,  1.8416e-07]]),\n",
       "    'exp_avg_sq': tensor([[3.1397e-12, 2.9961e-12, 3.2917e-12,  ..., 4.0093e-12, 4.6042e-12,\n",
       "             3.4871e-12],\n",
       "            [5.3299e-12, 2.7294e-12, 4.8956e-12,  ..., 3.5168e-12, 4.5027e-12,\n",
       "             3.6378e-12],\n",
       "            [1.0443e-11, 5.8465e-12, 4.9414e-12,  ..., 6.5136e-12, 5.8571e-12,\n",
       "             3.1457e-12],\n",
       "            ...,\n",
       "            [5.0575e-12, 4.0571e-12, 4.0898e-12,  ..., 8.0401e-12, 3.5232e-12,\n",
       "             5.1376e-12],\n",
       "            [3.6116e-12, 3.8883e-12, 2.7366e-12,  ..., 5.6904e-12, 6.1521e-12,\n",
       "             4.5693e-12],\n",
       "            [5.5934e-12, 3.6550e-12, 3.3325e-12,  ..., 3.6784e-12, 5.6117e-12,\n",
       "             4.1855e-12]])},\n",
       "   'model.layers.8.mlp.up_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-8.5264e-08,  3.2517e-07, -8.2820e-07,  ..., -4.3687e-07,\n",
       "             -1.6915e-07, -4.5306e-09],\n",
       "            [-4.8067e-07,  7.5941e-07,  3.2503e-07,  ...,  3.9516e-08,\n",
       "             -5.3538e-07,  1.7484e-07],\n",
       "            [-1.2170e-07, -2.0561e-08, -1.9942e-07,  ...,  2.7020e-07,\n",
       "              1.5640e-07,  5.6269e-07],\n",
       "            ...,\n",
       "            [-1.9409e-08,  3.4275e-07,  2.9032e-07,  ...,  2.0222e-07,\n",
       "              6.7695e-08,  8.6402e-07],\n",
       "            [ 3.6632e-07, -5.3839e-07,  4.7237e-07,  ..., -5.3267e-07,\n",
       "              1.2304e-07,  2.7442e-07],\n",
       "            [ 9.8215e-07,  7.3691e-08,  1.1647e-07,  ...,  2.0305e-07,\n",
       "             -9.2571e-08, -2.9297e-07]]),\n",
       "    'exp_avg_sq': tensor([[2.4630e-12, 2.6264e-12, 2.6224e-12,  ..., 4.8880e-12, 6.1709e-12,\n",
       "             3.7716e-12],\n",
       "            [3.8253e-12, 3.0996e-12, 3.1270e-12,  ..., 4.3825e-12, 5.2256e-12,\n",
       "             3.1261e-12],\n",
       "            [5.3706e-12, 5.8462e-12, 4.7368e-12,  ..., 6.3761e-12, 4.2313e-12,\n",
       "             3.2435e-12],\n",
       "            ...,\n",
       "            [3.4315e-12, 2.9498e-12, 2.4456e-12,  ..., 3.8670e-12, 4.3444e-12,\n",
       "             6.4134e-12],\n",
       "            [4.3219e-12, 2.3462e-12, 3.1315e-12,  ..., 3.4405e-12, 5.4360e-12,\n",
       "             3.4348e-12],\n",
       "            [9.6127e-12, 6.1597e-12, 4.0588e-12,  ..., 4.2036e-12, 5.7360e-12,\n",
       "             3.5823e-12]])},\n",
       "   'model.layers.8.post_attention_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 2.2926e-06,  5.3455e-06,  2.9973e-08,  ..., -9.7294e-06,\n",
       "             5.0502e-06,  6.1061e-06]),\n",
       "    'exp_avg_sq': tensor([4.1933e-10, 6.2901e-10, 8.3234e-10,  ..., 8.2623e-10, 7.8740e-10,\n",
       "            8.4961e-10])},\n",
       "   'model.layers.8.self_attn.k_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-1.0861e-06,  5.4906e-07,  2.7737e-07,  ...,  9.4610e-10,\n",
       "            -5.7711e-10,  1.5717e-09]),\n",
       "    'exp_avg_sq': tensor([8.9956e-12, 8.5775e-12, 9.7337e-12,  ..., 1.0785e-16, 7.7318e-17,\n",
       "            5.4159e-17])},\n",
       "   'model.layers.8.self_attn.k_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 6.4543e-08,  7.7091e-08, -1.9625e-07,  ...,  1.8948e-09,\n",
       "              3.4365e-07, -1.0254e-07],\n",
       "            [ 9.7665e-09, -9.5460e-08, -1.6912e-07,  ...,  1.1831e-07,\n",
       "             -2.3006e-07, -5.5386e-08],\n",
       "            [-2.0083e-07, -1.0482e-07,  9.4610e-08,  ..., -1.5872e-07,\n",
       "             -1.5828e-07, -1.4826e-07],\n",
       "            ...,\n",
       "            [ 1.1627e-07,  5.9857e-08,  1.6017e-07,  ...,  1.3768e-07,\n",
       "              1.6408e-07, -2.7714e-07],\n",
       "            [-1.0847e-07, -1.7098e-07,  1.4697e-07,  ...,  9.4454e-08,\n",
       "             -3.4428e-07, -2.4036e-08],\n",
       "            [-1.2682e-07, -2.8796e-07, -5.4263e-08,  ..., -1.3206e-08,\n",
       "              2.3723e-07,  4.0796e-07]]),\n",
       "    'exp_avg_sq': tensor([[3.7532e-13, 4.0096e-13, 6.5982e-13,  ..., 3.1710e-13, 5.8401e-13,\n",
       "             5.7016e-13],\n",
       "            [2.7953e-13, 3.0221e-13, 6.2355e-13,  ..., 2.8143e-13, 4.7926e-13,\n",
       "             5.6952e-13],\n",
       "            [8.6123e-13, 8.4881e-13, 8.1113e-13,  ..., 6.9193e-13, 9.0196e-13,\n",
       "             1.4616e-12],\n",
       "            ...,\n",
       "            [5.9348e-13, 5.6450e-13, 5.7640e-13,  ..., 3.9441e-13, 4.5490e-13,\n",
       "             6.6694e-13],\n",
       "            [8.1786e-13, 6.3369e-13, 8.7425e-13,  ..., 7.0706e-13, 5.6614e-13,\n",
       "             7.5250e-13],\n",
       "            [1.3852e-12, 4.3913e-13, 1.2077e-12,  ..., 6.8800e-13, 6.0733e-13,\n",
       "             8.2515e-13]])},\n",
       "   'model.layers.8.self_attn.o_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 4.1252e-07, -5.8160e-07,  2.1711e-08,  ..., -2.0724e-08,\n",
       "             -1.3435e-06,  9.4892e-07],\n",
       "            [ 6.4074e-07,  1.7583e-07,  1.9664e-07,  ..., -3.5206e-07,\n",
       "             -2.8522e-08, -2.3223e-07],\n",
       "            [ 3.0377e-08,  9.7095e-08,  4.9689e-07,  ..., -2.2989e-07,\n",
       "              1.8780e-06, -2.2346e-07],\n",
       "            ...,\n",
       "            [-3.2028e-07, -1.0315e-07,  1.1945e-06,  ..., -2.7275e-07,\n",
       "             -1.7878e-07,  3.2658e-07],\n",
       "            [-7.0294e-07, -8.9134e-07, -2.1253e-07,  ...,  6.0585e-07,\n",
       "              8.2894e-07, -9.3503e-07],\n",
       "            [-3.7661e-07, -3.6129e-07, -3.9829e-07,  ...,  7.4514e-07,\n",
       "             -7.1661e-07,  3.0182e-07]]),\n",
       "    'exp_avg_sq': tensor([[7.4950e-12, 9.3433e-12, 7.1245e-12,  ..., 9.0818e-12, 1.1610e-11,\n",
       "             7.4223e-12],\n",
       "            [5.1585e-12, 8.0550e-12, 6.9686e-12,  ..., 1.1453e-11, 8.7575e-12,\n",
       "             6.5996e-12],\n",
       "            [6.6963e-12, 4.8723e-12, 6.8133e-12,  ..., 1.0592e-11, 1.2137e-11,\n",
       "             7.7415e-12],\n",
       "            ...,\n",
       "            [6.7727e-12, 7.5338e-12, 7.2145e-12,  ..., 8.8800e-12, 1.0849e-11,\n",
       "             7.0002e-12],\n",
       "            [8.6439e-12, 1.0080e-11, 9.4796e-12,  ..., 8.8898e-12, 1.1727e-11,\n",
       "             6.8483e-12],\n",
       "            [1.0245e-11, 7.2791e-12, 7.6251e-12,  ..., 8.9340e-12, 1.0901e-11,\n",
       "             7.9089e-12]])},\n",
       "   'model.layers.8.self_attn.q_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-1.1103e-06, -4.5845e-07,  3.0494e-07,  ...,  4.8387e-07,\n",
       "             2.3995e-07,  4.4663e-07]),\n",
       "    'exp_avg_sq': tensor([1.6225e-11, 7.8742e-12, 2.1214e-11,  ..., 1.6320e-11, 2.3293e-11,\n",
       "            2.0680e-11])},\n",
       "   'model.layers.8.self_attn.q_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 3.5228e-08,  8.6050e-10,  2.2265e-07,  ..., -4.8529e-08,\n",
       "              2.1080e-07, -3.9832e-07],\n",
       "            [ 9.3662e-08,  7.2836e-08,  4.3104e-08,  ...,  7.9932e-08,\n",
       "              1.6518e-07,  1.0646e-07],\n",
       "            [-1.6566e-08,  7.4219e-08,  2.1519e-07,  ..., -1.1178e-07,\n",
       "             -5.8791e-08, -2.5774e-07],\n",
       "            ...,\n",
       "            [-1.2252e-07,  1.8064e-07,  1.1095e-07,  ..., -2.0860e-07,\n",
       "             -4.6030e-09, -5.6494e-07],\n",
       "            [ 1.3188e-07, -1.2099e-08,  2.3159e-07,  ...,  7.3744e-08,\n",
       "              4.8208e-08,  2.1099e-07],\n",
       "            [-2.2176e-08,  3.7933e-07,  6.1018e-08,  ...,  1.9812e-07,\n",
       "             -1.0550e-07,  1.9832e-07]]),\n",
       "    'exp_avg_sq': tensor([[7.4251e-13, 9.4405e-13, 8.4563e-13,  ..., 8.2353e-13, 1.0476e-12,\n",
       "             1.0233e-12],\n",
       "            [2.7412e-13, 5.1960e-13, 6.0422e-13,  ..., 5.2084e-13, 6.2061e-13,\n",
       "             7.3821e-13],\n",
       "            [1.6191e-12, 1.0043e-12, 1.7235e-12,  ..., 7.6286e-13, 8.3448e-13,\n",
       "             1.8296e-12],\n",
       "            ...,\n",
       "            [6.4342e-13, 4.9125e-13, 9.5510e-13,  ..., 6.1403e-13, 6.1152e-13,\n",
       "             1.2685e-12],\n",
       "            [8.5503e-13, 4.7180e-13, 1.1545e-12,  ..., 5.8248e-13, 1.0455e-12,\n",
       "             1.1438e-12],\n",
       "            [6.6431e-13, 7.3201e-13, 8.0609e-13,  ..., 4.4891e-13, 6.3552e-13,\n",
       "             7.3978e-13]])},\n",
       "   'model.layers.8.self_attn.v_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-1.0682e-05,  4.0897e-06, -6.5848e-06,  ...,  5.1555e-06,\n",
       "            -9.5490e-07, -7.3739e-06]),\n",
       "    'exp_avg_sq': tensor([1.3779e-09, 1.0121e-09, 1.6023e-09,  ..., 1.5153e-09, 1.8742e-09,\n",
       "            1.8109e-09])},\n",
       "   'model.layers.8.self_attn.v_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 3.0655e-07, -3.0492e-07,  3.5725e-07,  ..., -4.5562e-07,\n",
       "             -1.7098e-07,  7.5795e-07],\n",
       "            [ 7.1814e-07,  6.2828e-07,  1.7391e-07,  ..., -6.8902e-07,\n",
       "             -9.9992e-08,  4.8281e-08],\n",
       "            [-2.7223e-07, -6.9960e-08, -1.0056e-06,  ..., -1.9869e-07,\n",
       "              1.0292e-07,  2.2098e-07],\n",
       "            ...,\n",
       "            [-2.4921e-07,  1.0897e-06,  2.5968e-07,  ..., -6.7562e-07,\n",
       "             -1.1613e-07, -6.1368e-08],\n",
       "            [-6.8634e-07, -3.9316e-07, -6.5449e-07,  ..., -2.0922e-07,\n",
       "             -3.1691e-07, -6.2392e-07],\n",
       "            [ 3.0649e-07, -3.0308e-07, -4.0738e-07,  ...,  4.5423e-07,\n",
       "              4.4462e-07, -9.1971e-07]]),\n",
       "    'exp_avg_sq': tensor([[3.8532e-12, 4.3419e-12, 6.4140e-12,  ..., 4.0154e-12, 3.3544e-12,\n",
       "             5.2617e-12],\n",
       "            [3.7366e-12, 3.4681e-12, 3.7436e-12,  ..., 3.6101e-12, 4.8307e-12,\n",
       "             4.5964e-12],\n",
       "            [3.8161e-12, 3.8311e-12, 3.7241e-12,  ..., 3.2408e-12, 3.3470e-12,\n",
       "             4.1673e-12],\n",
       "            ...,\n",
       "            [1.2582e-11, 1.0137e-11, 1.3442e-11,  ..., 7.5964e-12, 1.0121e-11,\n",
       "             1.0492e-11],\n",
       "            [1.3805e-11, 1.0740e-11, 1.0441e-11,  ..., 5.7843e-12, 5.5148e-12,\n",
       "             1.1691e-11],\n",
       "            [8.5220e-12, 8.7798e-12, 8.4074e-12,  ..., 8.0025e-12, 6.1737e-12,\n",
       "             5.5360e-12]])},\n",
       "   'model.layers.9.input_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 8.9180e-06,  6.7910e-06, -4.9366e-06,  ..., -5.1579e-06,\n",
       "             7.3695e-06, -1.7612e-07]),\n",
       "    'exp_avg_sq': tensor([1.0413e-09, 1.0685e-09, 1.4451e-09,  ..., 6.8957e-10, 8.6923e-10,\n",
       "            6.1830e-10])},\n",
       "   'model.layers.9.mlp.down_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-9.0670e-07, -3.0435e-07,  2.9605e-08,  ..., -3.7514e-07,\n",
       "             -8.7125e-08,  1.6003e-07],\n",
       "            [ 3.6805e-07, -6.7497e-08,  1.8932e-08,  ..., -2.4860e-07,\n",
       "              1.0261e-06, -1.3241e-07],\n",
       "            [ 5.8913e-07, -1.4355e-07, -4.0028e-07,  ..., -2.6669e-07,\n",
       "              1.6076e-07,  1.5500e-07],\n",
       "            ...,\n",
       "            [ 4.3670e-07, -3.5593e-08,  1.7296e-07,  ..., -2.9962e-07,\n",
       "             -1.0990e-07, -4.0173e-07],\n",
       "            [ 1.6315e-07, -7.7274e-08, -7.7787e-07,  ..., -3.2931e-07,\n",
       "             -2.5936e-07,  6.8936e-07],\n",
       "            [-4.8339e-07,  1.5423e-07,  1.0633e-07,  ..., -3.9480e-07,\n",
       "              1.4839e-07, -6.8180e-07]]),\n",
       "    'exp_avg_sq': tensor([[5.0073e-12, 5.4905e-12, 3.3325e-12,  ..., 6.7443e-12, 3.3837e-12,\n",
       "             2.9705e-12],\n",
       "            [4.4109e-12, 3.0045e-12, 3.7432e-12,  ..., 3.6203e-12, 4.7796e-12,\n",
       "             5.1571e-12],\n",
       "            [5.2349e-12, 4.1420e-12, 3.7075e-12,  ..., 5.2051e-12, 5.1557e-12,\n",
       "             6.5708e-12],\n",
       "            ...,\n",
       "            [3.7981e-12, 3.0438e-12, 4.2306e-12,  ..., 6.0830e-12, 6.2730e-12,\n",
       "             6.0058e-12],\n",
       "            [4.1520e-12, 3.7639e-12, 4.4511e-12,  ..., 4.6072e-12, 4.5082e-12,\n",
       "             6.5286e-12],\n",
       "            [5.9098e-12, 3.9467e-12, 4.7554e-12,  ..., 3.9285e-12, 3.5262e-12,\n",
       "             4.6908e-12]])},\n",
       "   'model.layers.9.mlp.gate_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-1.7086e-07,  3.5012e-07,  1.8129e-07,  ...,  2.0842e-07,\n",
       "              5.5092e-08, -2.2705e-07],\n",
       "            [ 1.7476e-07, -1.6328e-07,  4.7605e-07,  ..., -1.6116e-07,\n",
       "              3.9093e-07,  7.8079e-07],\n",
       "            [-4.8878e-08,  1.2417e-07,  3.0671e-07,  ..., -3.1514e-09,\n",
       "             -8.2938e-07, -1.4618e-07],\n",
       "            ...,\n",
       "            [-1.2194e-07, -5.1840e-07, -1.1984e-07,  ..., -1.9927e-07,\n",
       "              1.4916e-06, -2.5537e-07],\n",
       "            [ 5.7952e-07, -5.9104e-08,  3.0996e-07,  ..., -4.1257e-07,\n",
       "              5.2303e-07,  2.6589e-08],\n",
       "            [ 2.4161e-07, -2.8921e-07, -1.9194e-07,  ...,  7.4050e-07,\n",
       "              1.0996e-06,  3.0807e-07]]),\n",
       "    'exp_avg_sq': tensor([[4.3140e-12, 2.9860e-12, 3.1857e-12,  ..., 3.3262e-12, 4.2234e-12,\n",
       "             2.5637e-12],\n",
       "            [3.6494e-12, 4.0011e-12, 2.1295e-12,  ..., 3.8232e-12, 4.2800e-12,\n",
       "             3.2873e-12],\n",
       "            [2.3821e-12, 2.5097e-12, 1.5687e-12,  ..., 2.7089e-12, 2.6047e-12,\n",
       "             2.2480e-12],\n",
       "            ...,\n",
       "            [2.9502e-12, 2.9619e-12, 3.3923e-12,  ..., 4.6160e-12, 5.0238e-12,\n",
       "             4.1941e-12],\n",
       "            [3.2430e-12, 3.6462e-12, 4.5801e-12,  ..., 3.8304e-12, 6.5812e-12,\n",
       "             3.2071e-12],\n",
       "            [6.7416e-12, 3.1890e-12, 3.6019e-12,  ..., 6.9678e-12, 1.0417e-11,\n",
       "             4.3424e-12]])},\n",
       "   'model.layers.9.mlp.up_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-8.5379e-08,  4.7111e-08,  7.3621e-07,  ...,  4.7173e-07,\n",
       "              2.2131e-07,  1.4053e-07],\n",
       "            [-4.1299e-07,  4.5321e-07, -2.9829e-07,  ..., -5.1995e-08,\n",
       "             -5.3530e-07, -2.3703e-07],\n",
       "            [-2.6066e-08, -4.9413e-08,  1.0713e-07,  ..., -3.5664e-08,\n",
       "              4.0648e-07,  3.9076e-07],\n",
       "            ...,\n",
       "            [ 3.9929e-07,  2.7669e-07,  4.3843e-07,  ...,  1.8177e-07,\n",
       "             -5.4160e-07,  4.0249e-07],\n",
       "            [ 1.1932e-07,  3.2983e-07,  2.7190e-07,  ..., -5.3890e-08,\n",
       "             -6.7445e-09,  7.8139e-07],\n",
       "            [-1.0528e-07,  2.9727e-08,  2.6201e-07,  ..., -2.7904e-07,\n",
       "              7.5247e-07,  2.0761e-07]]),\n",
       "    'exp_avg_sq': tensor([[3.2551e-12, 2.6616e-12, 2.5353e-12,  ..., 3.2934e-12, 3.3432e-12,\n",
       "             2.0586e-12],\n",
       "            [2.8466e-12, 3.4751e-12, 2.3874e-12,  ..., 3.6357e-12, 2.2587e-12,\n",
       "             3.0949e-12],\n",
       "            [1.5932e-12, 2.1619e-12, 1.6517e-12,  ..., 1.7981e-12, 1.5005e-12,\n",
       "             1.7249e-12],\n",
       "            ...,\n",
       "            [4.9969e-12, 3.4913e-12, 2.2723e-12,  ..., 2.1749e-12, 4.5686e-12,\n",
       "             2.2051e-12],\n",
       "            [2.7868e-12, 4.5574e-12, 2.4878e-12,  ..., 2.5866e-12, 4.9070e-12,\n",
       "             3.9176e-12],\n",
       "            [3.7692e-12, 3.2646e-12, 1.4691e-12,  ..., 3.7329e-12, 4.7433e-12,\n",
       "             3.6050e-12]])},\n",
       "   'model.layers.9.post_attention_layernorm.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([-2.5887e-06, -1.7091e-06,  7.1365e-06,  ..., -3.1157e-06,\n",
       "            -9.4387e-07, -7.6657e-06]),\n",
       "    'exp_avg_sq': tensor([1.1917e-09, 1.6038e-09, 6.9533e-10,  ..., 7.1543e-10, 8.7047e-10,\n",
       "            8.9771e-10])},\n",
       "   'model.layers.9.self_attn.k_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 9.9883e-11, -2.2132e-07, -3.3621e-08,  ..., -8.0082e-09,\n",
       "            -3.5958e-09,  2.8885e-09]),\n",
       "    'exp_avg_sq': tensor([6.6363e-11, 4.4158e-11, 1.0153e-11,  ..., 3.0267e-16, 2.4015e-16,\n",
       "            2.7366e-16])},\n",
       "   'model.layers.9.self_attn.k_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 3.3403e-07,  3.2515e-07,  3.8346e-08,  ...,  5.4668e-07,\n",
       "             -3.2142e-07, -3.5777e-07],\n",
       "            [ 4.0913e-08, -2.2719e-07, -5.5067e-08,  ..., -5.7369e-07,\n",
       "             -1.8456e-07,  1.1995e-07],\n",
       "            [ 1.9654e-08, -1.5202e-07, -3.8547e-08,  ..., -1.6047e-07,\n",
       "             -2.5715e-07,  3.0709e-07],\n",
       "            ...,\n",
       "            [-3.0203e-07, -1.0210e-07, -3.7459e-08,  ..., -2.0670e-07,\n",
       "             -1.6083e-07,  9.9764e-08],\n",
       "            [-1.1266e-07, -4.4067e-07,  1.0127e-07,  ...,  6.1446e-09,\n",
       "              2.7373e-07, -2.9511e-07],\n",
       "            [ 2.7303e-08,  6.2998e-08, -1.2546e-07,  ...,  2.6826e-07,\n",
       "             -1.1105e-07, -3.1607e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.6516e-12, 2.3765e-12, 1.6627e-12,  ..., 1.7377e-12, 1.5286e-12,\n",
       "             1.2653e-12],\n",
       "            [1.0601e-12, 1.3257e-12, 8.7650e-13,  ..., 1.2742e-12, 1.0140e-12,\n",
       "             1.0454e-12],\n",
       "            [6.2231e-13, 9.6991e-13, 5.4315e-13,  ..., 7.6096e-13, 7.6010e-13,\n",
       "             9.9998e-13],\n",
       "            ...,\n",
       "            [1.1163e-12, 1.0398e-12, 8.6181e-13,  ..., 5.2185e-13, 7.0916e-13,\n",
       "             7.8885e-13],\n",
       "            [5.6605e-13, 1.4943e-12, 7.5568e-13,  ..., 5.1039e-13, 1.0297e-12,\n",
       "             1.3519e-12],\n",
       "            [7.6786e-13, 7.6044e-13, 7.5034e-13,  ..., 7.2193e-13, 9.9203e-13,\n",
       "             9.3943e-13]])},\n",
       "   'model.layers.9.self_attn.o_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 6.6698e-07, -6.7662e-07,  3.2691e-07,  ...,  4.7868e-07,\n",
       "             -2.0785e-06,  1.5603e-07],\n",
       "            [ 1.0541e-06,  5.7084e-07, -1.4659e-06,  ..., -8.9989e-08,\n",
       "              1.0536e-07,  3.1958e-07],\n",
       "            [ 1.9812e-07, -9.7221e-09,  2.2562e-07,  ..., -2.6948e-07,\n",
       "             -1.6313e-07, -9.5327e-08],\n",
       "            ...,\n",
       "            [ 1.6134e-07,  3.7685e-07,  3.4713e-07,  ..., -4.0733e-07,\n",
       "              9.3733e-07,  1.3989e-06],\n",
       "            [-1.0229e-06, -9.8242e-08,  3.4336e-06,  ..., -6.0465e-07,\n",
       "              1.5756e-06,  6.7898e-07],\n",
       "            [ 9.1447e-07, -3.2903e-07, -7.7414e-07,  ...,  1.2725e-07,\n",
       "             -5.3484e-07,  6.3440e-07]]),\n",
       "    'exp_avg_sq': tensor([[8.0047e-12, 1.3051e-11, 1.6882e-11,  ..., 1.3672e-11, 2.2368e-11,\n",
       "             1.7494e-11],\n",
       "            [1.5654e-11, 1.8657e-11, 2.1310e-11,  ..., 1.7122e-11, 2.5076e-11,\n",
       "             2.1511e-11],\n",
       "            [1.1712e-11, 1.1504e-11, 1.1273e-11,  ..., 1.6336e-11, 1.8871e-11,\n",
       "             1.7143e-11],\n",
       "            ...,\n",
       "            [1.1011e-11, 1.5488e-11, 1.9902e-11,  ..., 2.1135e-11, 3.1200e-11,\n",
       "             1.8947e-11],\n",
       "            [1.1662e-11, 1.4849e-11, 2.5121e-11,  ..., 2.2371e-11, 2.1140e-11,\n",
       "             1.8574e-11],\n",
       "            [8.7900e-12, 1.4234e-11, 1.1323e-11,  ..., 1.5337e-11, 2.3612e-11,\n",
       "             2.3745e-11]])},\n",
       "   'model.layers.9.self_attn.q_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 8.0417e-07,  3.2039e-07, -4.9544e-07,  ...,  8.0391e-08,\n",
       "            -1.9665e-06,  1.8562e-06]),\n",
       "    'exp_avg_sq': tensor([2.9386e-11, 3.8969e-11, 1.1810e-11,  ..., 2.6099e-11, 4.2653e-11,\n",
       "            2.2083e-11])},\n",
       "   'model.layers.9.self_attn.q_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[-5.4441e-08,  3.3697e-07, -2.9216e-08,  ..., -5.2743e-08,\n",
       "             -2.9622e-07, -8.8256e-08],\n",
       "            [ 8.0824e-08, -1.3257e-07,  3.7481e-08,  ..., -2.8428e-07,\n",
       "             -8.6180e-08,  5.5316e-07],\n",
       "            [ 1.5007e-08,  1.2652e-07,  6.2047e-08,  ..., -1.2148e-09,\n",
       "             -8.6897e-08, -1.7383e-07],\n",
       "            ...,\n",
       "            [-1.7223e-08, -1.9555e-07,  9.6791e-08,  ..., -1.3676e-08,\n",
       "              1.3506e-07,  1.4547e-07],\n",
       "            [ 3.8436e-07,  3.1522e-09,  5.1076e-08,  ..., -1.7656e-07,\n",
       "             -1.1380e-07,  3.2938e-07],\n",
       "            [-7.6228e-07, -3.5541e-07,  7.8510e-08,  ..., -2.7811e-07,\n",
       "              4.2217e-07, -1.2064e-07]]),\n",
       "    'exp_avg_sq': tensor([[9.9153e-13, 1.2513e-12, 1.4365e-12,  ..., 8.7143e-13, 1.6983e-12,\n",
       "             1.3919e-12],\n",
       "            [1.0498e-12, 1.1504e-12, 1.2896e-12,  ..., 9.4720e-13, 1.2492e-12,\n",
       "             1.1776e-12],\n",
       "            [6.1959e-13, 7.3057e-13, 6.8573e-13,  ..., 5.0780e-13, 5.6975e-13,\n",
       "             7.0691e-13],\n",
       "            ...,\n",
       "            [7.4616e-13, 1.2163e-12, 1.4434e-12,  ..., 5.9362e-13, 1.0097e-12,\n",
       "             1.1720e-12],\n",
       "            [1.2161e-12, 1.1211e-12, 7.6713e-13,  ..., 1.2222e-12, 1.2904e-12,\n",
       "             1.3411e-12],\n",
       "            [1.2344e-12, 1.3417e-12, 7.9152e-13,  ..., 1.0324e-12, 1.0219e-12,\n",
       "             1.0524e-12]])},\n",
       "   'model.layers.9.self_attn.v_proj.bias': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([ 3.9645e-06,  4.9526e-07,  1.3758e-05,  ..., -4.3452e-06,\n",
       "            -5.3797e-06, -3.7958e-06]),\n",
       "    'exp_avg_sq': tensor([4.4902e-09, 1.4492e-09, 2.8961e-09,  ..., 1.1448e-09, 1.6850e-09,\n",
       "            1.6744e-09])},\n",
       "   'model.layers.9.self_attn.v_proj.weight': {'step': tensor(30000.),\n",
       "    'exp_avg': tensor([[ 4.2913e-07, -6.8709e-07, -2.5748e-07,  ...,  1.4088e-07,\n",
       "              1.2893e-06, -1.0560e-06],\n",
       "            [-9.8751e-07, -1.4281e-06, -7.4980e-07,  ..., -3.8789e-07,\n",
       "             -7.0483e-07,  3.6234e-07],\n",
       "            [-9.1371e-07, -7.2795e-08, -1.1180e-06,  ..., -5.1976e-09,\n",
       "             -8.4882e-07,  4.0846e-07],\n",
       "            ...,\n",
       "            [-2.4421e-07, -9.9640e-07,  2.8724e-08,  ..., -3.2211e-07,\n",
       "             -6.8550e-07, -1.1883e-07],\n",
       "            [ 4.8921e-07, -9.3455e-07, -6.2905e-07,  ..., -1.1716e-06,\n",
       "             -6.4237e-07,  1.2692e-06],\n",
       "            [ 2.3563e-08,  2.2552e-07, -1.3056e-06,  ..., -1.2204e-06,\n",
       "             -6.3293e-07,  1.3009e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.7405e-11, 1.1077e-11, 1.3538e-11,  ..., 1.1776e-11, 1.6035e-11,\n",
       "             2.1301e-11],\n",
       "            [1.2643e-11, 2.0838e-11, 1.3835e-11,  ..., 1.2918e-11, 1.2000e-11,\n",
       "             1.9795e-11],\n",
       "            [1.6029e-11, 2.3112e-11, 1.7263e-11,  ..., 1.4303e-11, 2.5351e-11,\n",
       "             1.6161e-11],\n",
       "            ...,\n",
       "            [1.6657e-11, 1.7093e-11, 1.1726e-11,  ..., 2.0897e-11, 9.7443e-12,\n",
       "             1.1504e-11],\n",
       "            [1.2853e-11, 2.3367e-11, 2.3066e-11,  ..., 1.3074e-11, 9.5557e-12,\n",
       "             1.5081e-11],\n",
       "            [1.3468e-11, 2.0868e-11, 1.3987e-11,  ..., 1.3498e-11, 1.4466e-11,\n",
       "             2.1996e-11]])}},\n",
       "  'param_groups': [{'lr': 0.00035788900944458185,\n",
       "    'betas': (0.9, 0.95),\n",
       "    'eps': 1e-08,\n",
       "    'weight_decay': 0.1,\n",
       "    'amsgrad': False,\n",
       "    'foreach': False,\n",
       "    'maximize': False,\n",
       "    'capturable': False,\n",
       "    'differentiable': False,\n",
       "    'fused': None,\n",
       "    'params': ['model.embed_tokens.weight',\n",
       "     'model.layers.0.self_attn.q_proj.weight',\n",
       "     'model.layers.0.self_attn.q_proj.bias',\n",
       "     'model.layers.0.self_attn.k_proj.weight',\n",
       "     'model.layers.0.self_attn.k_proj.bias',\n",
       "     'model.layers.0.self_attn.v_proj.weight',\n",
       "     'model.layers.0.self_attn.v_proj.bias',\n",
       "     'model.layers.0.self_attn.o_proj.weight',\n",
       "     'model.layers.0.mlp.gate_proj.weight',\n",
       "     'model.layers.0.mlp.up_proj.weight',\n",
       "     'model.layers.0.mlp.down_proj.weight',\n",
       "     'model.layers.0.input_layernorm.weight',\n",
       "     'model.layers.0.post_attention_layernorm.weight',\n",
       "     'model.layers.1.self_attn.q_proj.weight',\n",
       "     'model.layers.1.self_attn.q_proj.bias',\n",
       "     'model.layers.1.self_attn.k_proj.weight',\n",
       "     'model.layers.1.self_attn.k_proj.bias',\n",
       "     'model.layers.1.self_attn.v_proj.weight',\n",
       "     'model.layers.1.self_attn.v_proj.bias',\n",
       "     'model.layers.1.self_attn.o_proj.weight',\n",
       "     'model.layers.1.mlp.gate_proj.weight',\n",
       "     'model.layers.1.mlp.up_proj.weight',\n",
       "     'model.layers.1.mlp.down_proj.weight',\n",
       "     'model.layers.1.input_layernorm.weight',\n",
       "     'model.layers.1.post_attention_layernorm.weight',\n",
       "     'model.layers.2.self_attn.q_proj.weight',\n",
       "     'model.layers.2.self_attn.q_proj.bias',\n",
       "     'model.layers.2.self_attn.k_proj.weight',\n",
       "     'model.layers.2.self_attn.k_proj.bias',\n",
       "     'model.layers.2.self_attn.v_proj.weight',\n",
       "     'model.layers.2.self_attn.v_proj.bias',\n",
       "     'model.layers.2.self_attn.o_proj.weight',\n",
       "     'model.layers.2.mlp.gate_proj.weight',\n",
       "     'model.layers.2.mlp.up_proj.weight',\n",
       "     'model.layers.2.mlp.down_proj.weight',\n",
       "     'model.layers.2.input_layernorm.weight',\n",
       "     'model.layers.2.post_attention_layernorm.weight',\n",
       "     'model.layers.3.self_attn.q_proj.weight',\n",
       "     'model.layers.3.self_attn.q_proj.bias',\n",
       "     'model.layers.3.self_attn.k_proj.weight',\n",
       "     'model.layers.3.self_attn.k_proj.bias',\n",
       "     'model.layers.3.self_attn.v_proj.weight',\n",
       "     'model.layers.3.self_attn.v_proj.bias',\n",
       "     'model.layers.3.self_attn.o_proj.weight',\n",
       "     'model.layers.3.mlp.gate_proj.weight',\n",
       "     'model.layers.3.mlp.up_proj.weight',\n",
       "     'model.layers.3.mlp.down_proj.weight',\n",
       "     'model.layers.3.input_layernorm.weight',\n",
       "     'model.layers.3.post_attention_layernorm.weight',\n",
       "     'model.layers.4.self_attn.q_proj.weight',\n",
       "     'model.layers.4.self_attn.q_proj.bias',\n",
       "     'model.layers.4.self_attn.k_proj.weight',\n",
       "     'model.layers.4.self_attn.k_proj.bias',\n",
       "     'model.layers.4.self_attn.v_proj.weight',\n",
       "     'model.layers.4.self_attn.v_proj.bias',\n",
       "     'model.layers.4.self_attn.o_proj.weight',\n",
       "     'model.layers.4.mlp.gate_proj.weight',\n",
       "     'model.layers.4.mlp.up_proj.weight',\n",
       "     'model.layers.4.mlp.down_proj.weight',\n",
       "     'model.layers.4.input_layernorm.weight',\n",
       "     'model.layers.4.post_attention_layernorm.weight',\n",
       "     'model.layers.5.self_attn.q_proj.weight',\n",
       "     'model.layers.5.self_attn.q_proj.bias',\n",
       "     'model.layers.5.self_attn.k_proj.weight',\n",
       "     'model.layers.5.self_attn.k_proj.bias',\n",
       "     'model.layers.5.self_attn.v_proj.weight',\n",
       "     'model.layers.5.self_attn.v_proj.bias',\n",
       "     'model.layers.5.self_attn.o_proj.weight',\n",
       "     'model.layers.5.mlp.gate_proj.weight',\n",
       "     'model.layers.5.mlp.up_proj.weight',\n",
       "     'model.layers.5.mlp.down_proj.weight',\n",
       "     'model.layers.5.input_layernorm.weight',\n",
       "     'model.layers.5.post_attention_layernorm.weight',\n",
       "     'model.layers.6.self_attn.q_proj.weight',\n",
       "     'model.layers.6.self_attn.q_proj.bias',\n",
       "     'model.layers.6.self_attn.k_proj.weight',\n",
       "     'model.layers.6.self_attn.k_proj.bias',\n",
       "     'model.layers.6.self_attn.v_proj.weight',\n",
       "     'model.layers.6.self_attn.v_proj.bias',\n",
       "     'model.layers.6.self_attn.o_proj.weight',\n",
       "     'model.layers.6.mlp.gate_proj.weight',\n",
       "     'model.layers.6.mlp.up_proj.weight',\n",
       "     'model.layers.6.mlp.down_proj.weight',\n",
       "     'model.layers.6.input_layernorm.weight',\n",
       "     'model.layers.6.post_attention_layernorm.weight',\n",
       "     'model.layers.7.self_attn.q_proj.weight',\n",
       "     'model.layers.7.self_attn.q_proj.bias',\n",
       "     'model.layers.7.self_attn.k_proj.weight',\n",
       "     'model.layers.7.self_attn.k_proj.bias',\n",
       "     'model.layers.7.self_attn.v_proj.weight',\n",
       "     'model.layers.7.self_attn.v_proj.bias',\n",
       "     'model.layers.7.self_attn.o_proj.weight',\n",
       "     'model.layers.7.mlp.gate_proj.weight',\n",
       "     'model.layers.7.mlp.up_proj.weight',\n",
       "     'model.layers.7.mlp.down_proj.weight',\n",
       "     'model.layers.7.input_layernorm.weight',\n",
       "     'model.layers.7.post_attention_layernorm.weight',\n",
       "     'model.layers.8.self_attn.q_proj.weight',\n",
       "     'model.layers.8.self_attn.q_proj.bias',\n",
       "     'model.layers.8.self_attn.k_proj.weight',\n",
       "     'model.layers.8.self_attn.k_proj.bias',\n",
       "     'model.layers.8.self_attn.v_proj.weight',\n",
       "     'model.layers.8.self_attn.v_proj.bias',\n",
       "     'model.layers.8.self_attn.o_proj.weight',\n",
       "     'model.layers.8.mlp.gate_proj.weight',\n",
       "     'model.layers.8.mlp.up_proj.weight',\n",
       "     'model.layers.8.mlp.down_proj.weight',\n",
       "     'model.layers.8.input_layernorm.weight',\n",
       "     'model.layers.8.post_attention_layernorm.weight',\n",
       "     'model.layers.9.self_attn.q_proj.weight',\n",
       "     'model.layers.9.self_attn.q_proj.bias',\n",
       "     'model.layers.9.self_attn.k_proj.weight',\n",
       "     'model.layers.9.self_attn.k_proj.bias',\n",
       "     'model.layers.9.self_attn.v_proj.weight',\n",
       "     'model.layers.9.self_attn.v_proj.bias',\n",
       "     'model.layers.9.self_attn.o_proj.weight',\n",
       "     'model.layers.9.mlp.gate_proj.weight',\n",
       "     'model.layers.9.mlp.up_proj.weight',\n",
       "     'model.layers.9.mlp.down_proj.weight',\n",
       "     'model.layers.9.input_layernorm.weight',\n",
       "     'model.layers.9.post_attention_layernorm.weight',\n",
       "     'model.layers.10.self_attn.q_proj.weight',\n",
       "     'model.layers.10.self_attn.q_proj.bias',\n",
       "     'model.layers.10.self_attn.k_proj.weight',\n",
       "     'model.layers.10.self_attn.k_proj.bias',\n",
       "     'model.layers.10.self_attn.v_proj.weight',\n",
       "     'model.layers.10.self_attn.v_proj.bias',\n",
       "     'model.layers.10.self_attn.o_proj.weight',\n",
       "     'model.layers.10.mlp.gate_proj.weight',\n",
       "     'model.layers.10.mlp.up_proj.weight',\n",
       "     'model.layers.10.mlp.down_proj.weight',\n",
       "     'model.layers.10.input_layernorm.weight',\n",
       "     'model.layers.10.post_attention_layernorm.weight',\n",
       "     'model.layers.11.self_attn.q_proj.weight',\n",
       "     'model.layers.11.self_attn.q_proj.bias',\n",
       "     'model.layers.11.self_attn.k_proj.weight',\n",
       "     'model.layers.11.self_attn.k_proj.bias',\n",
       "     'model.layers.11.self_attn.v_proj.weight',\n",
       "     'model.layers.11.self_attn.v_proj.bias',\n",
       "     'model.layers.11.self_attn.o_proj.weight',\n",
       "     'model.layers.11.mlp.gate_proj.weight',\n",
       "     'model.layers.11.mlp.up_proj.weight',\n",
       "     'model.layers.11.mlp.down_proj.weight',\n",
       "     'model.layers.11.input_layernorm.weight',\n",
       "     'model.layers.11.post_attention_layernorm.weight',\n",
       "     'model.layers.12.self_attn.q_proj.weight',\n",
       "     'model.layers.12.self_attn.q_proj.bias',\n",
       "     'model.layers.12.self_attn.k_proj.weight',\n",
       "     'model.layers.12.self_attn.k_proj.bias',\n",
       "     'model.layers.12.self_attn.v_proj.weight',\n",
       "     'model.layers.12.self_attn.v_proj.bias',\n",
       "     'model.layers.12.self_attn.o_proj.weight',\n",
       "     'model.layers.12.mlp.gate_proj.weight',\n",
       "     'model.layers.12.mlp.up_proj.weight',\n",
       "     'model.layers.12.mlp.down_proj.weight',\n",
       "     'model.layers.12.input_layernorm.weight',\n",
       "     'model.layers.12.post_attention_layernorm.weight',\n",
       "     'model.layers.13.self_attn.q_proj.weight',\n",
       "     'model.layers.13.self_attn.q_proj.bias',\n",
       "     'model.layers.13.self_attn.k_proj.weight',\n",
       "     'model.layers.13.self_attn.k_proj.bias',\n",
       "     'model.layers.13.self_attn.v_proj.weight',\n",
       "     'model.layers.13.self_attn.v_proj.bias',\n",
       "     'model.layers.13.self_attn.o_proj.weight',\n",
       "     'model.layers.13.mlp.gate_proj.weight',\n",
       "     'model.layers.13.mlp.up_proj.weight',\n",
       "     'model.layers.13.mlp.down_proj.weight',\n",
       "     'model.layers.13.input_layernorm.weight',\n",
       "     'model.layers.13.post_attention_layernorm.weight',\n",
       "     'model.layers.14.self_attn.q_proj.weight',\n",
       "     'model.layers.14.self_attn.q_proj.bias',\n",
       "     'model.layers.14.self_attn.k_proj.weight',\n",
       "     'model.layers.14.self_attn.k_proj.bias',\n",
       "     'model.layers.14.self_attn.v_proj.weight',\n",
       "     'model.layers.14.self_attn.v_proj.bias',\n",
       "     'model.layers.14.self_attn.o_proj.weight',\n",
       "     'model.layers.14.mlp.gate_proj.weight',\n",
       "     'model.layers.14.mlp.up_proj.weight',\n",
       "     'model.layers.14.mlp.down_proj.weight',\n",
       "     'model.layers.14.input_layernorm.weight',\n",
       "     'model.layers.14.post_attention_layernorm.weight',\n",
       "     'model.layers.15.self_attn.q_proj.weight',\n",
       "     'model.layers.15.self_attn.q_proj.bias',\n",
       "     'model.layers.15.self_attn.k_proj.weight',\n",
       "     'model.layers.15.self_attn.k_proj.bias',\n",
       "     'model.layers.15.self_attn.v_proj.weight',\n",
       "     'model.layers.15.self_attn.v_proj.bias',\n",
       "     'model.layers.15.self_attn.o_proj.weight',\n",
       "     'model.layers.15.mlp.gate_proj.weight',\n",
       "     'model.layers.15.mlp.up_proj.weight',\n",
       "     'model.layers.15.mlp.down_proj.weight',\n",
       "     'model.layers.15.input_layernorm.weight',\n",
       "     'model.layers.15.post_attention_layernorm.weight',\n",
       "     'model.layers.16.self_attn.q_proj.weight',\n",
       "     'model.layers.16.self_attn.q_proj.bias',\n",
       "     'model.layers.16.self_attn.k_proj.weight',\n",
       "     'model.layers.16.self_attn.k_proj.bias',\n",
       "     'model.layers.16.self_attn.v_proj.weight',\n",
       "     'model.layers.16.self_attn.v_proj.bias',\n",
       "     'model.layers.16.self_attn.o_proj.weight',\n",
       "     'model.layers.16.mlp.gate_proj.weight',\n",
       "     'model.layers.16.mlp.up_proj.weight',\n",
       "     'model.layers.16.mlp.down_proj.weight',\n",
       "     'model.layers.16.input_layernorm.weight',\n",
       "     'model.layers.16.post_attention_layernorm.weight',\n",
       "     'model.layers.17.self_attn.q_proj.weight',\n",
       "     'model.layers.17.self_attn.q_proj.bias',\n",
       "     'model.layers.17.self_attn.k_proj.weight',\n",
       "     'model.layers.17.self_attn.k_proj.bias',\n",
       "     'model.layers.17.self_attn.v_proj.weight',\n",
       "     'model.layers.17.self_attn.v_proj.bias',\n",
       "     'model.layers.17.self_attn.o_proj.weight',\n",
       "     'model.layers.17.mlp.gate_proj.weight',\n",
       "     'model.layers.17.mlp.up_proj.weight',\n",
       "     'model.layers.17.mlp.down_proj.weight',\n",
       "     'model.layers.17.input_layernorm.weight',\n",
       "     'model.layers.17.post_attention_layernorm.weight',\n",
       "     'model.layers.18.self_attn.q_proj.weight',\n",
       "     'model.layers.18.self_attn.q_proj.bias',\n",
       "     'model.layers.18.self_attn.k_proj.weight',\n",
       "     'model.layers.18.self_attn.k_proj.bias',\n",
       "     'model.layers.18.self_attn.v_proj.weight',\n",
       "     'model.layers.18.self_attn.v_proj.bias',\n",
       "     'model.layers.18.self_attn.o_proj.weight',\n",
       "     'model.layers.18.mlp.gate_proj.weight',\n",
       "     'model.layers.18.mlp.up_proj.weight',\n",
       "     'model.layers.18.mlp.down_proj.weight',\n",
       "     'model.layers.18.input_layernorm.weight',\n",
       "     'model.layers.18.post_attention_layernorm.weight',\n",
       "     'model.layers.19.self_attn.q_proj.weight',\n",
       "     'model.layers.19.self_attn.q_proj.bias',\n",
       "     'model.layers.19.self_attn.k_proj.weight',\n",
       "     'model.layers.19.self_attn.k_proj.bias',\n",
       "     'model.layers.19.self_attn.v_proj.weight',\n",
       "     'model.layers.19.self_attn.v_proj.bias',\n",
       "     'model.layers.19.self_attn.o_proj.weight',\n",
       "     'model.layers.19.mlp.gate_proj.weight',\n",
       "     'model.layers.19.mlp.up_proj.weight',\n",
       "     'model.layers.19.mlp.down_proj.weight',\n",
       "     'model.layers.19.input_layernorm.weight',\n",
       "     'model.layers.19.post_attention_layernorm.weight',\n",
       "     'model.layers.20.self_attn.q_proj.weight',\n",
       "     'model.layers.20.self_attn.q_proj.bias',\n",
       "     'model.layers.20.self_attn.k_proj.weight',\n",
       "     'model.layers.20.self_attn.k_proj.bias',\n",
       "     'model.layers.20.self_attn.v_proj.weight',\n",
       "     'model.layers.20.self_attn.v_proj.bias',\n",
       "     'model.layers.20.self_attn.o_proj.weight',\n",
       "     'model.layers.20.mlp.gate_proj.weight',\n",
       "     'model.layers.20.mlp.up_proj.weight',\n",
       "     'model.layers.20.mlp.down_proj.weight',\n",
       "     'model.layers.20.input_layernorm.weight',\n",
       "     'model.layers.20.post_attention_layernorm.weight',\n",
       "     'model.layers.21.self_attn.q_proj.weight',\n",
       "     'model.layers.21.self_attn.q_proj.bias',\n",
       "     'model.layers.21.self_attn.k_proj.weight',\n",
       "     'model.layers.21.self_attn.k_proj.bias',\n",
       "     'model.layers.21.self_attn.v_proj.weight',\n",
       "     'model.layers.21.self_attn.v_proj.bias',\n",
       "     'model.layers.21.self_attn.o_proj.weight',\n",
       "     'model.layers.21.mlp.gate_proj.weight',\n",
       "     'model.layers.21.mlp.up_proj.weight',\n",
       "     'model.layers.21.mlp.down_proj.weight',\n",
       "     'model.layers.21.input_layernorm.weight',\n",
       "     'model.layers.21.post_attention_layernorm.weight',\n",
       "     'model.layers.22.self_attn.q_proj.weight',\n",
       "     'model.layers.22.self_attn.q_proj.bias',\n",
       "     'model.layers.22.self_attn.k_proj.weight',\n",
       "     'model.layers.22.self_attn.k_proj.bias',\n",
       "     'model.layers.22.self_attn.v_proj.weight',\n",
       "     'model.layers.22.self_attn.v_proj.bias',\n",
       "     'model.layers.22.self_attn.o_proj.weight',\n",
       "     'model.layers.22.mlp.gate_proj.weight',\n",
       "     'model.layers.22.mlp.up_proj.weight',\n",
       "     'model.layers.22.mlp.down_proj.weight',\n",
       "     'model.layers.22.input_layernorm.weight',\n",
       "     'model.layers.22.post_attention_layernorm.weight',\n",
       "     'model.layers.23.self_attn.q_proj.weight',\n",
       "     'model.layers.23.self_attn.q_proj.bias',\n",
       "     'model.layers.23.self_attn.k_proj.weight',\n",
       "     'model.layers.23.self_attn.k_proj.bias',\n",
       "     'model.layers.23.self_attn.v_proj.weight',\n",
       "     'model.layers.23.self_attn.v_proj.bias',\n",
       "     'model.layers.23.self_attn.o_proj.weight',\n",
       "     'model.layers.23.mlp.gate_proj.weight',\n",
       "     'model.layers.23.mlp.up_proj.weight',\n",
       "     'model.layers.23.mlp.down_proj.weight',\n",
       "     'model.layers.23.input_layernorm.weight',\n",
       "     'model.layers.23.post_attention_layernorm.weight',\n",
       "     'model.norm.weight',\n",
       "     'lm_head.weight']}]},\n",
       " 'hparams': {'current_file_path': '/home/calfa100/gqs/Steel-LLM/pretrain_modify_from_TinyLlama/pretrain/pretrain_steel_llm.py',\n",
       "  'current_dir': '/home/calfa100/gqs/Steel-LLM/pretrain_modify_from_TinyLlama/pretrain',\n",
       "  'parent_dir': '/home/calfa100/gqs/Steel-LLM/pretrain_modify_from_TinyLlama',\n",
       "  'name': 'test_qwen2',\n",
       "  'MODEL_PATH': '../model/qwen_15_1_8B_chat',\n",
       "  'BLOCK_SIZE': 2048,\n",
       "  'RESUME': False,\n",
       "  'IGNORE_INDEX': 151643,\n",
       "  'USE_FLASH_ATTN': True,\n",
       "  'num_of_devices': 8,\n",
       "  'global_batch_size': 128,\n",
       "  'learning_rate': 0.0004,\n",
       "  'micro_batch_size': 4,\n",
       "  'max_step': 1430512,\n",
       "  'decay_lr': True,\n",
       "  'lr_decay_step': 100000,\n",
       "  'min_lr': 4e-05,\n",
       "  'warmup_steps': 10000,\n",
       "  'log_step_interval': 1,\n",
       "  'eval_iters': 100,\n",
       "  'save_step_interval': 5000,\n",
       "  'eval_step_interval': 5000,\n",
       "  'weight_decay': 0.1,\n",
       "  'beta1': 0.9,\n",
       "  'beta2': 0.95,\n",
       "  'grad_clip': 1.0,\n",
       "  'batch_size': 16,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'warmup_iters': 40000,\n",
       "  'max_iters': 5722048,\n",
       "  'lr_decay_iters': 400000,\n",
       "  'log_iter_interval': 4},\n",
       " 'iter_num': 120000,\n",
       " 'step_count': 30000}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy  as np\n",
    "import lightning as L\n",
    "from deepspeed.profiling.flops_profiler import get_model_profile  # type: ignore\n",
    "fabric = L.Fabric(devices=1, precision=\"bf16-mixed\")\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "sys.path.append(os.path.join(current_dir, \"steel_modify_from_qwen_1_5\"))\n",
    "from transformers import AutoConfig\n",
    "from steel_modify_from_qwen_1_5.modeling_steel import Qwen2ForCausalLM\n",
    "config = AutoConfig.from_pretrained(\"./steel_modify_from_qwen_1_5\",trust_remote_code=True)\n",
    "config.FFN_type = \"raw\"\n",
    "config.mlp_div_ratio = 1\n",
    "ckpt = \"/home/calfa100/gqs/Steel-LLM/pretrain_modify_from_TinyLlama/pretrain/out/qwen1_5_step-030000-iter-120000-ckpt/state.pth\"\n",
    "model = Qwen2ForCausalLM(config).to(\"cuda:0\").to(torch.bfloat16)\n",
    "state = {\"model\": model}\n",
    "fabric.load(ckpt, state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我好看吗？我好喜欢你，我好喜欢你，我好喜欢你，我好喜欢你，我好喜欢你，我好喜欢你，我好喜欢你，我好喜欢你，我好喜欢你，我好喜欢你，我好喜欢你，我好喜欢你，我好喜欢你，我好喜欢你，我好喜欢你，我好喜欢你，我好喜欢你，我好喜欢你，我好喜欢你，我好喜欢你\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/calfa100/gqs/Steel-LLM/pretrain_modify_from_TinyLlama/model/tokenizer_from_qwen_moe_chat\")\n",
    "model_inputs = tokenizer([\"我好看吗\"], return_tensors=\"pt\").to(\"cuda:0\")\n",
    "generated_ids = model.generate(\n",
    "    model_inputs.input_ids,\n",
    "    max_new_tokens=100\n",
    ")\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# softmoe v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 30, 8])\n",
      "torch.Size([1, 30, 8, 10])\n",
      "torch.Size([1, 30, 10])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from transformers import AutoConfig\n",
    "config = AutoConfig.from_pretrained(\"./steel_modify_from_qwen_1_5\",trust_remote_code=True)\n",
    "\n",
    "class SteelSoftMoeV1(nn.Module):\n",
    "    def __init__(self, config, layer=None):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        # self.experts = nn.ModuleList([layer(config) for _ in range(config.n_experts)])\n",
    "        self.experts = nn.ModuleList([nn.Linear(config.hidden_size, 10) for _ in range(config.n_experts)])\n",
    "        self.gating = nn.Linear(config.hidden_size, config.n_experts)\n",
    "    def forward(self, x):\n",
    "        weights = self.gating(x)\n",
    "        weights = nn.functional.softmax(weights, dim=-1, dtype=torch.float32).to(x.dtype)\n",
    "        outputs = torch.stack( \n",
    "            [expert(x) for expert in self.experts], dim=2) \n",
    "        weights = weights.unsqueeze(-1)\n",
    "        return torch.sum(outputs * weights, dim=2)\n",
    "    \n",
    "fake_input = torch.randn([1,30,config.hidden_size])\n",
    "layer = SteelSoftMoeV1(config)\n",
    "print(layer(fake_input).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
